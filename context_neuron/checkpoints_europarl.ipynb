{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from transformer_lens import HookedTransformer\n",
    "from jaxtyping import Float, Int, Bool\n",
    "from torch import Tensor\n",
    "from tqdm.auto import tqdm\n",
    "import plotly.io as pio\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px \n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from IPython.display import display, HTML\n",
    "from datasets import load_dataset\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import os\n",
    "import haystack_utils\n",
    "from transformer_lens import utils\n",
    "from fancy_einsum import einsum\n",
    "import einops\n",
    "import json\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from datasets import load_dataset\n",
    "import random\n",
    "import math\n",
    "import random\n",
    "import neel.utils as nutils\n",
    "from neel_plotly import *\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import shuffle\n",
    "import probing_utils\n",
    "import pickle\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "import gzip\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotting_utils\n",
    "import re\n",
    "\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "pio.renderers.default = \"notebook_connected+notebook\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "#torch.autograd.set_grad_enabled(False)\n",
    "#torch.set_grad_enabled(False)\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b529162667dd4dcf878f0ea85717ba8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "europarl_temp.jsonl.zst:   0%|          | 0.00/10.4G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import pyzstd\n",
    "\n",
    "def download_file_with_progress(url, filename):\n",
    "    response = requests.get(url, stream=True)\n",
    "    file_size = int(response.headers.get('content-length', 0))\n",
    "    \n",
    "    with open(filename, 'wb') as f, tqdm(\n",
    "        desc=filename,\n",
    "        total=file_size,\n",
    "        unit='B',\n",
    "        unit_scale=True,\n",
    "        unit_divisor=1024,\n",
    "    ) as bar:\n",
    "        for data in response.iter_content(chunk_size=1024):\n",
    "            bar.update(len(data))\n",
    "            f.write(data)\n",
    "\n",
    "# Download the file\n",
    "url = \"https://huggingface.co/datasets/monology/pile-uncopyrighted/resolve/main/train/00.jsonl.zst\"\n",
    "#url = \"https://huggingface.co/datasets/monology/pile-uncopyrighted/resolve/main/val.jsonl.zst\"\n",
    "# response = requests.get(url)\n",
    "# with open(\"europarl_temp.jsonl.zst\", \"wb\") as f:\n",
    "#     f.write(response.content)\n",
    "\n",
    "download_file_with_progress(url, \"europarl_temp.jsonl.zst\")\n",
    "\n",
    "# Decompress the file\n",
    "with open(\"europarl_temp.jsonl.zst\", \"rb\") as compressed, open(\"europarl_temp.jsonl\", \"wb\") as decompressed:\n",
    "    decompressed.write(pyzstd.decompress(compressed.read()))\n",
    "\n",
    "# Read JSON lines from the decompressed file\n",
    "with open(\"europarl_temp.jsonl\", \"r\") as f:\n",
    "    data = [json.loads(line) for line in f.readlines()]\n",
    "\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read JSON lines from the decompressed file\n",
    "with open(\"europarl_temp.jsonl\", \"r\") as f:\n",
    "    data = [json.loads(line) for line in f.readlines()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': '2. Označování pneumatik s ohledem na palivovou účinnost (\\nIvo Belet\\nzpravodaj. - Pane předsedo, v krátkosti bych rád poděkoval švédskému předsednictví za výbornou spolupráci. Domnívám se, že tato smlouva je zároveň ambiciózní i realistická. Přesvědčí nás přiklonit se k větší palivové účinnosti, menší hlučnosti a samozřejmě větší bezpečnosti. Mé poděkování směřuje i ke Komisi a stínovým zpravodajům, Matthiasi Grootemu a Jorgu Chatzimarkakisovi, za jejich skvělou práci.\\n', 'meta': {'pile_set_name': 'EuroParl'}}\n"
     ]
    }
   ],
   "source": [
    "for example in data:\n",
    "    if example[\"meta\"][\"pile_set_name\"] == \"EuroParl\":\n",
    "        print(example)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
