{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from transformer_lens import HookedTransformer, ActivationCache, utils, patching\n",
    "from jaxtyping import Float, Int, Bool\n",
    "from torch import Tensor\n",
    "from tqdm.auto import tqdm\n",
    "import plotly.io as pio\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "pio.renderers.default = \"notebook_connected\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.autograd.set_grad_enabled(False)\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "from haystack_utils import get_mlp_activations\n",
    "import haystack_utils\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adc75ab72d6a4658b98991ce76fe8a5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/567 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34209e8777c74d92be4876be04a825db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/166M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8319d993cdbb466f8ff35354246cb1b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/396 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "524fc849365c4f4c8f2af4d91b87aa76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "798592238c2443d49c9872a8a415a98d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model EleutherAI/pythia-70m into HookedTransformer\n",
      "data/german_europarl.json: Loaded 2000 examples with 152 to 2000 characters each.\n",
      "data/english_europarl.json: Loaded 2000 examples with 165 to 2000 characters each.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec354adb99b94c1f88c6796881cb115e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39796880c2f942ec9f386535f08da5df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "744cd4451a12456e80c50cb10a6cb339",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e8946b2ddf842fe84428ec020700329",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd8cbc5c0543408a9ba4ecf953222ea1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9401ea3ec70a4115bcdc1993b93641a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = HookedTransformer.from_pretrained(\"EleutherAI/pythia-70m\",\n",
    "    center_unembed=True,\n",
    "    center_writing_weights=True,\n",
    "    fold_ln=True,\n",
    "    device=device)\n",
    "\n",
    "german_data = haystack_utils.load_json_data(\"data/german_europarl.json\")\n",
    "english_data = haystack_utils.load_json_data(\"data/english_europarl.json\")\n",
    "\n",
    "\n",
    "english_activations = {}\n",
    "german_activations = {}\n",
    "for layer in range(3, 6):\n",
    "    english_activations[layer] = get_mlp_activations(english_data[:200], layer, model, mean=False)\n",
    "    german_activations[layer] = get_mlp_activations(german_data[:200], layer, model, mean=False)\n",
    "\n",
    "LAYER_TO_ABLATE = 3\n",
    "NEURONS_TO_ABLATE = [669]\n",
    "MEAN_ACTIVATION_ACTIVE = german_activations[LAYER_TO_ABLATE][:, NEURONS_TO_ABLATE].mean()\n",
    "MEAN_ACTIVATION_INACTIVE = english_activations[LAYER_TO_ABLATE][:, NEURONS_TO_ABLATE].mean()\n",
    "\n",
    "def deactivate_neurons_hook(value, hook):\n",
    "    value[:, :, NEURONS_TO_ABLATE] = MEAN_ACTIVATION_INACTIVE\n",
    "    return value\n",
    "deactivate_neurons_fwd_hooks=[(f'blocks.{LAYER_TO_ABLATE}.mlp.hook_post', deactivate_neurons_hook)]\n",
    "\n",
    "def activate_neurons_hook(value, hook):\n",
    "    value[:, :, NEURONS_TO_ABLATE] = MEAN_ACTIVATION_ACTIVE\n",
    "    return value\n",
    "activate_neurons_fwd_hooks=[(f'blocks.{LAYER_TO_ABLATE}.mlp.hook_post', activate_neurons_hook)]\n",
    "\n",
    "all_ignore, not_ignore = haystack_utils.get_weird_tokens(model, plot_norms=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find top common German tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "779815dd913342f694838d615264b91e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' der', 'en', ' die', ' und', 'ung', 'ä', ' in', ' den', ' des', 'ch', 'st', ' zu', 're', ' für', 'äsident', ' Pr', 'n', 'z', 'ischen', ' von', 'ü', 't', 'icht', 'in', 'ge', 'gen', 'te', ' ist', ' auf', 'ig', ' über', ' dass', ' im', 'f', ' er', 'es', ' das', 'men', 'g', 'ß', ' Europ', ' w', 'w', 'le', 'ten', ' eine', ' wir', ' ein', ' an', 'hen', 'ren', 'e', ' ich', 'ungen', ' W', ' Ver', ' B', ' dem', ' mit', ' dies', ' nicht', ' Z', 'h', ' z', 's', 'it', 'hr', ' es', ' zur', ' An', ' Herr', 'ich', 'heit', 'b', 'lich', 'l', ' ver', ' S', 'i', ' G', 'Der', ' V', 'der', 'u', 'ie', ' Ab', 'ungs', 'chte', 'chaft', 'igen', ' werden', 'uss', 'ord', 'em', ' Ber', 'ür', ' haben', 'et', ' um', ' Ich']\n"
     ]
    }
   ],
   "source": [
    "# Get top common german tokens excluding punctuation\n",
    "token_counts = torch.zeros(model.cfg.d_vocab).cuda()\n",
    "for example in tqdm(german_data):\n",
    "    tokens = model.to_tokens(example)\n",
    "    for token in tokens[0]:\n",
    "        token_counts[token.item()] += 1\n",
    "\n",
    "punctuation = [\"\\n\", \".\", \",\", \"!\", \"?\", \";\", \":\", \"-\", \"(\", \")\", \"[\", \"]\", \"{\", \"}\", \"<\", \">\", \"/\", \"\\\\\", \"\\\"\", \"'\"]\n",
    "leading_space_punctuation = [\" \" + char for char in punctuation]\n",
    "punctuation_tokens = model.to_tokens(punctuation + leading_space_punctuation + [' –', \" \", '  ', \"<|endoftext|>\"])[:, 1].flatten()\n",
    "token_counts[punctuation_tokens] = 0\n",
    "token_counts[all_ignore] = 0\n",
    "\n",
    "top_counts, top_tokens = torch.topk(token_counts, 100)\n",
    "print(model.to_str_tokens(top_tokens[:100]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of ngrams preceded by random prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_selection(tensor, n=12):\n",
    "    # Hacky replacement for np.random.choice\n",
    "    return tensor[torch.randperm(len(tensor))[:n]]\n",
    "\n",
    "def generate_random_prompts(end_string, n=50, length=12):\n",
    "    # Generate a batch of random prompts ending with a specific ngram\n",
    "    end_tokens = model.to_tokens(end_string).flatten()[1:]\n",
    "    prompts = []\n",
    "    for i in range(n):\n",
    "        prompt = get_random_selection(top_tokens[:max(50, length)], n=length).cuda()\n",
    "        prompt = torch.cat([prompt, end_tokens])\n",
    "        prompts.append(prompt)\n",
    "    prompts = torch.stack(prompts)\n",
    "    return prompts\n",
    "\n",
    "def replace_column(prompts: Int[Tensor, \"n_prompts n_tokens\"], token_index: int):\n",
    "    # Replaces a specific token position in a batch of prompts with random common German tokens\n",
    "    new_prompts = prompts.clone()\n",
    "    random_tokens = get_random_selection(top_tokens[:max(50, prompts.shape[0])], n=prompts.shape[0]).cuda()\n",
    "    new_prompts[:, token_index] = random_tokens\n",
    "    return new_prompts \n",
    "\n",
    "def loss_analysis(prompts: Tensor, title=\"\"):\n",
    "    # Loss plot for a batch of prompts\n",
    "    names = [\"Original\", \"Ablated\", \"MLP5 path patched\"]\n",
    "    original_loss, ablated_loss, _, only_activated_loss = \\\n",
    "        haystack_utils.get_direct_effect(prompts, model, pos=-1,\n",
    "                                        context_ablation_hooks=deactivate_neurons_fwd_hooks, \n",
    "                                        context_activation_hooks=activate_neurons_fwd_hooks, \n",
    "                                        )\n",
    "    haystack_utils.plot_barplot([original_loss.tolist(), ablated_loss.tolist(), only_activated_loss.tolist()], names, ylabel=\"Loss\", title=title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_analysis_random_prompts(end_string, n=50, length=12, replace_columns: list[int] | None = None):\n",
    "    # Loss plot for a batch of random prompts ending with a specific ngram and optionally replacing specific tokens\n",
    "    prompts = generate_random_prompts(end_string, n=n, length=length)\n",
    "    title=f\"Average last token loss on {length} random tokens ending in '{end_string}'\"\n",
    "    if replace_columns is not None:\n",
    "        replaced_tokens = model.to_str_tokens(prompts[0, replace_columns])\n",
    "        title += f\" replacing {replaced_tokens}\"\n",
    "        for column in replace_columns:\n",
    "            prompts = replace_column(prompts, column)\n",
    "    \n",
    "    loss_analysis(prompts, title=title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "# loss_analysis_random_prompts(\" Vorschlägen\", n=100, length=20)\n",
    "# loss_analysis_random_prompts(\" Vorschlägen\", n=100, length=20, replace_columns=[-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89a94d1da41b40ea8257f54ced267ffd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Ngram: ', options=(' Vorschlägen', ' Vorschläge', ' häufig', ' schließt', ' beweglich'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "970720f6fc6d44ca991c46f8552ede81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SelectMultiple(description='Replace Columns:', index=(3,), options=('-2', '-3', '-4', 'None'), value=('None',)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdc97d93c8404f87834f437bcce64211",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a dropdown menu widget\n",
    "dropdown = widgets.Dropdown(\n",
    "    options = [\" Vorschlägen\", \" Vorschläge\", \" häufig\", \" schließt\", \" beweglich\"], \n",
    "    value = \" Vorschlägen\",\n",
    "    description = 'Ngram: ',\n",
    ")\n",
    "\n",
    "replace_columns_dropdown = widgets.SelectMultiple(\n",
    "    options = ['-2', '-3', '-4', 'None'],\n",
    "    value = ['None'],  # default selected value\n",
    "    description = 'Replace Columns:',\n",
    ")\n",
    "\n",
    "# Create an output widget to hold the plot\n",
    "output = widgets.Output()\n",
    "\n",
    "# Define a function to call when the widget's value changes\n",
    "def update_plot(*args):\n",
    "    # Clear the old plot from the output\n",
    "    with output:\n",
    "        clear_output(wait=True)\n",
    "\n",
    "        if 'None' in replace_columns_dropdown.value:\n",
    "            replace_columns = None\n",
    "        else:\n",
    "            # If 'None' not selected, convert the selected values to integers\n",
    "            replace_columns = [int(val) for val in replace_columns_dropdown.value]\n",
    "        \n",
    "        # Call your function with the values from the widgets\n",
    "        loss_analysis_random_prompts(dropdown.value, n=100, length=20, replace_columns=replace_columns)\n",
    "\n",
    "# Set the function to be called when the widget's value changes\n",
    "dropdown.observe(update_plot, 'value')\n",
    "replace_columns_dropdown.observe(update_plot, 'value')\n",
    "\n",
    "# Display the widget and the output\n",
    "display(dropdown, replace_columns_dropdown, output)\n",
    "\n",
    "# Run once at startup\n",
    "update_plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify relevant neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 24])\n"
     ]
    }
   ],
   "source": [
    "prompts = generate_random_prompts(\" Vorschlägen\", n=100, length=20)\n",
    "print(prompts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e841a708b764eb2b0163004d159b903",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2048 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0007)\n"
     ]
    }
   ],
   "source": [
    "# Calculate neuron-wise loss change\n",
    "with model.hooks(deactivate_neurons_fwd_hooks):\n",
    "    _, ablated_cache = model.run_with_cache(prompts)\n",
    "\n",
    "def get_ablate_neurons_hook(neuron: int | list[int], ablated_cache):\n",
    "    def ablate_neurons_hook(value, hook):\n",
    "        value[:, :, neuron] = ablated_cache['blocks.5.mlp.hook_post'][:, :, neuron]\n",
    "        return value\n",
    "    return [('blocks.5.mlp.hook_post', ablate_neurons_hook)]\n",
    "\n",
    "diffs = torch.zeros(2048, prompts.shape[0])\n",
    "# Loss with path patched MLP5 neurons\n",
    "_, _, _, baseline_loss = haystack_utils.get_direct_effect(prompts, model, pos=-1, context_ablation_hooks=deactivate_neurons_fwd_hooks, context_activation_hooks=activate_neurons_fwd_hooks)\n",
    "for neuron in tqdm(range(2048)):\n",
    "    ablate_single_neuron_hook = get_ablate_neurons_hook(neuron, ablated_cache)\n",
    "    # Loss with path patched MLP5 neurons but a single neuron changed back to original ablated value\n",
    "    _, _, _, only_activated_loss = haystack_utils.get_direct_effect(prompts, model, pos=-1, context_ablation_hooks=deactivate_neurons_fwd_hooks, context_activation_hooks=activate_neurons_fwd_hooks+ablate_single_neuron_hook)\n",
    "    diffs[neuron] = only_activated_loss - baseline_loss\n",
    "\n",
    "print(diffs.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>                            <div id=\"50474075-57e1-4a03-b14e-1b7606c91f23\" class=\"plotly-graph-div\" style=\"height:525px; width:800px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"50474075-57e1-4a03-b14e-1b7606c91f23\")) {                    Plotly.newPlot(                        \"50474075-57e1-4a03-b14e-1b7606c91f23\",                        [{\"hovertemplate\":\"variable=0\\u003cbr\\u003eindex=%{x}\\u003cbr\\u003evalue=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"0\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"0\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800,801,802,803,804,805,806,807,808,809,810,811,812,813,814,815,816,817,818,819,820,821,822,823,824,825,826,827,828,829,830,831,832,833,834,835,836,837,838,839,840,841,842,843,844,845,846,847,848,849,850,851,852,853,854,855,856,857,858,859,860,861,862,863,864,865,866,867,868,869,870,871,872,873,874,875,876,877,878,879,880,881,882,883,884,885,886,887,888,889,890,891,892,893,894,895,896,897,898,899,900,901,902,903,904,905,906,907,908,909,910,911,912,913,914,915,916,917,918,919,920,921,922,923,924,925,926,927,928,929,930,931,932,933,934,935,936,937,938,939,940,941,942,943,944,945,946,947,948,949,950,951,952,953,954,955,956,957,958,959,960,961,962,963,964,965,966,967,968,969,970,971,972,973,974,975,976,977,978,979,980,981,982,983,984,985,986,987,988,989,990,991,992,993,994,995,996,997,998,999,1000,1001,1002,1003,1004,1005,1006,1007,1008,1009,1010,1011,1012,1013,1014,1015,1016,1017,1018,1019,1020,1021,1022,1023,1024,1025,1026,1027,1028,1029,1030,1031,1032,1033,1034,1035,1036,1037,1038,1039,1040,1041,1042,1043,1044,1045,1046,1047,1048,1049,1050,1051,1052,1053,1054,1055,1056,1057,1058,1059,1060,1061,1062,1063,1064,1065,1066,1067,1068,1069,1070,1071,1072,1073,1074,1075,1076,1077,1078,1079,1080,1081,1082,1083,1084,1085,1086,1087,1088,1089,1090,1091,1092,1093,1094,1095,1096,1097,1098,1099,1100,1101,1102,1103,1104,1105,1106,1107,1108,1109,1110,1111,1112,1113,1114,1115,1116,1117,1118,1119,1120,1121,1122,1123,1124,1125,1126,1127,1128,1129,1130,1131,1132,1133,1134,1135,1136,1137,1138,1139,1140,1141,1142,1143,1144,1145,1146,1147,1148,1149,1150,1151,1152,1153,1154,1155,1156,1157,1158,1159,1160,1161,1162,1163,1164,1165,1166,1167,1168,1169,1170,1171,1172,1173,1174,1175,1176,1177,1178,1179,1180,1181,1182,1183,1184,1185,1186,1187,1188,1189,1190,1191,1192,1193,1194,1195,1196,1197,1198,1199,1200,1201,1202,1203,1204,1205,1206,1207,1208,1209,1210,1211,1212,1213,1214,1215,1216,1217,1218,1219,1220,1221,1222,1223,1224,1225,1226,1227,1228,1229,1230,1231,1232,1233,1234,1235,1236,1237,1238,1239,1240,1241,1242,1243,1244,1245,1246,1247,1248,1249,1250,1251,1252,1253,1254,1255,1256,1257,1258,1259,1260,1261,1262,1263,1264,1265,1266,1267,1268,1269,1270,1271,1272,1273,1274,1275,1276,1277,1278,1279,1280,1281,1282,1283,1284,1285,1286,1287,1288,1289,1290,1291,1292,1293,1294,1295,1296,1297,1298,1299,1300,1301,1302,1303,1304,1305,1306,1307,1308,1309,1310,1311,1312,1313,1314,1315,1316,1317,1318,1319,1320,1321,1322,1323,1324,1325,1326,1327,1328,1329,1330,1331,1332,1333,1334,1335,1336,1337,1338,1339,1340,1341,1342,1343,1344,1345,1346,1347,1348,1349,1350,1351,1352,1353,1354,1355,1356,1357,1358,1359,1360,1361,1362,1363,1364,1365,1366,1367,1368,1369,1370,1371,1372,1373,1374,1375,1376,1377,1378,1379,1380,1381,1382,1383,1384,1385,1386,1387,1388,1389,1390,1391,1392,1393,1394,1395,1396,1397,1398,1399,1400,1401,1402,1403,1404,1405,1406,1407,1408,1409,1410,1411,1412,1413,1414,1415,1416,1417,1418,1419,1420,1421,1422,1423,1424,1425,1426,1427,1428,1429,1430,1431,1432,1433,1434,1435,1436,1437,1438,1439,1440,1441,1442,1443,1444,1445,1446,1447,1448,1449,1450,1451,1452,1453,1454,1455,1456,1457,1458,1459,1460,1461,1462,1463,1464,1465,1466,1467,1468,1469,1470,1471,1472,1473,1474,1475,1476,1477,1478,1479,1480,1481,1482,1483,1484,1485,1486,1487,1488,1489,1490,1491,1492,1493,1494,1495,1496,1497,1498,1499,1500,1501,1502,1503,1504,1505,1506,1507,1508,1509,1510,1511,1512,1513,1514,1515,1516,1517,1518,1519,1520,1521,1522,1523,1524,1525,1526,1527,1528,1529,1530,1531,1532,1533,1534,1535,1536,1537,1538,1539,1540,1541,1542,1543,1544,1545,1546,1547,1548,1549,1550,1551,1552,1553,1554,1555,1556,1557,1558,1559,1560,1561,1562,1563,1564,1565,1566,1567,1568,1569,1570,1571,1572,1573,1574,1575,1576,1577,1578,1579,1580,1581,1582,1583,1584,1585,1586,1587,1588,1589,1590,1591,1592,1593,1594,1595,1596,1597,1598,1599,1600,1601,1602,1603,1604,1605,1606,1607,1608,1609,1610,1611,1612,1613,1614,1615,1616,1617,1618,1619,1620,1621,1622,1623,1624,1625,1626,1627,1628,1629,1630,1631,1632,1633,1634,1635,1636,1637,1638,1639,1640,1641,1642,1643,1644,1645,1646,1647,1648,1649,1650,1651,1652,1653,1654,1655,1656,1657,1658,1659,1660,1661,1662,1663,1664,1665,1666,1667,1668,1669,1670,1671,1672,1673,1674,1675,1676,1677,1678,1679,1680,1681,1682,1683,1684,1685,1686,1687,1688,1689,1690,1691,1692,1693,1694,1695,1696,1697,1698,1699,1700,1701,1702,1703,1704,1705,1706,1707,1708,1709,1710,1711,1712,1713,1714,1715,1716,1717,1718,1719,1720,1721,1722,1723,1724,1725,1726,1727,1728,1729,1730,1731,1732,1733,1734,1735,1736,1737,1738,1739,1740,1741,1742,1743,1744,1745,1746,1747,1748,1749,1750,1751,1752,1753,1754,1755,1756,1757,1758,1759,1760,1761,1762,1763,1764,1765,1766,1767,1768,1769,1770,1771,1772,1773,1774,1775,1776,1777,1778,1779,1780,1781,1782,1783,1784,1785,1786,1787,1788,1789,1790,1791,1792,1793,1794,1795,1796,1797,1798,1799,1800,1801,1802,1803,1804,1805,1806,1807,1808,1809,1810,1811,1812,1813,1814,1815,1816,1817,1818,1819,1820,1821,1822,1823,1824,1825,1826,1827,1828,1829,1830,1831,1832,1833,1834,1835,1836,1837,1838,1839,1840,1841,1842,1843,1844,1845,1846,1847,1848,1849,1850,1851,1852,1853,1854,1855,1856,1857,1858,1859,1860,1861,1862,1863,1864,1865,1866,1867,1868,1869,1870,1871,1872,1873,1874,1875,1876,1877,1878,1879,1880,1881,1882,1883,1884,1885,1886,1887,1888,1889,1890,1891,1892,1893,1894,1895,1896,1897,1898,1899,1900,1901,1902,1903,1904,1905,1906,1907,1908,1909,1910,1911,1912,1913,1914,1915,1916,1917,1918,1919,1920,1921,1922,1923,1924,1925,1926,1927,1928,1929,1930,1931,1932,1933,1934,1935,1936,1937,1938,1939,1940,1941,1942,1943,1944,1945,1946,1947,1948,1949,1950,1951,1952,1953,1954,1955,1956,1957,1958,1959,1960,1961,1962,1963,1964,1965,1966,1967,1968,1969,1970,1971,1972,1973,1974,1975,1976,1977,1978,1979,1980,1981,1982,1983,1984,1985,1986,1987,1988,1989,1990,1991,1992,1993,1994,1995,1996,1997,1998,1999,2000,2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,2020,2021,2022,2023,2024,2025,2026,2027,2028,2029,2030,2031,2032,2033,2034,2035,2036,2037,2038,2039,2040,2041,2042,2043,2044,2045,2046,2047],\"xaxis\":\"x\",\"y\":[-0.6308077573776245,-0.3370246887207031,-0.22024986147880554,-0.17209851741790771,-0.16998399794101715,-0.16091912984848022,-0.1530517041683197,-0.14129261672496796,-0.12456971406936646,-0.12169701606035233,-0.1203182116150856,-0.11520304530858994,-0.11043772101402283,-0.10353577882051468,-0.10160411894321442,-0.09944525361061096,-0.08654740452766418,-0.08548317104578018,-0.08281959593296051,-0.08275853842496872,-0.08114277571439743,-0.0800957977771759,-0.07899320125579834,-0.0773465484380722,-0.0735892727971077,-0.0721699520945549,-0.07197169214487076,-0.07160908728837967,-0.07159808278083801,-0.07081911712884903,-0.07030940800905228,-0.06893931329250336,-0.06775594502687454,-0.06617354601621628,-0.06433242559432983,-0.06198159232735634,-0.061948928982019424,-0.0613592192530632,-0.06094979867339134,-0.060751840472221375,-0.060736242681741714,-0.06019546836614609,-0.05977337062358856,-0.058833394199609756,-0.057542987167835236,-0.05634387955069542,-0.0550362765789032,-0.05311470851302147,-0.05252769589424133,-0.05184941738843918,-0.0500471405684948,-0.04976434260606766,-0.049106236547231674,-0.048278674483299255,-0.04762961342930794,-0.04663094878196716,-0.04571275785565376,-0.04221315681934357,-0.04201802611351013,-0.04082247242331505,-0.04073126241564751,-0.04063606634736061,-0.04023699834942818,-0.039953943341970444,-0.03976699709892273,-0.03941049054265022,-0.03908085078001022,-0.038581833243370056,-0.03848854452371597,-0.038258325308561325,-0.03777540847659111,-0.03759988024830818,-0.03696797415614128,-0.0363992415368557,-0.035967640578746796,-0.03589256852865219,-0.03531726822257042,-0.034774020314216614,-0.0344928614795208,-0.034155480563640594,-0.033917177468538284,-0.03264421597123146,-0.03249545395374298,-0.03232469782233238,-0.032237403094768524,-0.03187809884548187,-0.03181319311261177,-0.03168310225009918,-0.031031040474772453,-0.030790459364652634,-0.030785996466875076,-0.030671317130327225,-0.030164461582899094,-0.029968757182359695,-0.02996550314128399,-0.029911672696471214,-0.029804544523358345,-0.029715681448578835,-0.029617827385663986,-0.02957647107541561,-0.029384005814790726,-0.029360173270106316,-0.029316993430256844,-0.02920841984450817,-0.029019711539149284,-0.028702741488814354,-0.02864602580666542,-0.02836158499121666,-0.027373602613806725,-0.026839962229132652,-0.02625923417508602,-0.025828585028648376,-0.025636933743953705,-0.02552216500043869,-0.025084316730499268,-0.025081640109419823,-0.024863241240382195,-0.02428814023733139,-0.024218285456299782,-0.024188583716750145,-0.024102065712213516,-0.023997869342565536,-0.023384222760796547,-0.022902019321918488,-0.022826408967375755,-0.02282087877392769,-0.022530803456902504,-0.022008344531059265,-0.021879538893699646,-0.021871821954846382,-0.021149413660168648,-0.02094372920691967,-0.020729122683405876,-0.020447388291358948,-0.02018900215625763,-0.019854513928294182,-0.019854018464684486,-0.01958015188574791,-0.019561029970645905,-0.019444596022367477,-0.019242167472839355,-0.019185248762369156,-0.018956167623400688,-0.018925698474049568,-0.018808316439390182,-0.018757928162813187,-0.018679285421967506,-0.01863439381122589,-0.018618380650877953,-0.01849464140832424,-0.018332449719309807,-0.018228234723210335,-0.018006790429353714,-0.018000125885009766,-0.017978735268115997,-0.01794346049427986,-0.01794176548719406,-0.017723137512803078,-0.017013797536492348,-0.016793295741081238,-0.0167750995606184,-0.016711972653865814,-0.016244584694504738,-0.01621387153863907,-0.016080671921372414,-0.016004571691155434,-0.015927104279398918,-0.015896260738372803,-0.015706274658441544,-0.015490405261516571,-0.015477814711630344,-0.01545292604714632,-0.015250925906002522,-0.014943605288863182,-0.01468489971011877,-0.014624452218413353,-0.01451204065233469,-0.014446395449340343,-0.014302403666079044,-0.01424639206379652,-0.014176270924508572,-0.014062056317925453,-0.014015666209161282,-0.013933271169662476,-0.013851986266672611,-0.013762661255896091,-0.013726795092225075,-0.013454845175147057,-0.013413190841674805,-0.01332442183047533,-0.013193807564675808,-0.013057981617748737,-0.013014961034059525,-0.012694556266069412,-0.01257840171456337,-0.012459982186555862,-0.012341822497546673,-0.012281227856874466,-0.012259301729500294,-0.01217062957584858,-0.012111022137105465,-0.01193193532526493,-0.011667277663946152,-0.011572449468076229,-0.011567744426429272,-0.01154563669115305,-0.011513919569551945,-0.01150061096996069,-0.011405291967093945,-0.011383313685655594,-0.011308846063911915,-0.01129306759685278,-0.011093289591372013,-0.011042234487831593,-0.010825100354850292,-0.010807491838932037,-0.01080529484897852,-0.010790646076202393,-0.010675075463950634,-0.01067272387444973,-0.010662514716386795,-0.010477188043296337,-0.010470135137438774,-0.01045744214206934,-0.010228118859231472,-0.010206351056694984,-0.010126249864697456,-0.010025960393249989,-0.00999760627746582,-0.00982979591935873,-0.009762161411345005,-0.00973304733633995,-0.009723467752337456,-0.009697678498923779,-0.009696094319224358,-0.009661795571446419,-0.009433326311409473,-0.009331101551651955,-0.009299499914050102,-0.009224130772054195,-0.009218418039381504,-0.009164886549115181,-0.00913022831082344,-0.00904062483459711,-0.009015902876853943,-0.008972116746008396,-0.008927102200686932,-0.008925190195441246,-0.008907021954655647,-0.008815331384539604,-0.008719339966773987,-0.00869323406368494,-0.008685894310474396,-0.008658829145133495,-0.008537065237760544,-0.008531667292118073,-0.008495047688484192,-0.008343972265720367,-0.008243147283792496,-0.008213785476982594,-0.008194959722459316,-0.0081560667604208,-0.008128251880407333,-0.008044559508562088,-0.008041712455451488,-0.00799473188817501,-0.007685153279453516,-0.007681755814701319,-0.007648074999451637,-0.007636813446879387,-0.007605729624629021,-0.007596391253173351,-0.00759083591401577,-0.007581167388707399,-0.007548528723418713,-0.007502168882638216,-0.0074759311974048615,-0.007434219121932983,-0.007354095112532377,-0.00735109020024538,-0.00724439462646842,-0.007219257298856974,-0.007213020697236061,-0.007212752476334572,-0.007191626355051994,-0.007177838124334812,-0.007160721346735954,-0.0071399034932255745,-0.007124718278646469,-0.007086020894348621,-0.007049298845231533,-0.007033593486994505,-0.007030907087028027,-0.0069647585041821,-0.00696113845333457,-0.006939542479813099,-0.006936122663319111,-0.006923149339854717,-0.006921317428350449,-0.0068473513238132,-0.006820701528340578,-0.00681297667324543,-0.006747007369995117,-0.006727464031428099,-0.0066796583123505116,-0.006669858004897833,-0.006634123157709837,-0.006508722901344299,-0.006452718749642372,-0.006300526205450296,-0.006294062361121178,-0.006278038024902344,-0.006272680126130581,-0.006270368583500385,-0.006261568516492844,-0.006215333938598633,-0.0062103234231472015,-0.006191783584654331,-0.0061572534032166,-0.006143924780189991,-0.006124334875494242,-0.006124293431639671,-0.006122132763266563,-0.0060995882377028465,-0.006099065765738487,-0.006086510606110096,-0.0060772462747991085,-0.006076924968510866,-0.005979184526950121,-0.005961226765066385,-0.005925532430410385,-0.005920597817748785,-0.00591902993619442,-0.005907748825848103,-0.005906706675887108,-0.005879454780369997,-0.005800743121653795,-0.005752046126872301,-0.005743826739490032,-0.005688611418008804,-0.005677068140357733,-0.005671005230396986,-0.005655778106302023,-0.005641319788992405,-0.00562943983823061,-0.005614100489765406,-0.005613828077912331,-0.0056055509485304356,-0.005539119243621826,-0.005478414706885815,-0.005414049606770277,-0.0053803338669240475,-0.0053803157061338425,-0.005358549766242504,-0.005356869660317898,-0.005345050245523453,-0.005331980064511299,-0.00531347980722785,-0.00531150633469224,-0.005306554958224297,-0.005303023848682642,-0.005272751674056053,-0.005227091256529093,-0.005215184763073921,-0.005156885366886854,-0.005083037074655294,-0.005040182266384363,-0.005036765243858099,-0.004966069012880325,-0.00495171919465065,-0.004939587786793709,-0.004937955643981695,-0.004879070911556482,-0.0048723299987614155,-0.004744755104184151,-0.004730605985969305,-0.00472688116133213,-0.004715141840279102,-0.004691231995820999,-0.00468369759619236,-0.004659709054976702,-0.004607351031154394,-0.0045681362971663475,-0.004520314745604992,-0.004435269627720118,-0.004428790416568518,-0.00440722331404686,-0.004367895890027285,-0.004354239907115698,-0.004332416690886021,-0.004278252366930246,-0.004270932171493769,-0.004255315754562616,-0.0042534456588327885,-0.004241346847265959,-0.004227678291499615,-0.004208485130220652,-0.004188077058643103,-0.0041799359023571014,-0.00415864959359169,-0.004089659079909325,-0.004075292497873306,-0.004068298265337944,-0.0040591382421553135,-0.0040499665774405,-0.004045643378049135,-0.004021902568638325,-0.004017415922135115,-0.004006677772849798,-0.003985286690294743,-0.003982846159487963,-0.003980288747698069,-0.0039458810351789,-0.003942990675568581,-0.003939793910831213,-0.0039239008910954,-0.0039197662845253944,-0.003876244183629751,-0.003865346545353532,-0.0038640229031443596,-0.0038594340439885855,-0.0038360273465514183,-0.0038098678924143314,-0.003800776321440935,-0.003788634203374386,-0.003708101576194167,-0.003687457647174597,-0.003671405604109168,-0.0036713259760290384,-0.0036689648404717445,-0.003661355935037136,-0.003629994112998247,-0.003622462972998619,-0.0036179295275360346,-0.0036011915653944016,-0.0035973277408629656,-0.00351085071451962,-0.0035105403512716293,-0.00348622165620327,-0.003479589009657502,-0.003463253378868103,-0.0034446276258677244,-0.00340871955268085,-0.0034013621043413877,-0.0033878814429044724,-0.003366420976817608,-0.00333699700422585,-0.003330606734380126,-0.0033018928952515125,-0.0032951957546174526,-0.003291041823104024,-0.0032757092267274857,-0.0032457036431878805,-0.003211105475202203,-0.0031990057323127985,-0.0031887495424598455,-0.0031718332320451736,-0.0031629649456590414,-0.0031485557556152344,-0.0031419144943356514,-0.0031328555196523666,-0.003115336410701275,-0.0031126635149121284,-0.003106971038505435,-0.0031025907956063747,-0.0031011318787932396,-0.003063854295760393,-0.003032349282875657,-0.0030303692910820246,-0.0030155875720083714,-0.0029857230838388205,-0.00296522444114089,-0.0029633715748786926,-0.0029604234732687473,-0.0029501167591661215,-0.0029157944954931736,-0.0029077157378196716,-0.002907088492065668,-0.0028898564632982016,-0.0028782589361071587,-0.0028632087633013725,-0.0028456503059715033,-0.002837671898305416,-0.002830876037478447,-0.0028170740697532892,-0.0028038800228387117,-0.002780927810817957,-0.0027769929729402065,-0.0027685114182531834,-0.00276398379355669,-0.0027568426448851824,-0.0027462083380669355,-0.0027375149074941874,-0.002722910838201642,-0.0027063237503170967,-0.0026874030008912086,-0.0026722121983766556,-0.0026289469096809626,-0.0026101558469235897,-0.0025989776477217674,-0.00259400368668139,-0.002592299599200487,-0.0025813677348196507,-0.0025808466598391533,-0.002547880634665489,-0.0025426095817238092,-0.0025302711874246597,-0.002504779724404216,-0.002482646144926548,-0.002480417722836137,-0.002454684115946293,-0.002446891274303198,-0.0024370308965444565,-0.002427143044769764,-0.0024203904904425144,-0.0023817657493054867,-0.0023647767957299948,-0.002361998660489917,-0.002354852156713605,-0.0023544891737401485,-0.002349438378587365,-0.0023253464605659246,-0.0023024864494800568,-0.002287855837494135,-0.0022719353437423706,-0.0022614856716245413,-0.0022399539593607187,-0.0022345560137182474,-0.002232644474133849,-0.002223473507910967,-0.0022217831574380398,-0.002216905588284135,-0.0022093576844781637,-0.0022081336937844753,-0.0022061667405068874,-0.0021948956418782473,-0.002190768253058195,-0.0021892560180276632,-0.002187397563830018,-0.0021863188594579697,-0.0021758279763162136,-0.0021704586688429117,-0.002163475379347801,-0.0021568730007857084,-0.002155131893232465,-0.0021510524675250053,-0.0021413774229586124,-0.00213979952968657,-0.0021255281753838062,-0.002124910010024905,-0.0021183679345995188,-0.0021098956931382418,-0.0021079310681670904,-0.0021053545642644167,-0.002100314013659954,-0.002097217133268714,-0.002095454139634967,-0.0020688530057668686,-0.002062899526208639,-0.002057277597486973,-0.0020518971141427755,-0.0020291409455239773,-0.0020241362508386374,-0.0020226386841386557,-0.002005138201639056,-0.0020035970956087112,-0.0019924850203096867,-0.001986062154173851,-0.0019715118687599897,-0.0019496351014822721,-0.0019489298574626446,-0.001948326826095581,-0.0019451326224952936,-0.0019408693769946694,-0.001936545828357339,-0.0019273007055744529,-0.0019177885260432959,-0.0019163669785484672,-0.0018774393247440457,-0.0018757727229967713,-0.001875031739473343,-0.0018548381049185991,-0.0018472657538950443,-0.0018313475884497166,-0.0018310094019398093,-0.0018249920103698969,-0.001822402235120535,-0.0017999840201810002,-0.001798821846023202,-0.0017974808579310775,-0.0017974114743992686,-0.0017950836336240172,-0.0017945057479664683,-0.0017893218901008368,-0.0017828989075496793,-0.0017827048432081938,-0.0017341088969260454,-0.0017286204965785146,-0.0017243071924895048,-0.0017181062139570713,-0.001717011327855289,-0.0017002912936732173,-0.0016960183857008815,-0.0016918400069698691,-0.001691201003268361,-0.0016544380923733115,-0.0016479045152664185,-0.001646310673095286,-0.0016432872507721186,-0.0016428816597908735,-0.0016351336380466819,-0.001629226258955896,-0.0016246737213805318,-0.0016142661916092038,-0.0016055394662544131,-0.0015997323207557201,-0.0015955360140651464,-0.0015743892872706056,-0.00155610591173172,-0.0015289372531697154,-0.0015269084833562374,-0.0015175837324932218,-0.001515957061201334,-0.0015088494401425123,-0.0015019166748970747,-0.0014878843212500215,-0.0014803579542785883,-0.0014765841187909245,-0.0014557898975908756,-0.0014519882388412952,-0.001439121668227017,-0.0014293045969679952,-0.001420163200236857,-0.0014087181771174073,-0.0013999039074406028,-0.0013806958450004458,-0.0013751530786976218,-0.0013646212173625827,-0.0013561556115746498,-0.0013470565900206566,-0.0013462849892675877,-0.001343540265224874,-0.001343099633231759,-0.001323025207966566,-0.0013215962098911405,-0.0013213723432272673,-0.001314042485319078,-0.0013077452313154936,-0.0013047239044681191,-0.001293587381951511,-0.001250491593964398,-0.0012438851408660412,-0.0012278205249458551,-0.0012198792537674308,-0.0012136107543483377,-0.0012105563655495644,-0.0012056115083396435,-0.0011994033120572567,-0.0011965582380071282,-0.00119462376460433,-0.0011938316747546196,-0.0011935615912079811,-0.0011783988447859883,-0.0011778634507209063,-0.0011777764884755015,-0.0011777112958952785,-0.0011635995469987392,-0.0011587042827159166,-0.0011574748205021024,-0.0011543513974174857,-0.0011488086311146617,-0.0011424754047766328,-0.0011361301876604557,-0.0011319410987198353,-0.0011253339471295476,-0.0011109384940937161,-0.0011079177493229508,-0.0011079114628955722,-0.0011028415756300092,-0.0010988604044541717,-0.0010980091756209731,-0.0010975010227411985,-0.0010958429193124175,-0.0010953783057630062,-0.0010894759325310588,-0.0010748544009402394,-0.001074466505087912,-0.0010717299301177263,-0.001067302655428648,-0.0010571816237643361,-0.0010539565701037645,-0.001042183954268694,-0.001033769571222365,-0.001024138182401657,-0.0010231167543679476,-0.0010148801375180483,-0.0010147052817046642,-0.0009942993056029081,-0.0009912692476063967,-0.0009850203059613705,-0.0009744216222316027,-0.0009715924388729036,-0.0009593699360266328,-0.0009536540601402521,-0.000950997753534466,-0.0009425090393051505,-0.0009360787225887179,-0.000932268041651696,-0.0009216814651153982,-0.0009184820228256285,-0.000917040859349072,-0.0009066861239261925,-0.0009042077581398189,-0.0009004005696624517,-0.0008891584002412856,-0.000886029505636543,-0.0008834007894620299,-0.0008808348211459816,-0.0008510689367540181,-0.0008387655834667385,-0.0008282076450996101,-0.0008219908340834081,-0.0008211681270040572,-0.0008156815310940146,-0.0008149161003530025,-0.0008148582419380546,-0.0008087804890237749,-0.0007988254074007273,-0.0007963918033055961,-0.000785761745646596,-0.0007780867163091898,-0.0007757863495498896,-0.0007753667887300253,-0.0007737121195532382,-0.0007654292858205736,-0.0007643876015208662,-0.0007608168525621295,-0.0007549897418357432,-0.0007514479220844805,-0.00074827327625826,-0.0007459957851096988,-0.0007406190852634609,-0.0007362786564044654,-0.0007351264357566833,-0.0007325346814468503,-0.0007279980927705765,-0.0007145877461880445,-0.0007103869575075805,-0.0007099399226717651,-0.0007040122873149812,-0.000693676236551255,-0.0006884516915306449,-0.0006855928222648799,-0.000681535922922194,-0.0006802408606745303,-0.000680060067679733,-0.0006586276576854289,-0.0006530517130158842,-0.0006376050878316164,-0.0006315133068710566,-0.0006251569138839841,-0.00060412532184273,-0.0006015670951455832,-0.0005855881609022617,-0.0005841196980327368,-0.000576353573706001,-0.0005729619297198951,-0.0005661587929353118,-0.0005617413553409278,-0.0005528657929971814,-0.0005528000765480101,-0.0005471968906931579,-0.0005421609384939075,-0.0005412010359577835,-0.0005384367541410029,-0.0005367192788980901,-0.0005345821264199913,-0.0005314365844242275,-0.0005288183456286788,-0.0005240996833890676,-0.000517404405400157,-0.0005131415091454983,-0.0005118799163028598,-0.0005101109272800386,-0.0005092330393381417,-0.000508248747792095,-0.0005081556155346334,-0.0005024041747674346,-0.0004887311370112002,-0.00047903283848427236,-0.0004768621874973178,-0.00047471298603340983,-0.00047071659355424345,-0.0004669085028581321,-0.0004668346082326025,-0.00046641455264762044,-0.0004595611244440079,-0.000459547940408811,-0.0004405525978654623,-0.00043163090595044196,-0.0004316243575885892,-0.00042396888602524996,-0.00042241744813509285,-0.0004196298832539469,-0.00041138575761578977,-0.0004081630031578243,-0.00040608749259263277,-0.0004041558422613889,-0.0003976998559664935,-0.00038974531344138086,-0.0003887744969688356,-0.0003855930408462882,-0.0003854079404845834,-0.00037767915637232363,-0.0003742832050193101,-0.0003662148956209421,-0.0003635661269072443,-0.00036253363941796124,-0.00036229260149411857,-0.000358785007847473,-0.00035740085877478123,-0.00035573652712628245,-0.00035554319038055837,-0.0003554127470124513,-0.00035429775016382337,-0.0003493473632261157,-0.0003480395535007119,-0.00034588552080094814,-0.00034581683576107025,-0.0003457000129856169,-0.00034558161860331893,-0.000345532811479643,-0.00034465582575649023,-0.00033951952354982495,-0.0003309854946564883,-0.00032922334503382444,-0.000325152650475502,-0.0003171012504026294,-0.0003165715897921473,-0.00031218939693644643,-0.00031200566445477307,-0.00030620538746006787,-0.0003057688591070473,-0.0003055522684007883,-0.0003054810222238302,-0.0002961180289275944,-0.00029513597837649286,-0.0002897529338952154,-0.0002888846502173692,-0.00028613186441361904,-0.00028596914489753544,-0.00027850308106280863,-0.0002747020043898374,-0.00027301444788463414,-0.00027257108013145626,-0.0002709986292757094,-0.00026248639915138483,-0.0002616957644931972,-0.00025977991754189134,-0.00025967723922804,-0.00025548413395881653,-0.00025466925580985844,-0.0002544855233281851,-0.0002497511450201273,-0.0002489792532287538,-0.00024716026382520795,-0.0002445074205752462,-0.0002389600849710405,-0.00023615159443579614,-0.00023454592155758291,-0.00022782139421906322,-0.00022113911109045148,-0.00021902061416767538,-0.00021729797299485654,-0.0002165959740523249,-0.00021189823746681213,-0.00020986511663068086,-0.00020672679238487035,-0.00020546838641166687,-0.00020361505448818207,-0.00020092129125259817,-0.00019994958711322397,-0.0001995825004996732,-0.00019692041678354144,-0.00019463799253571779,-0.00018779061792884022,-0.0001874017034424469,-0.0001810312969610095,-0.0001795445423340425,-0.00017664700862951577,-0.00017586581816431135,-0.00017286442744079977,-0.00016991994925774634,-0.00016632661572657526,-0.00016615382628515363,-0.00016372457321267575,-0.00016250468615908176,-0.00016196265642065555,-0.0001612178166396916,-0.00016009896353352815,-0.0001599483221070841,-0.0001588730519870296,-0.00015856623940635473,-0.00015703134704381227,-0.000156242327648215,-0.0001545454579172656,-0.00015439830895047635,-0.0001516334741609171,-0.0001506382250227034,-0.00014540806296281517,-0.00014382228255271912,-0.00014153636584524065,-0.0001400209148414433,-0.00013839431630913168,-0.0001288556377403438,-0.0001257871772395447,-0.0001247069303644821,-0.00012403697473928332,-0.00012325093848630786,-0.00012171149137429893,-0.00011743418872356415,-0.00011555053060874343,-0.0001144792913692072,-0.00011383242963347584,-0.00011225052003283054,-0.00011160008580191061,-0.00011018596705980599,-0.00010799542360473424,-0.00010479323827894405,-0.00010172576003242284,-9.756624785950407e-05,-9.707100980449468e-05,-9.70651235547848e-05,-9.358063107356429e-05,-9.32754555833526e-05,-8.904628339223564e-05,-8.894346683518961e-05,-8.642070315545425e-05,-8.301459456561133e-05,-8.186407649191096e-05,-8.12745129223913e-05,-7.410146645270288e-05,-7.399514288408682e-05,-7.140532397897914e-05,-7.093548629200086e-05,-6.926648347871378e-05,-6.754845526302233e-05,-6.561100599355996e-05,-6.179235788295045e-05,-5.998626511427574e-05,-5.994185630697757e-05,-5.914688154007308e-05,-5.7998149713966995e-05,-5.7340563216712326e-05,-5.649603917845525e-05,-5.345046520233154e-05,-5.189925286686048e-05,-5.061231422587298e-05,-5.0295366236241534e-05,-4.992946924176067e-05,-4.8823803808772936e-05,-4.7979949158616364e-05,-4.2220948671456426e-05,-3.6878063838230446e-05,-3.64023435395211e-05,-3.5339446185389534e-05,-3.437466875766404e-05,-3.116727020824328e-05,-3.095820648013614e-05,-2.988502455991693e-05,-2.966061219922267e-05,-2.9108226954122074e-05,-2.3058206352288835e-05,-2.181462878070306e-05,-1.8629953046911396e-05,-1.818284363253042e-05,-1.776538738340605e-05,-1.7385929822921753e-05,-1.6570911611779593e-05,-1.6559810319449753e-05,-1.5149042155826464e-05,-1.4509632819681428e-05,-1.4460087186307646e-05,-1.4292001651483588e-05,-1.3881027371098753e-05,-1.3404786841419991e-05,-1.2323334885877557e-05,-8.825585609884001e-06,-8.063540008151904e-06,-7.087215635692701e-06,-6.681457307422534e-06,-4.9545615183888e-06,-4.233419986121589e-06,-2.796649823721964e-06,-7.366389240814897e-07,-7.164478574850364e-07,0.0,8.002668892004294e-07,4.050731604365865e-06,6.734952421538765e-06,1.1147782061016187e-05,1.1435523447289597e-05,1.3393461813393515e-05,1.3708174265048001e-05,1.4046951946511399e-05,1.4215186638466548e-05,1.4631598787673283e-05,1.7557442333782092e-05,1.7800852219806984e-05,2.2519006961374544e-05,2.361312544962857e-05,2.4175345970434137e-05,2.4643242795718834e-05,2.573542224126868e-05,2.7842297640745528e-05,2.9183551305322908e-05,3.1534804293187335e-05,3.179304258082993e-05,3.4572556614875793e-05,3.716148421517573e-05,3.8871989090694115e-05,3.935925633413717e-05,4.0002763853408396e-05,4.0832088416209444e-05,4.328213617554866e-05,4.386931686894968e-05,4.5060143747832626e-05,4.564054324873723e-05,4.597753286361694e-05,4.698857810581103e-05,4.7482251829933375e-05,4.926405745209195e-05,4.989579247194342e-05,5.391567901824601e-05,5.521997809410095e-05,5.582779704127461e-05,5.692802369594574e-05,5.722947389585897e-05,5.7432280300417915e-05,5.8561341575114056e-05,5.891092223464511e-05,5.944274380453862e-05,6.02535146754235e-05,6.072074029361829e-05,6.104044587118551e-05,6.28268753644079e-05,6.289862358244136e-05,6.536528235301375e-05,6.923526234459132e-05,6.974697316763923e-05,7.433310383930802e-05,7.443822687491775e-05,7.831260882085189e-05,7.920280040707439e-05,7.994063344085589e-05,7.998548244358972e-05,8.129343041218817e-05,8.171617810148746e-05,8.343189983861521e-05,8.34938109619543e-05,8.905515278456733e-05,8.941754640545696e-05,9.52633490669541e-05,0.00010001339251175523,0.00010096959886141121,0.00010185412975260988,0.00010331906378269196,0.00010444469808135182,0.00010447904787724838,0.0001045411845552735,0.00010535068577155471,0.0001061043149093166,0.00010661251872079447,0.0001075852633221075,0.00011177636770298705,0.00011222303146496415,0.00011234231351409107,0.00011285662912996486,0.00011289752728771418,0.00011423096293583512,0.00011701643234118819,0.00011753343278542161,0.00011889383313246071,0.0001243795413756743,0.00013110839063301682,0.00013132400636095554,0.0001334749103989452,0.00013548940478358418,0.00013694704102817923,0.00013694785593543202,0.00013832785771228373,0.00013916046009398997,0.00014135912351775914,0.0001427658717148006,0.0001439788902644068,0.0001456473837606609,0.0001473424636060372,0.00014851719606667757,0.0001493158924859017,0.00015053048264235258,0.00015065408661030233,0.00015349657041952014,0.00015753753541503102,0.00015873178199399263,0.00015984468336682767,0.00016003326163627207,0.00016342759772669524,0.0001639147085370496,0.0001666586904320866,0.0001666708994889632,0.00016872026026248932,0.0001693645172053948,0.00017058319645002484,0.00017074659990612417,0.00017633773677516729,0.00018432595243211836,0.0001851727138273418,0.00018535263370722532,0.0001868042309070006,0.0001874122826848179,0.00018892988737206906,0.0001934730971697718,0.00020765334193129092,0.0002102050930261612,0.00021386667503975332,0.0002150412619812414,0.00021731220476794988,0.00021925225155428052,0.00021957949502393603,0.00022208623704500496,0.00022231892216950655,0.00022330842330120504,0.0002242080809082836,0.00022742077999282628,0.00022788300702814013,0.00023188084014691412,0.00023227476049214602,0.00023684091866016388,0.0002393075847066939,0.00024039186246227473,0.000241936300881207,0.0002458783274050802,0.0002480550901964307,0.0002493122301530093,0.0002495967491995543,0.00025612852186895907,0.00025656670914031565,0.0002599824219942093,0.0002610068768262863,0.00026139573310501873,0.00026352948043495417,0.000266207818640396,0.0002685242216102779,0.00026939145755022764,0.00027269675047136843,0.00027442307327874005,0.0002893928322009742,0.0002917092351708561,0.00029415020253509283,0.00029467715648934245,0.0002962911094073206,0.0002979902783408761,0.00029880955116823316,0.00029915967024862766,0.00030427350429818034,0.0003053162363357842,0.000305918394587934,0.00030690000858157873,0.0003077492874581367,0.0003236150078009814,0.00033399395761080086,0.0003358102694619447,0.00034225263516418636,0.00034626005799509585,0.0003480243613012135,0.0003507059009280056,0.0003547293599694967,0.0003553118440322578,0.0003573609865270555,0.0003585039812605828,0.0003599178744480014,0.0003623547381721437,0.00036291457945480943,0.00036362610990181565,0.0003660483635030687,0.00037511123809963465,0.00037519691977649927,0.0003755459329113364,0.0003757760568987578,0.00037701078690588474,0.0003798144171014428,0.0003806722234003246,0.0003811411443166435,0.0003874936664942652,0.0003928320948034525,0.00039354219916276634,0.0004057207843288779,0.0004086376866325736,0.0004118135548196733,0.00041344098281115294,0.00041686370968818665,0.00042098716949112713,0.0004221854323986918,0.00043043404002673924,0.000436223519500345,0.00043716037180274725,0.0004377820296213031,0.0004383205669000745,0.00044259571586735547,0.00044417299795895815,0.00044863022048957646,0.0004507324192672968,0.00045408791629597545,0.0004600441316142678,0.00046444841427728534,0.00047080114018172026,0.0004710210778284818,0.0004806979850400239,0.000481496739666909,0.00048178009456023574,0.0004830105463042855,0.00048732131836004555,0.00049118377501145,0.0005158609128557146,0.0005243289633654058,0.0005243837949819863,0.0005245222127996385,0.0005268491804599762,0.0005375453038141131,0.0005413307226262987,0.0005415547057054937,0.0005440940149128437,0.0005495590739883482,0.0005583739257417619,0.0005597408744506538,0.0005720716435462236,0.0005850319284945726,0.0005898223025724292,0.0005965124582871795,0.000597480742726475,0.0005998504348099232,0.0006004722672514617,0.0006028147763572633,0.0006067358772270381,0.0006159099866636097,0.0006168434047140181,0.0006174566806294024,0.0006245768163353205,0.0006261335220187902,0.0006266903365030885,0.0006296029896475375,0.0006354890647344291,0.0006373216747306287,0.0006394439260475338,0.000643750827293843,0.00064453249797225,0.0006480859010480344,0.0006512177060358226,0.0006521088071167469,0.0006671979790553451,0.000668656371999532,0.0006706920103169978,0.0006980973412282765,0.0007027474930509925,0.0007110583246685565,0.0007200738764367998,0.0007229199400171638,0.0007309727952815592,0.0007388623198494315,0.0007462839712388813,0.0007476545288227499,0.0007487072143703699,0.0007927344995550811,0.0007983812829479575,0.0007992246537469327,0.0008053072378970683,0.0008085071458481252,0.0008113434887491167,0.0008136288961395621,0.0008224089397117496,0.0008276028092950583,0.0008291522972285748,0.0008312357240356505,0.0008370451396331191,0.0008397501660510898,0.0008400279330089688,0.0008519911207258701,0.0008600287837907672,0.0008668488007970154,0.000867281632963568,0.000869479903485626,0.0008716133888810873,0.0008734610164538026,0.0008741095662117004,0.0008858440560288727,0.0008886541472747922,0.0008890653261914849,0.000896620680578053,0.0008992942166514695,0.0009020875440910459,0.0009080688469111919,0.0009107949445024133,0.0009201786597259343,0.0009217683109454811,0.0009307691361755133,0.0009362048585899174,0.0009377877577207983,0.0009411853388883173,0.0009639731142669916,0.0009683538810350001,0.0009709875448606908,0.000977543881163001,0.0009802845306694508,0.0009804385481402278,0.0009920189622789621,0.0009960774332284927,0.0010061269858852029,0.0010064427042379975,0.001009743777103722,0.001028247526846826,0.0010322782909497619,0.001039251103065908,0.0010472015710547566,0.001061511691659689,0.001068088342435658,0.0010727079352363944,0.0010855505242943764,0.0010890283156186342,0.001089917030185461,0.001090517151169479,0.0011035699862986803,0.001113710692152381,0.0011162637965753675,0.0011194549733772874,0.0011214201804250479,0.0011220057494938374,0.0011256203288212419,0.001136499922722578,0.001138601335696876,0.0011448422446846962,0.0011590396752581,0.0011597884586080909,0.001162622356787324,0.0011759332846850157,0.0011796189937740564,0.001180189661681652,0.0011821617372334003,0.0011838764185085893,0.001189802773296833,0.0012049797223880887,0.001206862274557352,0.001209751470014453,0.0012145796790719032,0.0012205695966258645,0.0012285648845136166,0.001240196987055242,0.0012414338998496532,0.0012419059639796615,0.0012428680201992393,0.0012742184335365891,0.0012778079835698009,0.0012788125313818455,0.0012812891509383917,0.0012843480799347162,0.0013035880401730537,0.0013096737675368786,0.0013298612320795655,0.001346007687970996,0.0013557437341660261,0.0013595527270808816,0.0013656917726621032,0.0013661369448527694,0.00137037574313581,0.001378997229039669,0.0013969498686492443,0.0014036245411261916,0.001408992218784988,0.0014196207048371434,0.0014405453111976385,0.001466951915062964,0.00147634360473603,0.0014775764429941773,0.0014954135986045003,0.001504183397628367,0.0015053717652335763,0.0015081417514011264,0.001512346905656159,0.0015304863918572664,0.0015342915430665016,0.0015349105233326554,0.001538112759590149,0.0015460022259503603,0.0015501823509112,0.0015634873416274786,0.0015832519857212901,0.0015914723044261336,0.0016035852022469044,0.0016148203285411,0.0016168850706890225,0.0016357224667444825,0.0016490513226017356,0.0016637977678328753,0.0016807502834126353,0.0016882381169125438,0.0016996677732095122,0.001727390568703413,0.0017506263684481382,0.0017517692176625133,0.0017750471597537398,0.0017798765329644084,0.0017986397724598646,0.0018048721831291914,0.0018141083419322968,0.0018151372205466032,0.0018170818220824003,0.0018281546654179692,0.0018556412542238832,0.0018606223165988922,0.0018615232547745109,0.0018848134204745293,0.0019014716381207108,0.0019120455253869295,0.001914151944220066,0.0019191104220226407,0.0019216351211071014,0.0019307882757857442,0.0019435916328802705,0.0019458711612969637,0.0019521553767845035,0.0019627695437520742,0.0019694408401846886,0.0019786094781011343,0.0019974804017692804,0.00199978263117373,0.0020039016380906105,0.0020047309808433056,0.002004855079576373,0.0020079067908227444,0.002010058145970106,0.0020161832217127085,0.0020200926810503006,0.0020263607148081064,0.0020340692717581987,0.0020365812815725803,0.0020417221821844578,0.0020516342483460903,0.002055560238659382,0.002062107902020216,0.002063297899439931,0.0020661852322518826,0.0020799273625016212,0.0020875423215329647,0.002099074423313141,0.0021124794147908688,0.0021130621898919344,0.00212849210947752,0.0021466785110533237,0.0021488030906766653,0.0021537470165640116,0.0021662809886038303,0.0021697941701859236,0.002177224960178137,0.002179314149543643,0.00217963894829154,0.0021880888380110264,0.0021953703835606575,0.002200411632657051,0.00220907898619771,0.0022308318875730038,0.0022329026833176613,0.002242262475192547,0.0022462543565779924,0.0022467700764536858,0.002256215550005436,0.0022818157449364662,0.002285878174006939,0.002294200472533703,0.0022989145945757627,0.002334239427000284,0.002350522205233574,0.002362847328186035,0.0023735605645924807,0.0023739889729768038,0.0023947253357619047,0.0024117135908454657,0.0024249767884612083,0.00243147904984653,0.002431547036394477,0.0024548841174691916,0.0024562114849686623,0.0024644171353429556,0.0024816340301185846,0.0024818642996251583,0.00248707109130919,0.0025145357940346003,0.00252338033169508,0.0025257340166717768,0.0025266725569963455,0.0025540804490447044,0.0025666377041488886,0.002594838384538889,0.0025950127746909857,0.002597060287371278,0.002610087627544999,0.002620683517307043,0.0026237070560455322,0.0026280826423317194,0.002629185328260064,0.002629917813464999,0.002633559750393033,0.002651458140462637,0.0026949080638587475,0.002714982256293297,0.0027445172891020775,0.002745462581515312,0.002748563652858138,0.00274977320805192,0.002757150446996093,0.002771079773083329,0.002783915027976036,0.0027969360817223787,0.0028015882708132267,0.0028262054547667503,0.0028594324830919504,0.002862284891307354,0.0028625684790313244,0.0028700754046440125,0.0028770086355507374,0.0028823520988225937,0.0029196261893957853,0.002922633895650506,0.002951416652649641,0.002952591283246875,0.0029543854761868715,0.003010183572769165,0.0030143531039357185,0.003023371798917651,0.0030330114532262087,0.0030358671210706234,0.003036058507859707,0.003050358034670353,0.003077874891459942,0.0030975162517279387,0.0031011151149868965,0.0031188977882266045,0.0031190107110887766,0.003121773712337017,0.0031342110596597195,0.0031592941377311945,0.003168074879795313,0.0031708981841802597,0.0031856982968747616,0.0032000592909753323,0.0032008627895265818,0.003217901336029172,0.00324191153049469,0.003260959405452013,0.0033199028111994267,0.0033276393078267574,0.0033493489027023315,0.003359189722687006,0.0033863920252770185,0.003461466170847416,0.0035050222650170326,0.003535276046022773,0.0035379095934331417,0.0035512663889676332,0.0035620492417365313,0.0035836913157254457,0.00359646906144917,0.0036007326561957598,0.003605030244216323,0.0036270807031542063,0.003670125501230359,0.003674744628369808,0.003711536293849349,0.0037134280428290367,0.0037324042059481144,0.0037452206015586853,0.0037766387686133385,0.003784359898418188,0.003835017327219248,0.0038767859805375338,0.003886015620082617,0.0038867308758199215,0.003916642628610134,0.003974258434027433,0.003987787291407585,0.003998270723968744,0.004027650225907564,0.004035704303532839,0.004042783286422491,0.004043768625706434,0.004068727605044842,0.004146830644458532,0.004148240201175213,0.0041561429388821125,0.004165693651884794,0.004207032732665539,0.004227726254612207,0.004275173414498568,0.0042813862673938274,0.004291051533073187,0.004304279573261738,0.004350852221250534,0.004384966101497412,0.0043907081708312035,0.004426937084645033,0.004492109641432762,0.004503910895437002,0.0045339991338551044,0.0045578633435070515,0.004603844601660967,0.004608366638422012,0.00462010782212019,0.004636249039322138,0.004660469479858875,0.004665798507630825,0.004762690979987383,0.004764620214700699,0.0048402417451143265,0.004864672664552927,0.004880914930254221,0.0048860968090593815,0.004911710508167744,0.004960862919688225,0.004963572137057781,0.00496970908716321,0.0049852291122078896,0.004999297671020031,0.005031667184084654,0.005050921346992254,0.005084586329758167,0.005086855962872505,0.0051031531766057014,0.005149556789547205,0.005152596160769463,0.0051809861324727535,0.005234807729721069,0.005279651843011379,0.0052937413565814495,0.005311093758791685,0.005339400842785835,0.005342505406588316,0.005391580983996391,0.005445405840873718,0.0054654572159051895,0.005475538782775402,0.005514731630682945,0.005616537295281887,0.005619901232421398,0.005632977932691574,0.005656576249748468,0.005698455031961203,0.005739908199757338,0.00576259009540081,0.005850724410265684,0.006048764102160931,0.006079645361751318,0.006080723367631435,0.006084603723138571,0.006140191573649645,0.006143208127468824,0.0061691938899457455,0.006194193847477436,0.006202070042490959,0.006232819985598326,0.00623514037579298,0.006271668244153261,0.006292931269854307,0.006293509621173143,0.006321480497717857,0.0063314842991530895,0.006334854289889336,0.0063436138443648815,0.006388988345861435,0.006391364149749279,0.006410473026335239,0.006418708711862564,0.0064316364005208015,0.006485715974122286,0.00651210593059659,0.006536089815199375,0.006546104326844215,0.0065640658140182495,0.006612466648221016,0.006633666809648275,0.006639736704528332,0.0066528613679111,0.0066910479217767715,0.006698066368699074,0.0068189711309969425,0.006831911858171225,0.006847217679023743,0.00689142569899559,0.006911401636898518,0.006961409002542496,0.006999343633651733,0.007063701283186674,0.007091598119586706,0.007096580229699612,0.007097180001437664,0.007142032962292433,0.007155218627303839,0.007158149033784866,0.007190151140093803,0.007244769483804703,0.007245509419590235,0.007250976748764515,0.007277367170900106,0.007360848132520914,0.007371771149337292,0.007418057415634394,0.007436064071953297,0.007460140157490969,0.0074643660336732864,0.0074715036898851395,0.007490923628211021,0.007503241300582886,0.007543030194938183,0.0075470078736543655,0.00761276762932539,0.007625913713127375,0.007639601361006498,0.007687425706535578,0.007707742974162102,0.007709198631346226,0.007793894037604332,0.007797451689839363,0.007818211801350117,0.007884928025305271,0.007943715900182724,0.007949767634272575,0.007950324565172195,0.007985969074070454,0.008007588796317577,0.008010325953364372,0.008015075698494911,0.008037757128477097,0.008051219396293163,0.00806689728051424,0.00809546560049057,0.008101445622742176,0.008216269314289093,0.008285777643322945,0.00828606728464365,0.00833782460540533,0.008342960849404335,0.00846833549439907,0.00850224494934082,0.00853675790131092,0.008672351948916912,0.008689651265740395,0.008689673617482185,0.00869055651128292,0.008748598396778107,0.008759444579482079,0.008823827840387821,0.008834904059767723,0.008870107121765614,0.009085963480174541,0.009096739813685417,0.009211133234202862,0.00923632737249136,0.009271143935620785,0.009340439923107624,0.009411541745066643,0.00947606936097145,0.009503656066954136,0.009566497057676315,0.009754212573170662,0.009966551326215267,0.009969127364456654,0.010021470487117767,0.010049493052065372,0.01005534641444683,0.0101252980530262,0.010256800800561905,0.010385436937212944,0.01045316457748413,0.010509831830859184,0.010537445545196533,0.0105698611587286,0.010598226450383663,0.010650291107594967,0.010782196186482906,0.010790104977786541,0.010902554728090763,0.010918224230408669,0.010982153005897999,0.01098902802914381,0.01101736817508936,0.011064550839364529,0.011068522930145264,0.011298225261271,0.01133827492594719,0.011354544200003147,0.011452560313045979,0.011500680819153786,0.011500997468829155,0.011541834101080894,0.011610827408730984,0.011632928624749184,0.011658888310194016,0.01170214544981718,0.011823265813291073,0.011839437298476696,0.011907126754522324,0.01193301659077406,0.012021281756460667,0.012074373662471771,0.012079374864697456,0.012219014577567577,0.01225709542632103,0.012311849743127823,0.012313175946474075,0.01233120821416378,0.01250116340816021,0.012524031102657318,0.012554973363876343,0.01270865648984909,0.012810178101062775,0.012885472737252712,0.012889832258224487,0.012908675707876682,0.013053719885647297,0.013224247843027115,0.013260425068438053,0.013363697566092014,0.01341976597905159,0.013452982529997826,0.013471542857587337,0.013496403582394123,0.01351679116487503,0.013522517867386341,0.013551683165133,0.01357248518615961,0.013642250560224056,0.01365816593170166,0.013718494214117527,0.01376295369118452,0.013852918520569801,0.013874147087335587,0.014022910967469215,0.014266767539083958,0.014277982525527477,0.01462479867041111,0.014637456275522709,0.01469329372048378,0.014760497026145458,0.01482645608484745,0.014835779555141926,0.014842825941741467,0.014855650253593922,0.014945285394787788,0.015137165784835815,0.01570782996714115,0.01577310636639595,0.015797292813658714,0.01593588851392269,0.016078421846032143,0.016198908910155296,0.016504203900694847,0.01674121432006359,0.016836104914546013,0.016976041719317436,0.017193647101521492,0.017303064465522766,0.017425958067178726,0.017557092010974884,0.017566809430718422,0.017840228974819183,0.017888784408569336,0.017914915457367897,0.018083442002534866,0.018392033874988556,0.018505478277802467,0.018627556040883064,0.018642213195562363,0.01870586909353733,0.01875094696879387,0.018774904310703278,0.018804050981998444,0.019001485779881477,0.019599251449108124,0.019622081890702248,0.019635776057839394,0.019709564745426178,0.019870080053806305,0.019892027601599693,0.020030427724123,0.020111456513404846,0.020139602944254875,0.020413588732481003,0.020463882014155388,0.020497800782322884,0.020685477182269096,0.020921193063259125,0.021115493029356003,0.021253567188978195,0.021608224138617516,0.021673642098903656,0.021886205300688744,0.022003965452313423,0.0223154928535223,0.022835183888673782,0.023100197315216064,0.023137051612138748,0.023372337222099304,0.023457832634449005,0.02374093607068062,0.023878188803792,0.024357866495847702,0.02458859421312809,0.024675238877534866,0.024905188009142876,0.02504732646048069,0.02509993128478527,0.025180211290717125,0.025419089943170547,0.025580719113349915,0.025643154978752136,0.025857161730527878,0.026382265612483025,0.026906883344054222,0.027369249612092972,0.027409248054027557,0.027969324961304665,0.028168363496661186,0.02845933847129345,0.028762195259332657,0.029214849695563316,0.02940184995532036,0.029454078525304794,0.029510997235774994,0.029636887833476067,0.03007490560412407,0.030218688771128654,0.03040514513850212,0.03050341084599495,0.030783317983150482,0.03147859871387482,0.031501539051532745,0.03206895291805267,0.03232051059603691,0.03236355632543564,0.03254389390349388,0.0332169309258461,0.03326242044568062,0.03342943266034126,0.03374241292476654,0.03420063108205795,0.03450401872396469,0.03454160317778587,0.03466413915157318,0.03471614792943001,0.03484904393553734,0.035060204565525055,0.035102467983961105,0.0353146567940712,0.03737941011786461,0.03924662247300148,0.03938017785549164,0.03955567255616188,0.03988164663314819,0.040504492819309235,0.040836501866579056,0.04180335998535156,0.04266800731420517,0.042951229959726334,0.04424745962023735,0.044931910932064056,0.045272644609212875,0.045280374586582184,0.04552432522177696,0.04570765048265457,0.045937176793813705,0.04615875333547592,0.04630977660417557,0.04633462429046631,0.0471855029463768,0.04749879240989685,0.04773575812578201,0.04913923144340515,0.049316033720970154,0.04961417242884636,0.0499088428914547,0.05019886791706085,0.050744980573654175,0.05171283707022667,0.05201854556798935,0.05527930334210396,0.055558089166879654,0.05760456249117851,0.05846632644534111,0.05936698988080025,0.059614840894937515,0.059860773384571075,0.06082988157868385,0.06149272620677948,0.061942070722579956,0.06307313591241837,0.06538500636816025,0.06557045876979828,0.0661587119102478,0.0684613361954689,0.06960518658161163,0.0711253434419632,0.07212093472480774,0.07213763147592545,0.07288976013660431,0.07292075455188751,0.0752788558602333,0.0755656510591507,0.07866434752941132,0.08045496791601181,0.08128805458545685,0.08255424350500107,0.08258137851953506,0.08617021888494492,0.08726006746292114,0.0889873132109642,0.09137321263551712,0.09490149468183517,0.09521035850048065,0.09529604017734528,0.09530581533908844,0.09821169078350067,0.10019844770431519,0.10734996199607849,0.10755890607833862,0.11011957377195358,0.1118309423327446,0.11984079331159592,0.12117645144462585,0.12550115585327148,0.1306990087032318,0.13828527927398682,0.14099420607089996,0.15214803814888,0.1576552838087082,0.17120996117591858,0.17183008790016174,0.17933247983455658,0.18561333417892456,0.2029632180929184,0.21635384857654572,0.23558074235916138],\"yaxis\":\"y\",\"type\":\"scattergl\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Neuron\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Loss change\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Loss change from ablating MLP5 neuron\"},\"width\":800},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('50474075-57e1-4a03-b14e-1b7606c91f23');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sorted_means, indices = torch.sort(diffs.mean(1))\n",
    "sorted_means = sorted_means.tolist()\n",
    "haystack_utils.line(sorted_means, xlabel=\"Neuron\", ylabel=\"Loss change\", title=\"Loss change from ablating MLP5 neuron\") # xticks=indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>                            <div id=\"48d3a7be-726c-4cf2-9721-6f42e3bcfb1d\" class=\"plotly-graph-div\" style=\"height:525px; width:1000px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"48d3a7be-726c-4cf2-9721-6f42e3bcfb1d\")) {                    Plotly.newPlot(                        \"48d3a7be-726c-4cf2-9721-6f42e3bcfb1d\",                        [{\"error_y\":{\"array\":[1.6655507142346149],\"type\":\"data\",\"visible\":true},\"name\":\"Original\",\"x\":[\"Original\"],\"y\":[1.8023502999544143],\"type\":\"bar\"},{\"error_y\":{\"array\":[2.2257524672876285],\"type\":\"data\",\"visible\":true},\"name\":\"Ablated\",\"x\":[\"Ablated\"],\"y\":[3.8644343587756156],\"type\":\"bar\"},{\"error_y\":{\"array\":[1.621827029108629],\"type\":\"data\",\"visible\":true},\"name\":\"MLP5 path patched\",\"x\":[\"MLP5 path patched\"],\"y\":[2.3167209704965352],\"type\":\"bar\"},{\"error_y\":{\"array\":[2.101963799788163],\"type\":\"data\",\"visible\":true},\"name\":\"MLP5 path patched + Top 10 MLP5 neurons ablated\",\"x\":[\"Top MLP5 removed\"],\"y\":[4.3831431472301485],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.8868366713391991],\"type\":\"data\",\"visible\":true},\"name\":\"MLP5 path patched + Bottom 10 MLP5 neurons ablated\",\"x\":[\"Bottom MLP5 removed\"],\"y\":[0.6417470578011125],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"Average last token loss when removing top \\u002f bottom neurons from path patching\"},\"xaxis\":{\"title\":{\"text\":\"\"}},\"yaxis\":{\"title\":{\"text\":\"Loss\"}},\"barmode\":\"group\",\"width\":1000},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('48d3a7be-726c-4cf2-9721-6f42e3bcfb1d');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check loss change when ablating top / bottom neurons\n",
    "\n",
    "top_neurons_count = 10\n",
    "top_neurons = indices[-top_neurons_count:]\n",
    "bottom_neurons = indices[:top_neurons_count]\n",
    "\n",
    "with model.hooks(deactivate_neurons_fwd_hooks):\n",
    "    ablated_loss, ablated_cache = model.run_with_cache(prompts, return_type=\"loss\")\n",
    "\n",
    "ablate_top_neurons_hook = get_ablate_neurons_hook(top_neurons, ablated_cache)\n",
    "ablate_bottom_neurons_hook = get_ablate_neurons_hook(bottom_neurons, ablated_cache)\n",
    "\n",
    "original_loss, ablated_loss, _, all_MLP5_loss = haystack_utils.get_direct_effect(prompts, model, pos=-1, context_ablation_hooks=deactivate_neurons_fwd_hooks, context_activation_hooks=activate_neurons_fwd_hooks)\n",
    "_, _, _, top_MLP5_ablated_loss = haystack_utils.get_direct_effect(prompts, model, pos=-1, context_ablation_hooks=deactivate_neurons_fwd_hooks, context_activation_hooks=activate_neurons_fwd_hooks+ablate_top_neurons_hook)\n",
    "_, _, _, bottom_MLP5_ablated_loss = haystack_utils.get_direct_effect(prompts, model, pos=-1, context_ablation_hooks=deactivate_neurons_fwd_hooks, context_activation_hooks=activate_neurons_fwd_hooks+ablate_bottom_neurons_hook)\n",
    "\n",
    "names = [\"Original\", \"Ablated\", \"MLP5 path patched\", f\"MLP5 path patched + Top {top_neurons_count} MLP5 neurons ablated\", f\"MLP5 path patched + Bottom {top_neurons_count} MLP5 neurons ablated\"]\n",
    "short_names = [\"Original\", \"Ablated\", \"MLP5 path patched\", f\"Top MLP5 removed\", f\"Bottom MLP5 removed\"]\n",
    "\n",
    "values = [original_loss.tolist(), ablated_loss.tolist(), all_MLP5_loss.tolist(), top_MLP5_ablated_loss.tolist(), bottom_MLP5_ablated_loss.tolist()]\n",
    "haystack_utils.plot_barplot(values, names, short_names=short_names, ylabel=\"Loss\", title=f\"Average last token loss when removing top / bottom neurons from path patching\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate top / bottom neuron boosts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patch in MLP5 neurons, ablated bottom neurons, compare with patched MLP5 neurons without ablating bottom neurons\n",
    "\n",
    "with model.hooks(deactivate_neurons_fwd_hooks):\n",
    "    ablated_logits, ablated_cache = model.run_with_cache(prompts)\n",
    "\n",
    "ablate_top_neurons_hook = get_ablate_neurons_hook(top_neurons, ablated_cache)\n",
    "ablate_bottom_neurons_hook = get_ablate_neurons_hook(bottom_neurons, ablated_cache)\n",
    "\n",
    "original_logits, ablated_logprobs, _, all_MLP5_logprobs = haystack_utils.get_direct_effect(prompts, model, pos=-2, context_ablation_hooks=deactivate_neurons_fwd_hooks, context_activation_hooks=activate_neurons_fwd_hooks, return_type='logprobs')\n",
    "_, _, _, top_MLP5_ablated_logprobs = haystack_utils.get_direct_effect(prompts, model, pos=-2, context_ablation_hooks=deactivate_neurons_fwd_hooks, context_activation_hooks=activate_neurons_fwd_hooks+ablate_top_neurons_hook, return_type='logprobs')\n",
    "_, _, _, bottom_MLP5_ablated_logprobs = haystack_utils.get_direct_effect(prompts, model, pos=-2, context_ablation_hooks=deactivate_neurons_fwd_hooks, context_activation_hooks=activate_neurons_fwd_hooks+ablate_bottom_neurons_hook, return_type='logprobs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_difference_neurons(baseline_logprobs, ablated_logprops, positive=True, logprob_threshold=-7, k=50):\n",
    "    neuron_logprob_difference = (baseline_logprobs - ablated_logprops).mean(0)\n",
    "    neuron_logprob_difference[baseline_logprobs.mean(0) < logprob_threshold] = 0\n",
    "    if positive:\n",
    "        non_zero_count = (neuron_logprob_difference > 0).sum()\n",
    "    else:\n",
    "        non_zero_count = (neuron_logprob_difference < 0).sum()\n",
    "    top_logprob_difference, top_neurons = haystack_utils.top_k_with_exclude(neuron_logprob_difference, min(non_zero_count, k), all_ignore, largest=positive)\n",
    "    return top_logprob_difference, top_neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boosted tokens\n",
    "bottom_neuron_pos_difference_logprobs, bottom_pos_indices = get_top_difference_neurons(all_MLP5_logprobs, bottom_MLP5_ablated_logprobs, positive=True)\n",
    "top_neuron_pos_difference_logprobs, top_pos_indices = get_top_difference_neurons(all_MLP5_logprobs, top_MLP5_ablated_logprobs, positive=True)\n",
    "# Deboosted tokens\n",
    "bottom_neuron_neg_difference_logprobs, bottom_neg_indices = get_top_difference_neurons(all_MLP5_logprobs, bottom_MLP5_ablated_logprobs, positive=False)\n",
    "top_neuron_neg_difference_logprobs, top_neg_indices = get_top_difference_neurons(all_MLP5_logprobs, top_MLP5_ablated_logprobs, positive=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "998816ce496d4a75b902587ccbbec7ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Tokens:', options=('Boosted', 'Deboosted'), value='Boosted'), Drop…"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def plot_data(boosted_deboosted, top_bottom):\n",
    "    if boosted_deboosted == 'Boosted' and top_bottom == 'Top':\n",
    "        logprobs = top_neuron_pos_difference_logprobs\n",
    "        indices = top_pos_indices\n",
    "        title_change = 'increase'\n",
    "    elif boosted_deboosted == 'Boosted' and top_bottom == 'Bottom':\n",
    "        logprobs = bottom_neuron_pos_difference_logprobs\n",
    "        indices = bottom_pos_indices\n",
    "        title_change = 'increase'\n",
    "    elif boosted_deboosted == 'Deboosted' and top_bottom == 'Top':\n",
    "        logprobs = top_neuron_neg_difference_logprobs\n",
    "        indices = top_neg_indices\n",
    "        title_change = 'decrease'\n",
    "    else:  # 'Deboosted' and 'Bottom'\n",
    "        logprobs = bottom_neuron_neg_difference_logprobs\n",
    "        indices = bottom_neg_indices\n",
    "        title_change = 'decrease'\n",
    "\n",
    "    xlabel = boosted_deboosted + \" tokens\"\n",
    "    ylabel = \"full_logprob - ablated_logprop\"\n",
    "    title = 'Logprob ' + title_change + ' from ' + top_bottom.lower() + ' neurons'\n",
    "    xticks = [model.to_str_tokens([i])[0] for i in indices]\n",
    "\n",
    "    haystack_utils.line(logprobs.cpu().numpy(), xlabel=xlabel, ylabel=ylabel, title=title, xticks=xticks, show_legend=False)\n",
    "\n",
    "\n",
    "boosted_deboosted = widgets.Dropdown(options=['Boosted', 'Deboosted'], value='Boosted', description='Tokens:')\n",
    "top_bottom = widgets.Dropdown(options=['Top', 'Bottom'], value='Top', description='Neurons:')\n",
    "widgets.interactive(plot_data, boosted_deboosted=boosted_deboosted, top_bottom=top_bottom)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decompose neuron effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get logprob change for individual neuron\n",
    "\n",
    "def get_individual_neuron_logprob_effect(sorted_indices, neuron_pos=0, top=True, positive=True):\n",
    "    if top:\n",
    "        neurons = sorted_indices[-(neuron_pos+1)]\n",
    "    else:\n",
    "        neurons = sorted_indices[neuron_pos]\n",
    "    neurons_hook = get_ablate_neurons_hook([neurons], ablated_cache)\n",
    "\n",
    "    original_logits, ablated_logprobs, _, all_MLP5_logprobs = haystack_utils.get_direct_effect(prompts, model, pos=-2, context_ablation_hooks=deactivate_neurons_fwd_hooks, context_activation_hooks=activate_neurons_fwd_hooks, return_type='logprobs')\n",
    "    _, _, _, neuron_ablated_logprobs = haystack_utils.get_direct_effect(prompts, model, pos=-2, context_ablation_hooks=deactivate_neurons_fwd_hooks, context_activation_hooks=activate_neurons_fwd_hooks+neurons_hook, return_type='logprobs')\n",
    "    neuron_difference_logprobs, difference_indices = \\\n",
    "        get_top_difference_neurons(all_MLP5_logprobs, neuron_ablated_logprobs, positive=positive)\n",
    "    \n",
    "    if positive:\n",
    "        xlabel = 'Boosted tokens'\n",
    "        title = 'Logprob increase from neuron ' + str(neurons.item())\n",
    "    else: \n",
    "        xlabel = 'Deboosted tokens'\n",
    "        title = 'Logprob decrease from neuron ' + str(neurons.item())\n",
    "    if top:\n",
    "        title += f' (top {neuron_pos+1} neuron)'\n",
    "    else:\n",
    "        title += f' (bottom {neuron_pos+1} neuron)'\n",
    "\n",
    "    xticks = [model.to_str_tokens([i])[0] for i in difference_indices]\n",
    "    haystack_utils.line(neuron_difference_logprobs.cpu().numpy(), xlabel=xlabel, ylabel=\"full_logprob - ablated_logprop\", title=title, xticks=xticks, show_legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e112689c0b3b4fb4a89d6eefa4692ee4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='Neuron Pos:', max=20), Dropdown(description='Neurons:', …"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a function to call your function with widget inputs\n",
    "def plot_individual_neuron(neuron_pos, top_bottom, pos_neg):\n",
    "    top_bool = True if top_bottom == 'Top' else False\n",
    "    positive_bool = True if pos_neg == 'Positive' else False\n",
    "    get_individual_neuron_logprob_effect(indices, neuron_pos=neuron_pos, top=top_bool, positive=positive_bool)\n",
    "\n",
    "# Define widgets\n",
    "neuron_pos_slider = widgets.IntSlider(min=0, max=20, step=1, value=0, description='Neuron Pos:')\n",
    "top_bottom_dropdown = widgets.Dropdown(options=['Top', 'Bottom'], value='Top', description='Neurons:')\n",
    "pos_neg_dropdown = widgets.Dropdown(options=['Positive', 'Negative'], value='Positive', description='Pos/Neg:')\n",
    "\n",
    "# Use interactive function to bind the widgets to the plotting function\n",
    "widgets.interactive(plot_individual_neuron, neuron_pos=neuron_pos_slider, top_bottom=top_bottom_dropdown, pos_neg=pos_neg_dropdown)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brainstorm notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to decompose an MLP5 neuron's effect into its boost to the correct logit and its deboost of other logits. I want to discover how these two effects change the log prob.\n",
    "\n",
    "metric like loss reduction vs. token boost\n",
    "\n",
    "~~run direct effect, patch each neuron in top 10 individually, get overall loss reduction from neuron controlled by context neuron (equivalent to logprob increase for correct token)~~\n",
    "decompose loss reduction into two parts:\n",
    "run direct effect, patch the correct token logit boost from the neuron (removing the neuron's other effects), get overall loss reduction from neuron (equivalent to logprob increase for correct token)\n",
    "destructive interference loss reduction = overall loss reduction - loss reduction from correct token logit boost (component of the logprob increase for correct token due to it deboosting incorrect token)\n",
    "\n",
    "Patch the correct token logit boost from the neuron (removing the neuron's other effects).\n",
    "1. Get baseline logprobs for a prompt\n",
    "2. Get difference in logits from activating the neuron under test. Can use get_direct_effects with return_type='logits'.\n",
    "3. Run the model with return_type='logits' and the neuron under test zero ablated. \n",
    "4. Add the correct token logit from step 1 to a copy of the output logits. Convert to logprobs\n",
    "5. Add the incorrect token logits from step 1 to a copy of the output logits. Convert to logprobs\n",
    "6. Compare A. lobprobs with correct answer token logit increase, B. logprobs with incorrect answer token logit increases, and C. baseline logprobs\n",
    "\n",
    "~~If the context neuron gives each neuron a flat boost then if we decompose the resulting flat boost to one MLP5 neuron into a boost to one logit vs. boosts to all other logits it will change the logprobs (first will increase answer probability and second will reduce answer probability). \n",
    "\n",
    "the two resulting log probs at the correct answer token won't add up to the original log probs (?). \n",
    "\n",
    "If the boost is flat the correct percentage decomposition is 1/50000 and 49999/50000? In practice/all other factors being equal\n",
    "\n",
    "New plan:\n",
    "\n",
    "Difference between baseline log prob and neuron log prob?\n",
    "Classify individual neurons by percentage constructive vs destructive by looking at their log probs and summing the incorrect token log probs\n",
    "\n",
    "Correct log prob difference\n",
    "Incorrect log prob difference (summed over every plausible token?)\n",
    "\n",
    "Largest boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the log prob for an incorrect token is significantly lower then that's where the extra probability density on the correct answer is coming from \n",
    "# Constructive interference increases correct token log prob and uniformly decreases other log probs\n",
    "# Destructive interference decreases specific other log probs and uniformly increases other log probs\n",
    " \n",
    "# Most neurons are a mixture of the above\n",
    "# Decompose neurons into what % of their effect is each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>                            <div id=\"551babc4-958a-4717-9401-c602be6d4d3f\" class=\"plotly-graph-div\" style=\"height:525px; width:800px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"551babc4-958a-4717-9401-c602be6d4d3f\")) {                    Plotly.newPlot(                        \"551babc4-958a-4717-9401-c602be6d4d3f\",                        [{\"hovertemplate\":\"variable=0\\u003cbr\\u003eindex=%{x}\\u003cbr\\u003evalue=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"0\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"0\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8],\"xaxis\":\"x\",\"y\":[1.7277206182479858,1.216694951057434,1.215029001235962,0.8604636192321777,0.855092465877533,0.5961781740188599,0.5597235560417175,0.49184340238571167,0.269136905670166],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"\"},\"tickmode\":\"array\",\"tickvals\":[0,1,2,3,4,5,6,7,8],\"ticktext\":[[\"ge\"],[\"gar\"],[\"ges\"],[\"g\"],[\"cen\"],[\"u\"],[\"gt\"],[\"gs\"],[\"glich\"]]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Largest positive difference in log probs for tokens when bottom neurons are not ablated\"},\"width\":800,\"showlegend\":true},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('551babc4-958a-4717-9401-c602be6d4d3f');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>                            <div id=\"bf00c5cf-6da1-4839-8205-2a1069f08add\" class=\"plotly-graph-div\" style=\"height:525px; width:800px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"bf00c5cf-6da1-4839-8205-2a1069f08add\")) {                    Plotly.newPlot(                        \"bf00c5cf-6da1-4839-8205-2a1069f08add\",                        [{\"hovertemplate\":\"variable=0\\u003cbr\\u003eindex=%{x}\\u003cbr\\u003evalue=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"0\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"0\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8],\"xaxis\":\"x\",\"y\":[2.0002169609069824,0.9866470098495483,0.9506673812866211,0.6417334079742432,0.4487774074077606,0.44692447781562805,0.43618014454841614,0.25941863656044006,0.10677473992109299],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"\"},\"tickmode\":\"array\",\"tickvals\":[0,1,2,3,4,5,6,7,8],\"ticktext\":[[\"gen\"],[\"glich\"],[\"u\"],[\"cen\"],[\"gt\"],[\"g\"],[\"ges\"],[\"gs\"],[\"gar\"]]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Largest positive difference in log probs for tokens when bottom neurons are not ablated\"},\"width\":800,\"showlegend\":true},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('bf00c5cf-6da1-4839-8205-2a1069f08add');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "original_logits, ablated_logprobs, _, all_MLP5_logprobs = haystack_utils.get_direct_effect(prompts, model, pos=-2, context_ablation_hooks=deactivate_neurons_fwd_hooks, context_activation_hooks=activate_neurons_fwd_hooks, return_type='logprobs')\n",
    "_, _, _, top_MLP5_ablated_logprobs = haystack_utils.get_direct_effect(prompts, model, pos=-2, context_ablation_hooks=deactivate_neurons_fwd_hooks, context_activation_hooks=activate_neurons_fwd_hooks+ablate_top_neurons_hook, return_type='logprobs')\n",
    "_, _, _, bottom_MLP5_ablated_logprobs = haystack_utils.get_direct_effect(prompts, model, pos=-2, context_ablation_hooks=deactivate_neurons_fwd_hooks, context_activation_hooks=activate_neurons_fwd_hooks+ablate_bottom_neurons_hook, return_type='logprobs')\n",
    "\n",
    "bottom_neuron_high_difference_logprobs = (all_MLP5_logprobs - bottom_MLP5_ablated_logprobs)\n",
    "bottom_neuron_high_difference_logprobs[bottom_neuron_high_difference_logprobs < 0] = 0\n",
    "bottom_neuron_high_difference_logprobs = bottom_neuron_high_difference_logprobs.mean(0)\n",
    "bottom_neuron_high_difference_logprobs[all_MLP5_logprobs.mean(0) < -7] = 0\n",
    "\n",
    "bottom_non_zero_count = (bottom_neuron_high_difference_logprobs > 0).sum()\n",
    "bottom_neuron_high_difference_logprobs, bottom_indices = haystack_utils.top_k_with_exclude(bottom_neuron_high_difference_logprobs, min(bottom_non_zero_count, 50), all_ignore)\n",
    "haystack_utils.line(bottom_neuron_high_difference_logprobs.cpu().numpy(), title='Largest positive difference in log probs for tokens when bottom neurons are not ablated', xticks=[model.to_str_tokens([i])[0] for i in bottom_indices])\n",
    "\n",
    "\n",
    "top_neuron_high_difference_logprobs = (all_MLP5_logprobs - top_MLP5_ablated_logprobs)\n",
    "top_neuron_high_difference_logprobs[top_neuron_high_difference_logprobs < 0] = 0\n",
    "top_neuron_high_difference_logprobs = top_neuron_high_difference_logprobs.mean(0)\n",
    "top_neuron_high_difference_logprobs[all_MLP5_logprobs.mean(0) < -7] = 0\n",
    "\n",
    "top_non_zero_count = (top_neuron_high_difference_logprobs > 0).sum()\n",
    "top_neuron_high_difference_logprobs, top_indices = haystack_utils.top_k_with_exclude(top_neuron_high_difference_logprobs, min(top_non_zero_count, 50), all_ignore)\n",
    "haystack_utils.line(top_neuron_high_difference_logprobs.cpu().numpy(), title='Largest positive difference in log probs for tokens when bottom neurons are not ablated', xticks=[model.to_str_tokens([i])[0] for i in top_indices])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'date' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m date\n",
      "\u001b[0;31mNameError\u001b[0m: name 'date' is not defined"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
