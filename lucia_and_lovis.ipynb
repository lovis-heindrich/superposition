{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NOTE: Redirects are currently not supported in Windows or MacOs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2 autoencoders\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model EleutherAI/pythia-160m into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformer_lens import HookedTransformer\n",
    "import numpy as np \n",
    "\n",
    "autoencoder_filename = \"pythia160m/output_sweep_tied_mlpout_l8_r4/_19/learned_dicts.pt\"\n",
    "# autoencoder_filename = \"pythia160m/output_hoagy_dense_sweep_tied_residual_l8_r4/_29/learned_dicts.pt\"\n",
    "auto_num = 0 # Selects which specific autoencoder to use\n",
    "all_autoencoders = torch.load(autoencoder_filename)\n",
    "num_dictionaries = len(all_autoencoders)\n",
    "print(f\"Loaded {num_dictionaries} autoencoders\")\n",
    "autoencoder, hyperparams = all_autoencoders[auto_num]\n",
    "l1_alpha = hyperparams['l1_alpha']\n",
    "autoencoder2, hyperparams2 = all_autoencoders[auto_num+1]\n",
    "smaller_dict = autoencoder.get_learned_dict()\n",
    "larger_dict = autoencoder2.get_learned_dict()\n",
    "\n",
    "#TODO: Lucis & Lovis\n",
    "#Change these settings to load the correct autoencoder #PLEEEEEAAASE Do this. Both layer & setting\n",
    "layer = 8\n",
    "# setting = \"residual\"\n",
    "# setting = \"attention\"\n",
    "setting = \"mlp\"\n",
    "# setting = \"mlp_out\"\n",
    "# model_name = \"EleutherAI/pythia-70m-deduped\"\n",
    "model_name = \"EleutherAI/pythia-160m\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = HookedTransformer.from_pretrained(model_name, device=device)\n",
    "\n",
    "if setting == \"residual\":\n",
    "    cache_name = f\"blocks.{layer}.hook_resid_post\"\n",
    "    neurons = model.cfg.d_model\n",
    "elif setting == \"mlp\":\n",
    "    cache_name = f\"blocks.{layer}.mlp.hook_post\"\n",
    "    neurons = model.cfg.d_mlp\n",
    "elif setting == \"attention\":\n",
    "    cache_name = f\"blocks.{layer}.hook_attn_out\"\n",
    "    neurons = model.cfg.d_model\n",
    "elif setting == \"mlp_out\":\n",
    "    cache_name = f\"blocks.{layer}.hook_mlp_out\"\n",
    "    neurons = model.cfg.d_model\n",
    "else:\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'dict_size': 3072, 'l1_alpha': 0.0010000000474974513},\n",
       " {'dict_size': 3072, 'l1_alpha': 0.0007999999797903001})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Two dicts: trained w/ different l1_alpha values\n",
    "hyperparams, hyperparams2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCS\n",
    "Max cosine similarity between one dictionary & another one. If they learned the same feature, then they'll have high cosine similarity. \n",
    "\n",
    "If two dictionaries learned it, it's probably a real feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('# of features above 0.9:', 514)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.optimize import linear_sum_assignment\n",
    "import matplotlib.pyplot as plt\n",
    "#Dictionary Comparison\n",
    "smaller_dict_features, _ = smaller_dict.shape\n",
    "larger_dict_features, _ = larger_dict.shape\n",
    "larger_dict = larger_dict.to(device)\n",
    "# Hungary algorithm\n",
    "# Calculate all cosine similarities and store in a 2D array\n",
    "cos_sims = np.zeros((smaller_dict_features, larger_dict_features))\n",
    "for idx, vector in enumerate(smaller_dict):\n",
    "    cos_sims[idx] = torch.nn.functional.cosine_similarity(vector.to(device), larger_dict, dim=1).cpu().numpy()\n",
    "# Convert to a minimization problem\n",
    "cos_sims = 1 - cos_sims\n",
    "# Use the Hungarian algorithm to solve the assignment problem\n",
    "row_ind, col_ind = linear_sum_assignment(cos_sims)\n",
    "# Retrieve the max cosine similarities and corresponding indices\n",
    "max_cosine_similarities = 1 - cos_sims[row_ind, col_ind]\n",
    "\n",
    "# Get the indices of the max cosine similarities in descending order\n",
    "max_indices = np.argsort(max_cosine_similarities)[::-1]\n",
    "max_cosine_similarities[max_indices][:20]\n",
    "print((\"# of features above 0.9:\", (max_cosine_similarities > .9).sum()))\n",
    "# Plot histogram of max_cosine_similarities\n",
    "plt.hist(max_cosine_similarities, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model activations & Dictionary Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "821b8f0d9a884d6ba1722332c632c129",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/373 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a305bb621ba4e399ff6d8ccb8a7cb39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/921 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "463ba5b039f44612bc29a2b87dfac0dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54822851b58149e29837832a86187c0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/33.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e97c10fdcde14fac84399dacc628dd64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12f245ae2dfd44f4889f034583b0596d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb62e5940c2444f994aee15067ff1bf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f11d5573d93f4d40b7a1b7b2442bfb1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed9474457780430e8d388ff975c77773",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9862 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Downnload dataset\n",
    "from datasets import Dataset, load_dataset\n",
    "dataset_name = \"NeelNanda/pile-10k\"\n",
    "token_amount= 40\n",
    "dataset = load_dataset(dataset_name, split=\"train\").map(\n",
    "    lambda x: model.tokenizer(x['text']),\n",
    "    batched=True,\n",
    ").filter(\n",
    "    lambda x: len(x['input_ids']) > token_amount\n",
    ").map(\n",
    "    lambda x: {'input_ids': x['input_ids'][:token_amount]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 309/309 [00:13<00:00, 23.64it/s]\n"
     ]
    }
   ],
   "source": [
    "# Now we can use the model to get the activations\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "from einops import rearrange\n",
    "# neurons = model.W_in.shape[-1]\n",
    "neurons = model.cfg.d_model\n",
    "datapoints = dataset.num_rows\n",
    "batch_size = 32\n",
    "neuron_activations = torch.zeros((datapoints*token_amount, neurons))\n",
    "dictionary_activations = torch.zeros((datapoints*token_amount, smaller_dict_features))\n",
    "smaller_auto_encoder = autoencoder\n",
    "smaller_auto_encoder.to_device(device)\n",
    "\n",
    "with torch.no_grad(), dataset.formatted_as(\"pt\"):\n",
    "    dl = DataLoader(dataset[\"input_ids\"], batch_size=batch_size)\n",
    "    for i, batch in enumerate(tqdm(dl)):\n",
    "        _, cache = model.run_with_cache(batch.to(device))\n",
    "        batched_neuron_activations = rearrange(cache[cache_name], \"b s n -> (b s) n\" )\n",
    "        neuron_activations[i*batch_size*token_amount:(i+1)*batch_size*token_amount,:] = batched_neuron_activations.cpu()\n",
    "        batched_dictionary_activations = smaller_auto_encoder.encode(batched_neuron_activations)\n",
    "        dictionary_activations[i*batch_size*token_amount:(i+1)*batch_size*token_amount,:] = batched_dictionary_activations.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(37.0351)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sparsity: or features/token\n",
    "dictionary_activations[:100000].count_nonzero(dim=1).float().mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Activation Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from circuitsvis.activations import text_neuron_activations\n",
    "# Get the activations for the best dict features\n",
    "def get_feature_datapoints(feature_index, dictionary_activations, dataset, k=10, setting=\"max\"):\n",
    "    best_feature_activations = dictionary_activations[:, feature_index]\n",
    "    # Sort the features by activation, get the indices\n",
    "    if setting==\"max\":\n",
    "        found_indices = torch.argsort(best_feature_activations, descending=True)[:k]\n",
    "    elif setting==\"uniform\":\n",
    "        min_value = torch.min(best_feature_activations)\n",
    "        max_value = torch.max(best_feature_activations)\n",
    "\n",
    "        # Define the number of bins\n",
    "        num_bins = k\n",
    "\n",
    "        # Calculate the bin boundaries as linear interpolation between min and max\n",
    "        bin_boundaries = torch.linspace(min_value, max_value, num_bins + 1)\n",
    "\n",
    "        # Assign each activation to its respective bin\n",
    "        bins = torch.bucketize(best_feature_activations, bin_boundaries)\n",
    "\n",
    "        # Initialize a list to store the sampled indices\n",
    "        sampled_indices = []\n",
    "\n",
    "        # Sample from each bin\n",
    "        for bin_idx in torch.unique(bins):\n",
    "            # Get the indices corresponding to the current bin\n",
    "            bin_indices = torch.nonzero(bins == bin_idx, as_tuple=False).squeeze(dim=1)\n",
    "            \n",
    "            # Randomly sample from the current bin\n",
    "            sampled_indices.extend(np.random.choice(bin_indices, size=1, replace=False))\n",
    "\n",
    "        # Convert the sampled indices to a PyTorch tensor & reverse order\n",
    "        found_indices = torch.tensor(sampled_indices).long().flip(dims=[0])\n",
    "    else: # random\n",
    "        # get nonzero indices\n",
    "        nonzero_indices = torch.nonzero(best_feature_activations)[:, 0]\n",
    "        # shuffle\n",
    "        shuffled_indices = nonzero_indices[torch.randperm(nonzero_indices.shape[0])]\n",
    "        found_indices = shuffled_indices[:k]\n",
    "    datapoint_indices =[np.unravel_index(i, (datapoints, token_amount)) for i in found_indices]\n",
    "    text_list = []\n",
    "    full_text = []\n",
    "    token_list = []\n",
    "    full_token_list = []\n",
    "    for md, s_ind in datapoint_indices:\n",
    "        md = int(md)\n",
    "        s_ind = int(s_ind)\n",
    "        full_tok = torch.tensor(dataset[md][\"input_ids\"])\n",
    "        full_text.append(model.tokenizer.decode(full_tok))\n",
    "        tok = dataset[md][\"input_ids\"][:s_ind+1]\n",
    "        text = model.tokenizer.decode(tok)\n",
    "        text_list.append(text)\n",
    "        token_list.append(tok)\n",
    "        full_token_list.append(full_tok)\n",
    "    return text_list, full_text, token_list, full_token_list\n",
    "\n",
    "def get_neuron_activation(token, feature, model, setting=\"dictionary_basis\"):\n",
    "    with torch.no_grad():\n",
    "        _, cache = model.run_with_cache(token.to(model.cfg.device))\n",
    "        neuron_act_batch = cache[cache_name]\n",
    "        if setting==\"dictionary_basis\":\n",
    "            neuron_act_batch = rearrange(neuron_act_batch, \"b s n -> (b s) n\" )\n",
    "            act = smaller_auto_encoder.encode(neuron_act_batch)\n",
    "            return act[:, feature].tolist()\n",
    "        else: # neuron/residual basis\n",
    "            return neuron_act_batch[0, :, feature].tolist()\n",
    "\n",
    "def ablate_text(text, feature, model, setting=\"dictionary_basis\"):\n",
    "    if isinstance(text, str):\n",
    "        text = [text]\n",
    "    display_text_list = []\n",
    "    activation_list = []\n",
    "    for t in text:\n",
    "        # Convert text into tokens\n",
    "        if isinstance(t, str): # If the text is a list of tokens\n",
    "            split_text = model.to_str_tokens(t, prepend_bos=False)\n",
    "            tokens = model.to_tokens(t, prepend_bos=False)\n",
    "        else: # t equals tokens\n",
    "            tokens = t\n",
    "            split_text = model.to_str_tokens(t, prepend_bos=False)\n",
    "        seq_size = tokens.shape[1]\n",
    "        if(seq_size == 1): # If the text is a single token, we can't ablate it\n",
    "            continue\n",
    "        original = get_neuron_activation(tokens, feature, model)[-1]\n",
    "        changed_activations = torch.zeros(seq_size, device=device).cpu()\n",
    "        for i in range(seq_size):\n",
    "            # Remove the i'th token from the input\n",
    "            ablated_tokens = torch.cat((tokens[:,:i], tokens[:,i+1:]), dim=1)\n",
    "            changed_activations[i] += get_neuron_activation(ablated_tokens, feature, model, setting)[-1]\n",
    "        changed_activations -= original\n",
    "        display_text_list += [x.replace('\\n', '\\\\newline') for x in split_text] + [\"\\n\"]\n",
    "        activation_list += changed_activations.tolist() + [0.0]\n",
    "    activation_list = torch.tensor(activation_list).reshape(-1,1,1)\n",
    "    return text_neuron_activations(tokens=display_text_list, activations=activation_list)\n",
    "\n",
    "def visualize_text(text, feature, model, setting=\"dictionary_basis\", max_activation = None):\n",
    "    if isinstance(text, str):\n",
    "        text = [text]\n",
    "    if isinstance(feature, int):\n",
    "        feature = [feature]\n",
    "    display_text_list = []\n",
    "    act_list = []\n",
    "    for t in text:\n",
    "        if isinstance(t, str): # If the text is a list of tokens\n",
    "            split_text = model.to_str_tokens(t, prepend_bos=False)\n",
    "            token = model.to_tokens(t, prepend_bos=False)\n",
    "        else: # t are tokens\n",
    "            token = t\n",
    "            split_text = model.to_str_tokens(t, prepend_bos=False)\n",
    "        for f in feature:\n",
    "            display_text_list += [x.replace('\\n', '\\\\newline') for x in split_text] + [\"\\n\"]\n",
    "            act_list += get_neuron_activation(token, f, model, setting) + [0.0]\n",
    "    act_list = torch.tensor(act_list).reshape(-1,1,1)\n",
    "    if(max_activation is not None):\n",
    "        act_list = torch.clamp(act_list, max=max_activation)\n",
    "    return text_neuron_activations(tokens=display_text_list, activations=act_list)\n",
    "# Ablate the feature direction of the tokens\n",
    "# token_list is a list of tokens, convert to tensor of shape (batch_size, seq_len)\n",
    "from einops import rearrange\n",
    "def ablate_feature_direction(tokens, feature, model, autoencoder):\n",
    "    def mlp_ablation_hook(value, hook):\n",
    "        # Rearrange to fit autoencoder\n",
    "        int_val = rearrange(value, 'b s h -> (b s) h')\n",
    "\n",
    "        # Run through the autoencoder\n",
    "        act = autoencoder.encode(int_val)\n",
    "        feature_to_ablate = feature # TODO: bring this out of the function\n",
    "\n",
    "        # Subtract value with feature direction*act_of_feature\n",
    "        dictionary_for_this_autoencoder = autoencoder.get_learned_dict()\n",
    "        feature_direction = torch.outer(act[:, feature_to_ablate].squeeze(), dictionary_for_this_autoencoder[feature_to_ablate].squeeze())\n",
    "        batch, seq_len, hidden_size = value.shape\n",
    "        feature_direction = rearrange(feature_direction, '(b s) h -> b s h', b=batch, s=seq_len)\n",
    "        value -= feature_direction\n",
    "        return value\n",
    "\n",
    "    return model.run_with_hooks(tokens, \n",
    "        fwd_hooks=[(\n",
    "            cache_name, \n",
    "            mlp_ablation_hook\n",
    "            )]\n",
    "        )\n",
    "def add_feature_direction(tokens, feature, model, autoencoder, scalar=1.0):\n",
    "    def residual_add_hook(value, hook):\n",
    "        feature_direction = autoencoder.decoder.weight[:, feature].squeeze()\n",
    "        value += scalar*feature_direction\n",
    "        return value\n",
    "\n",
    "    return model.run_with_hooks(tokens, \n",
    "        fwd_hooks=[(\n",
    "            cache_name,\n",
    "            residual_add_hook\n",
    "            )]\n",
    "        )\n",
    "def ablate_feature_direction_display(text, features=None, setting=\"true_tokens\", verbose=False):\n",
    "\n",
    "    if features==None:\n",
    "        features = torch.tensor([best_feature])\n",
    "    if isinstance(features, int):\n",
    "        features = torch.tensor([features])\n",
    "    if isinstance(features, list):\n",
    "        features = torch.tensor(features)\n",
    "    if isinstance(text, str):\n",
    "        text = [text]\n",
    "    text_list = []\n",
    "    logit_list = []\n",
    "    for t in text:\n",
    "        tokens = model.to_tokens(t, prepend_bos=False)\n",
    "        with torch.no_grad():\n",
    "            original_logits = model(tokens).log_softmax(-1).cpu()\n",
    "            ablated_logits = ablate_feature_direction(tokens, features, model, smaller_auto_encoder).log_softmax(-1).cpu()\n",
    "        diff_logits = ablated_logits  - original_logits# ablated > original -> negative diff\n",
    "        tokens = tokens.cpu()\n",
    "        if setting == \"true_tokens\":\n",
    "            split_text = model.to_str_tokens(t, prepend_bos=False)\n",
    "            gather_tokens = rearrange(tokens[:,1:], \"b s -> b s 1\") # TODO: verify this is correct\n",
    "            # Gather the logits for the true tokens\n",
    "            diff = rearrange(diff_logits[:, :-1].gather(-1,gather_tokens), \"b s n -> (b s n)\")\n",
    "        elif setting == \"max\":\n",
    "            # Negate the diff_logits to see which tokens have the largest effect on the neuron\n",
    "            val, ind = (-1*diff_logits).max(-1)\n",
    "            diff = rearrange(val[:, :-1], \"b s -> (b s)\")\n",
    "            diff*= -1 # Negate the values gathered\n",
    "            split_text = model.to_str_tokens(ind, prepend_bos=False)\n",
    "            gather_tokens = rearrange(ind[:,1:], \"1 s -> 1 s 1\")\n",
    "        split_text = split_text[1:] # Remove the first token since we're not predicting it\n",
    "        if(verbose):\n",
    "            text_list += [x.replace('\\n', '\\\\newline') for x in split_text] + [\"\\n\"]\n",
    "            text_list += [x.replace('\\n', '\\\\newline') for x in split_text] + [\"\\n\"]\n",
    "            orig = rearrange(original_logits[:, :-1].gather(-1, gather_tokens), \"b s n -> (b s n)\")\n",
    "            ablated = rearrange(ablated_logits[:, :-1].gather(-1, gather_tokens), \"b s n -> (b s n)\")\n",
    "            logit_list += orig.tolist() + [0.0]\n",
    "            logit_list += ablated.tolist() + [0.0]\n",
    "        text_list += [x.replace('\\n', '\\\\newline') for x in split_text] + [\"\\n\"]\n",
    "        logit_list += diff.tolist() + [0.0]\n",
    "    logit_list = torch.tensor(logit_list).reshape(-1,1,1)\n",
    "    if verbose:\n",
    "        print(f\"Max & Min logit-diff: {logit_list.max().item():.2f} & {logit_list.min().item():.2f}\")\n",
    "    return text_neuron_activations(tokens=text_list, activations=logit_list)\n",
    "def generate_text(input_text, num_tokens, model, autoencoder, feature, temperature=0.7, setting=\"add\", scalar=1.0):\n",
    "    # Convert input text to tokens\n",
    "    input_ids = model.tokenizer.encode(input_text, return_tensors='pt').to(device)\n",
    "\n",
    "    for _ in range(num_tokens):\n",
    "        # Generate logits\n",
    "        with torch.no_grad():\n",
    "            if(setting==\"add\"):\n",
    "                logits = add_feature_direction(input_ids, feature, model, autoencoder, scalar=scalar)\n",
    "            else:\n",
    "                logits = model(input_ids)\n",
    "\n",
    "        # Apply temperature\n",
    "        logits = logits / temperature\n",
    "\n",
    "        # Sample from the distribution\n",
    "        probs = torch.nn.functional.softmax(logits[:, -1, :], dim=-1)\n",
    "        predicted_token = torch.multinomial(probs, num_samples=1)\n",
    "\n",
    "        # Append predicted token to input_ids\n",
    "        input_ids = torch.cat((input_ids, predicted_token), dim=-1)\n",
    "\n",
    "    # Decode the tokens to text\n",
    "    output_text = model.tokenizer.decode(input_ids[0])\n",
    "\n",
    "    return output_text\n",
    "\n",
    "# Logit Lens\n",
    "def logit_lens(model, best_feature, smaller_dict, layer):\n",
    "    with torch.no_grad():\n",
    "        # There are never-used tokens, which have high norm. We want to ignore these.\n",
    "        bad_ind = (model.W_U.norm(dim=0) > 20)\n",
    "        feature_direction = smaller_dict[best_feature].to(device)\n",
    "        # feature_direction = torch.matmul(feature_direction, model.W_out[layer]) # if MLP\n",
    "        logits = torch.matmul(feature_direction, model.W_U).cpu()\n",
    "    # Don't include bad indices\n",
    "    logits[bad_ind] = -1000\n",
    "    topk_values, topk_indices = torch.topk(logits, 20)\n",
    "    top_text = model.to_str_tokens(topk_indices)\n",
    "    print(f\"{top_text}\")\n",
    "    print(topk_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Search\n",
    "Find Features that activate on the last token activation! Plug those into \"Best Feature\" below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activations: [7.89, 4.1, 2.38, 2.22, 2.16, 1.35, 0.75, 0.73, 0.52, 0.49]\n",
      "Feature_ids [920, 2709, 2987, 1384, 2468, 726, 235, 1550, 3042, 2935]\n"
     ]
    }
   ],
   "source": [
    "# t = \" I do like a\"\n",
    "# t = \" He had a first one (1), and then a second (2\"\n",
    "t = \"Das Berghain ist ein bekannter Nachtclub in Berlin, der für\"\n",
    "split_text = model.to_str_tokens(t, prepend_bos=False)\n",
    "token = model.to_tokens(t, prepend_bos=False)\n",
    "_, cache = model.run_with_cache(token.to(model.cfg.device))\n",
    "neuron_act_batch = cache[cache_name]\n",
    "act = smaller_auto_encoder.encode(neuron_act_batch.squeeze())\n",
    "# neg = \" He had a first one (1), and then a second 2\"\n",
    "# split_text = model.to_str_tokens(neg, prepend_bos=False)\n",
    "# token = model.to_tokens(neg, prepend_bos=False)\n",
    "# _, cache = model.run_with_cache(token.to(model.cfg.device))\n",
    "# neuron_act_batch = cache[cache_name]\n",
    "# act[-1, :] -= smaller_auto_encoder.encode(neuron_act_batch.squeeze())[-1,:]\n",
    "v, i = act[-1, :].topk(10)\n",
    "\n",
    "print(\"Activations:\",[round(val,2) for val in v.tolist()])\n",
    "print(\"Feature_ids\", i.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Interp\n",
    "Investigate the example sentences the activate this feature.\n",
    "\n",
    "Max: show max activating (tokens,contexts)\n",
    "\n",
    "Uniform: Show range of activations from each bin (e.g. sample an example from 1-2, 2-3, etc). \n",
    "[Note: if a feature is monosemantic, then the full range of activations should be that feature, not just max-activating ones]\n",
    "\n",
    "Full_text: shows the full text example\n",
    "\n",
    "Text_list: shows up to the most activating example (try w/ max activating on a couple of examples to see)\n",
    "\n",
    "ablate_text: remove the context one token at a time, and show the decrease/increase in activation of that feature\n",
    "\n",
    "ablate_feature_direction: removes feature direction from model's activation mid-inference, showing the logit diff in the output for every token.\n",
    "\n",
    "logit_lens: show the logit lens for that feature. If matches ablate_feature_direction, then the computation path is through the residual stream, else, it's through future layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature index: 920\n",
      "MCS: 0.9888160228729248\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-d8f3b345-239b\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, TextNeuronActivations } from \"https://unpkg.com/circuitsvis@1.40.1/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-d8f3b345-239b\",\n",
       "      TextNeuronActivations,\n",
       "      {\"tokens\": [\"In\", \" O\", \"er\", \"-\", \"Er\", \"k\", \"ensch\", \"wick\", \" hat\", \" es\", \" an\", \" einer\", \"\\n\", \"Die\", \" Bundes\", \"reg\", \"ierung\", \" will\", \" T\", \"aus\", \"ende\", \" As\", \"yl\", \"b\", \"ew\", \"er\", \"ber\", \" nach\", \" Afghanistan\", \" abs\", \"chie\", \"ben\", \".\", \" Ein\", \"ige\", \"\\n\", \"Il\", \"leg\", \"ale\", \" Ein\", \"w\", \"ande\", \"rer\", \" soll\", \"ten\", \" fest\", \"ge\", \"hal\", \"ten\", \" und\", \" ab\", \"ges\", \"ch\", \"ob\", \"en\", \" werden\", \"\\n\", \"Q\", \":\", \"\\\\newline\", \"\\\\newline\", \"W\", \"ie\", \" sp\", \"richt\", \" man\", \" von\", \" der\", \" deut\", \"schen\", \"\\n\", \"W\", \"ie\", \" bet\", \"re\", \"ib\", \"t\", \" man\", \" die\", \" D\", \"ek\", \"ol\", \"on\", \"is\", \"ierung\", \" einer\", \" F\", \"ach\", \"ze\", \"its\", \"chr\", \"ift\", \"?\", \" Der\", \" Che\", \"fred\", \"ak\", \"te\", \"ur\", \" der\", \" \\u201e\", \"American\", \" Historical\", \" Review\", \"\\u201c\", \" er\", \"\\n\", \"----------\", \" Forward\", \"ed\", \" message\", \" ----------\", \"\\\\newline\", \"From\", \":\", \" Google\", \" Group\", \" Inc\", \".\", \" <\", \"sch\", \"ac\", \"hen\", \"\\n\", \"Wa\", \"\\u00df\", \"\\n\", \"An\", \"ze\", \"ige\", \"\\\\newline\", \"\\\\newline\", \"Das\", \" B\", \"Af\", \"\\u00f6\", \"\\n\", \"Fried\", \"rich\", \" Sch\", \"\\u00fc\", \"tz\", \"\\\\newline\", \"\\\\newline\", \"Fried\", \"\\n\", \"D\", \"arius\", \"z\", \" Kos\", \"zyk\", \"owski\", \"\\\\newline\", \"\\\\newline\", \"D\", \"arius\", \"z\", \" Kos\", \"zyk\", \"\\n\", \"[\", \"Sign\", \"ificance\", \" of\", \" serum\", \" CD\", \"62\", \"p\", \" and\", \" CD\", \"\\n\"], \"activations\": [[[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[2.761497974395752]], [[2.556185245513916]], [[6.779508113861084]], [[6.402298450469971]], [[6.393479824066162]], [[9.202953338623047]], [[0.0]], [[0.0]], [[2.8261609077453613]], [[2.8808608055114746]], [[4.256248474121094]], [[4.907643795013428]], [[4.657352924346924]], [[4.431193828582764]], [[7.116590976715088]], [[3.074345111846924]], [[4.69190788269043]], [[3.887798309326172]], [[3.1577510833740234]], [[3.822205066680908]], [[6.355565547943115]], [[7.044996738433838]], [[4.094240665435791]], [[5.3558244705200195]], [[3.9581379890441895]], [[6.04323148727417]], [[0.0]], [[6.969540119171143]], [[7.96804666519165]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[2.4952797889709473]], [[2.3113036155700684]], [[2.9278173446655273]], [[4.072571277618408]], [[6.238897323608398]], [[8.556170463562012]], [[5.919338703155518]], [[5.079263210296631]], [[5.494926452636719]], [[6.613473415374756]], [[7.357731342315674]], [[5.631309986114502]], [[4.43295431137085]], [[2.4008240699768066]], [[4.086171627044678]], [[5.165167331695557]], [[6.983290195465088]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[5.8058366775512695]], [[3.8297910690307617]], [[5.3074212074279785]], [[5.48158073425293]], [[4.259832382202148]], [[4.862842082977295]], [[2.689751148223877]], [[5.608889102935791]], [[0.0]], [[0.0]], [[1.7032147645950317]], [[3.8614373207092285]], [[5.3016252517700195]], [[4.0391926765441895]], [[5.155192852020264]], [[5.059718608856201]], [[6.404574871063232]], [[3.6709961891174316]], [[2.8125243186950684]], [[1.0952092409133911]], [[2.739896774291992]], [[2.440690517425537]], [[6.269233703613281]], [[6.910330295562744]], [[3.2476134300231934]], [[4.677999973297119]], [[3.7331504821777344]], [[4.047740936279297]], [[2.406341552734375]], [[6.365929126739502]], [[4.197783946990967]], [[6.945300102233887]], [[2.6104397773742676]], [[2.691013813018799]], [[1.7540613412857056]], [[2.5533275604248047]], [[5.964476585388184]], [[7.070001125335693]], [[3.487975597381592]], [[0.0]], [[0.0]], [[0.0]], [[5.235105991363525]], [[5.276565074920654]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.04280674457550049]], [[0.0]], [[3.8751773834228516]], [[0.0]], [[0.0]], [[3.292965888977051]], [[0.0]], [[0.0]], [[0.0]], [[4.694018363952637]], [[0.0]], [[2.4566402435302734]], [[6.074641227722168]], [[3.7707462310791016]], [[1.6781708002090454]], [[2.516864776611328]], [[0.0]], [[0.0]], [[0.6254352331161499]], [[1.971948266029358]], [[1.5496550798416138]], [[1.5544191598892212]], [[0.0]], [[1.5334964990615845]], [[1.0842658281326294]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.040796875953674316]], [[0.0]], [[0.0]], [[0.10650455951690674]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]]], \"firstDimensionName\": \"Layer\", \"secondDimensionName\": \"Neuron\"}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7f0e62e6b370>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# N is sorted by MCS, so maybe they're cool and good, but\n",
    "# N = 106 # 106\n",
    "# best_feature = int(max_indices[N])\n",
    "\n",
    "# German ones?: 920, 2709, 2987 (maybe just 920)\n",
    "best_feature = 920 # Change this one for global index (N is sorted by MCS)\n",
    "\n",
    "print(f\"Feature index: {best_feature}\")\n",
    "print(f\"MCS: {max_cosine_similarities[best_feature]}\")\n",
    "text_list, full_text, token_list, full_token_list = get_feature_datapoints(best_feature, dictionary_activations, dataset, setting=\"uniform\")\n",
    "# text_list, full_text, token_list, full_token_list = get_feature_datapoints(best_feature, dictionary_activations, dataset, setting=\"max\")\n",
    "visualize_text(text_list, best_feature, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-65b156b8-e8c6\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, TextNeuronActivations } from \"https://unpkg.com/circuitsvis@1.40.1/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-65b156b8-e8c6\",\n",
       "      TextNeuronActivations,\n",
       "      {\"tokens\": [\"Die\", \" Bundes\", \"reg\", \"ierung\", \" will\", \" T\", \"aus\", \"ende\", \" As\", \"yl\", \"b\", \"ew\", \"er\", \"ber\", \" nach\", \" Afghanistan\", \" abs\", \"chie\", \"ben\", \".\", \" Ein\", \"ige\", \" von\", \" ihn\", \"en\", \" bez\", \"icht\", \"igen\", \" sich\", \" des\", \"hal\", \"b\", \" nun\", \" sel\", \"bst\", \" als\", \" Terror\", \"isten\", \" \\u2013\", \" und\", \"\\n\", \"W\", \"ie\", \" bet\", \"re\", \"ib\", \"t\", \" man\", \" die\", \" D\", \"ek\", \"ol\", \"on\", \"is\", \"ierung\", \" einer\", \" F\", \"ach\", \"ze\", \"its\", \"chr\", \"ift\", \"?\", \" Der\", \" Che\", \"fred\", \"ak\", \"te\", \"ur\", \" der\", \" \\u201e\", \"American\", \" Historical\", \" Review\", \"\\u201c\", \" er\", \"kl\", \"\\u00e4\", \"rt\", \",\", \" wie\", \"\\n\", \"Die\", \" \\u201e\", \"Sch\", \"reck\", \"ens\", \"n\", \"acht\", \"\\u201c\", \" von\", \" Im\", \"st\", \"\\\\newline\", \"\\\\newline\", \"En\", \"de\", \" April\", \" 1938\", \" haben\", \"\\n\", \"\\\\newline\", \"\\\\newline\", \"In\", \" T\", \"ans\", \"ania\", \" ab\", \" so\", \"fort\", \" ver\", \"bot\", \"en\", \":\", \" Gle\", \"it\", \"gel\", \"\\\\newline\", \"\\\\newline\", \"23\", \".\", \" Jul\", \"i\", \" 2016\", \",\", \" 16\", \":\", \"33\", \"h\", \",\", \"\\\\newline\", \"\\\\newline\", \"F\", \"\\u00fcr\", \" die\", \" Reg\", \"ierung\", \"\\n\", \"Q\", \":\", \"\\\\newline\", \"\\\\newline\", \"W\", \"ie\", \" sp\", \"richt\", \" man\", \" von\", \" der\", \" deut\", \"schen\", \" Spr\", \"ache\", \"?\", \"\\\\newline\", \"\\\\newline\", \"Es\", \" k\", \"ling\", \"t\", \" fast\", \"\\n\", \"Die\", \" Bundes\", \"reg\", \"ierung\", \" will\", \" T\", \"aus\", \"ende\", \" As\", \"yl\", \"b\", \"ew\", \"er\", \"ber\", \" nach\", \" Afghanistan\", \" abs\", \"chie\", \"ben\", \".\", \" Ein\", \"ige\", \" von\", \" ihn\", \"en\", \" bez\", \"icht\", \"igen\", \" sich\", \" des\", \"hal\", \"b\", \" nun\", \" sel\", \"bst\", \" als\", \" Terror\", \"\\n\", \"He\", \"i\", \",\", \" den\", \"ne\", \"\\n\", \"Da\", \" den\", \" f\", \"\\n\", \"K\", \"alt\", \"br\", \"\\n\", \"P\", \"rene\", \"z\", \" note\", \" que\", \" cet\", \" article\", \" pub\", \"li\", \"\\u00e9\", \" en\", \" 2016\", \" pour\", \"rait\", \"\\n\", \"Ox\", \"id\", \"ative\", \" stress\", \" in\", \" stable\", \" cystic\", \" fibrosis\", \" patients\", \":\", \" do\", \" we\", \" need\", \" higher\", \" antioxidant\", \" plasma\", \" levels\", \"?\", \"\\n\"], \"activations\": [[[-0.023637771606445312]], [[-0.051506996154785156]], [[0.04055213928222656]], [[0.0015716552734375]], [[-0.07532405853271484]], [[-0.02707958221435547]], [[-0.03195476531982422]], [[0.014710426330566406]], [[-0.03145408630371094]], [[-0.022602081298828125]], [[-0.048148155212402344]], [[-0.007037162780761719]], [[0.03299140930175781]], [[-0.014740943908691406]], [[-0.18398284912109375]], [[0.030517578125]], [[-0.009102821350097656]], [[0.032296180725097656]], [[0.0013341903686523438]], [[-0.43611812591552734]], [[-0.03895092010498047]], [[0.17428970336914062]], [[0.1356954574584961]], [[-0.13155746459960938]], [[0.10892772674560547]], [[-0.2001638412475586]], [[-0.051502227783203125]], [[-0.09539413452148438]], [[-0.05119037628173828]], [[-0.023145675659179688]], [[0.000335693359375]], [[0.09727859497070312]], [[-0.13712406158447266]], [[-0.28638172149658203]], [[-0.16753292083740234]], [[0.06489753723144531]], [[-0.3724374771118164]], [[0.12169933319091797]], [[-1.7097086906433105]], [[-1.577406406402588]], [[0.0]], [[-0.09592056274414062]], [[-0.061183929443359375]], [[0.07899665832519531]], [[0.0314178466796875]], [[-0.032283782958984375]], [[0.05222320556640625]], [[0.19234466552734375]], [[-0.2124309539794922]], [[-0.09919357299804688]], [[-0.1547985076904297]], [[-0.01975536346435547]], [[-0.04128074645996094]], [[0.0006685256958007812]], [[-0.33336639404296875]], [[-0.5867748260498047]], [[-0.060516357421875]], [[-0.12253665924072266]], [[0.003589630126953125]], [[-0.030580520629882812]], [[-0.24455642700195312]], [[-0.31314563751220703]], [[0.0756235122680664]], [[-0.14393043518066406]], [[-0.04239177703857422]], [[-0.012620925903320312]], [[-0.03628826141357422]], [[-0.030408859252929688]], [[-0.05785369873046875]], [[-0.035119056701660156]], [[-0.35732460021972656]], [[0.031007766723632812]], [[0.060821533203125]], [[0.05432319641113281]], [[0.12416839599609375]], [[0.5324392318725586]], [[0.6094355583190918]], [[-0.022995948791503906]], [[0.033184051513671875]], [[0.025758743286132812]], [[-0.32021045684814453]], [[0.0]], [[0.3095884323120117]], [[-0.016898632049560547]], [[-0.1406879425048828]], [[0.016869068145751953]], [[0.010786056518554688]], [[-0.15294790267944336]], [[-0.017946720123291016]], [[-0.2882261276245117]], [[0.2579636573791504]], [[-0.0800313949584961]], [[0.03359508514404297]], [[0.42479991912841797]], [[0.42479991912841797]], [[1.0462865829467773]], [[0.6097078323364258]], [[-0.19437599182128906]], [[-0.5789093971252441]], [[-4.481317043304443]], [[0.0]], [[0.23646163940429688]], [[0.23646163940429688]], [[-0.016844749450683594]], [[-0.024759769439697266]], [[-0.024598121643066406]], [[0.08219051361083984]], [[-0.016562461853027344]], [[-0.025472640991210938]], [[0.0011744499206542969]], [[-0.11406421661376953]], [[-0.1020956039428711]], [[0.015277862548828125]], [[-0.14716672897338867]], [[-0.02135181427001953]], [[-0.01723480224609375]], [[0.013921737670898438]], [[-0.012501716613769531]], [[-0.012501716613769531]], [[0.03267955780029297]], [[-0.037877559661865234]], [[-0.08435249328613281]], [[0.017656326293945312]], [[-0.037520408630371094]], [[0.07842636108398438]], [[-0.025156497955322266]], [[0.0642848014831543]], [[-0.023447036743164062]], [[-0.03663301467895508]], [[0.04711627960205078]], [[-0.11603260040283203]], [[-0.11603260040283203]], [[-0.8972272872924805]], [[-0.6904926300048828]], [[-0.5606675148010254]], [[1.393712043762207]], [[-2.6099729537963867]], [[0.0]], [[0.8881540298461914]], [[0.31980323791503906]], [[-0.3688349723815918]], [[-0.3688349723815918]], [[-0.5791721343994141]], [[-0.5661487579345703]], [[-0.38187313079833984]], [[-0.7041912078857422]], [[0.2030339241027832]], [[-0.22793340682983398]], [[-0.5695877075195312]], [[-0.2479419708251953]], [[-0.4424715042114258]], [[-0.09918880462646484]], [[-0.11435842514038086]], [[-0.04607677459716797]], [[-0.22595787048339844]], [[-0.22595787048339844]], [[-1.1960477828979492]], [[-0.24495267868041992]], [[-0.575014591217041]], [[0.8008108139038086]], [[1.9008417129516602]], [[0.0]], [[0.06685256958007812]], [[0.057578086853027344]], [[0.05002927780151367]], [[0.005375862121582031]], [[-0.013236045837402344]], [[-0.04496192932128906]], [[0.0046100616455078125]], [[0.02403736114501953]], [[0.03704071044921875]], [[-0.011187076568603516]], [[-0.031964778900146484]], [[-0.06307029724121094]], [[-0.00243377685546875]], [[-0.019817829132080078]], [[-0.09124088287353516]], [[0.11089086532592773]], [[0.027091026306152344]], [[0.0068759918212890625]], [[-0.007462501525878906]], [[0.2672882080078125]], [[-0.1105194091796875]], [[-0.04537391662597656]], [[0.04446125030517578]], [[-0.04476308822631836]], [[0.027647972106933594]], [[0.0016603469848632812]], [[0.10020160675048828]], [[0.0163421630859375]], [[-0.019906997680664062]], [[0.01024484634399414]], [[0.08594512939453125]], [[0.006433963775634766]], [[-0.012852668762207031]], [[-0.03166770935058594]], [[-0.4375171661376953]], [[-0.02010059356689453]], [[3.7599925994873047]], [[0.0]], [[0.8641700744628906]], [[0.6467180252075195]], [[-1.92446768283844]], [[-3.300853729248047]], [[-1.4697235822677612]], [[0.0]], [[0.09003877639770508]], [[-2.2223849296569824]], [[0.10798454284667969]], [[0.0]], [[-1.7188316583633423]], [[-1.7188316583633423]], [[-1.4913793802261353]], [[0.0]], [[0.08318686485290527]], [[0.06662595272064209]], [[-0.015944480895996094]], [[-0.015944480895996094]], [[0.1279517412185669]], [[-0.011188507080078125]], [[9.334087371826172e-05]], [[-0.015944480895996094]], [[0.007233619689941406]], [[-0.015944480895996094]], [[-0.015944480895996094]], [[-0.015944480895996094]], [[-0.015944480895996094]], [[-0.015944480895996094]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]]], \"firstDimensionName\": \"Layer\", \"secondDimensionName\": \"Neuron\"}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7f0e94fc2410>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ablate_text(text_list, best_feature, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-932b68f9-0eb3\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, TextNeuronActivations } from \"https://unpkg.com/circuitsvis@1.40.1/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-932b68f9-0eb3\",\n",
       "      TextNeuronActivations,\n",
       "      {\"tokens\": [\" Bundes\", \"reg\", \"ierung\", \" will\", \" T\", \"aus\", \"ende\", \" As\", \"yl\", \"b\", \"ew\", \"er\", \"ber\", \" nach\", \" Afghanistan\", \" abs\", \"chie\", \"ben\", \".\", \" Ein\", \"ige\", \" von\", \" ihn\", \"en\", \" bez\", \"icht\", \"igen\", \" sich\", \" des\", \"hal\", \"b\", \" nun\", \" sel\", \"bst\", \" als\", \" Terror\", \"isten\", \" \\u2013\", \" und\", \"\\n\", \"ie\", \" bet\", \"re\", \"ib\", \"t\", \" man\", \" die\", \" D\", \"ek\", \"ol\", \"on\", \"is\", \"ierung\", \" einer\", \" F\", \"ach\", \"ze\", \"its\", \"chr\", \"ift\", \"?\", \" Der\", \" Che\", \"fred\", \"ak\", \"te\", \"ur\", \" der\", \" \\u201e\", \"American\", \" Historical\", \" Review\", \"\\u201c\", \" er\", \"kl\", \"\\u00e4\", \"rt\", \",\", \" wie\", \"\\n\", \" \\u201e\", \"Sch\", \"reck\", \"ens\", \"n\", \"acht\", \"\\u201c\", \" von\", \" Im\", \"st\", \"\\\\newline\", \"\\\\newline\", \"En\", \"de\", \" April\", \" 1938\", \" haben\", \" Nazis\", \" in\", \" der\", \" Ti\", \"rol\", \"er\", \" Kle\", \"inst\", \"ad\", \"t\", \" Im\", \"st\", \" einen\", \" G\", \"ew\", \"al\", \"tex\", \"z\", \"ess\", \" gegen\", \" Aust\", \"ro\", \"\\n\", \"\\\\newline\", \"In\", \" T\", \"ans\", \"ania\", \" ab\", \" so\", \"fort\", \" ver\", \"bot\", \"en\", \":\", \" Gle\", \"it\", \"gel\", \"\\\\newline\", \"\\\\newline\", \"23\", \".\", \" Jul\", \"i\", \" 2016\", \",\", \" 16\", \":\", \"33\", \"h\", \",\", \"\\\\newline\", \"\\\\newline\", \"F\", \"\\u00fcr\", \" die\", \" Reg\", \"ierung\", \" ist\", \" das\", \" Ver\", \"k\", \"\\n\", \":\", \"\\\\newline\", \"\\\\newline\", \"W\", \"ie\", \" sp\", \"richt\", \" man\", \" von\", \" der\", \" deut\", \"schen\", \" Spr\", \"ache\", \"?\", \"\\\\newline\", \"\\\\newline\", \"Es\", \" k\", \"ling\", \"t\", \" fast\", \" wie\", \" eine\", \" Meta\", \"fr\", \"age\", \",\", \" aber\", \" wie\", \" sp\", \"richt\", \" man\", \" e\", \"igent\", \"lich\", \" von\", \" der\", \" deut\", \"\\n\", \" Bundes\", \"reg\", \"ierung\", \" will\", \" T\", \"aus\", \"ende\", \" As\", \"yl\", \"b\", \"ew\", \"er\", \"ber\", \" nach\", \" Afghanistan\", \" abs\", \"chie\", \"ben\", \".\", \" Ein\", \"ige\", \" von\", \" ihn\", \"en\", \" bez\", \"icht\", \"igen\", \" sich\", \" des\", \"hal\", \"b\", \" nun\", \" sel\", \"bst\", \" als\", \" Terror\", \"isten\", \" \\u2013\", \" und\", \"\\n\", \"i\", \",\", \" den\", \"ne\", \" art\", \"ik\", \"kel\", \"en\", \" er\", \" over\", \" ett\", \" \\u00e5r\", \" g\", \"amm\", \"el\", \" og\", \" kan\", \" in\", \"ne\", \"hol\", \"de\", \" ut\", \"d\", \"ater\", \"t\", \" inform\", \"as\", \"jon\", \"\\\\newline\", \"\\\\newline\", \"R\", \"une\", \" Gra\", \"hn\", \" (\", \"66\", \"),\", \" re\", \"kt\", \"\\n\", \" den\", \" f\", \"yn\", \"ske\", \" opt\", \"iker\", \" Finn\", \" Jun\", \"cker\", \" to\", \"g\", \" til\", \" Sen\", \"egal\", \" for\", \" at\", \" v\\u00e6re\", \" med\", \" til\", \" at\", \" ud\", \"de\", \"le\", \" b\", \"rug\", \"te\", \" br\", \"iller\", \" til\", \" be\", \"folk\", \"ningen\", \",\", \" var\", \" han\", \" op\", \"fy\", \"ld\", \"t\", \"\\n\", \"alt\", \"br\", \"unn\", \" railway\", \" station\", \"\\\\newline\", \"\\\\newline\", \"K\", \"alt\", \"br\", \"unn\", \" railway\", \" station\", \" is\", \" a\", \" railway\", \" station\", \" situated\", \" in\", \" the\", \" municipality\", \" of\", \" K\", \"alt\", \"br\", \"unn\", \" in\", \" the\", \" Swiss\", \" cant\", \"on\", \" of\", \" St\", \".\", \" Gall\", \"en\", \".\", \" It\", \" is\", \"\\n\", \"rene\", \"z\", \" note\", \" que\", \" cet\", \" article\", \" pub\", \"li\", \"\\u00e9\", \" en\", \" 2016\", \" pour\", \"rait\", \" cont\", \"en\", \"ir\", \" des\", \" inform\", \"ations\", \" qui\", \" ne\", \" sont\", \" plus\", \" \\u00e0\", \" jour\", \".\", \"\\\\newline\", \"\\\\newline\", \"L\", \"'\", \"h\", \"umor\", \"iste\", \" rim\", \"ous\", \"ko\", \"is\", \" Fred\", \" Dub\", \"\\n\", \"id\", \"ative\", \" stress\", \" in\", \" stable\", \" cystic\", \" fibrosis\", \" patients\", \":\", \" do\", \" we\", \" need\", \" higher\", \" antioxidant\", \" plasma\", \" levels\", \"?\", \"\\\\newline\", \"Ox\", \"id\", \"ative\", \" stress\", \" plays\", \" an\", \" important\", \" role\", \" in\", \" cystic\", \" fibrosis\", \" (\", \"CF\", \").\", \" However\", \",\", \" there\", \" is\", \" a\", \" lack\", \" of\", \"\\n\"], \"activations\": [[[0.0]], [[-0.3218259811401367]], [[-0.05874896049499512]], [[0.31967639923095703]], [[-0.8733654022216797]], [[-1.0546834468841553]], [[-0.03999197483062744]], [[0.1558375358581543]], [[0.06452858448028564]], [[-0.3899409770965576]], [[0.14168167114257812]], [[-0.07440585643053055]], [[-0.06836798042058945]], [[-1.0900664329528809]], [[-0.37645721435546875]], [[-0.4290647506713867]], [[-1.0491008758544922]], [[-0.016864173114299774]], [[0.06154584884643555]], [[-1.1704912185668945]], [[0.2922399044036865]], [[-0.6397190093994141]], [[-0.15118515491485596]], [[0.0016124295070767403]], [[0.291780948638916]], [[-0.9136462211608887]], [[0.38416504859924316]], [[-0.7679028511047363]], [[-0.710059642791748]], [[-0.5874987244606018]], [[0.0005374866304919124]], [[-1.1508822441101074]], [[0.06333112716674805]], [[-0.12583771347999573]], [[-0.22880077362060547]], [[-0.866055965423584]], [[-0.29585063457489014]], [[0.18523263931274414]], [[0.08344364166259766]], [[0.0]], [[0.0]], [[-0.41448020935058594]], [[-0.10072016716003418]], [[-0.2648963928222656]], [[0.02682371437549591]], [[-0.1695566177368164]], [[-0.6481101512908936]], [[-1.0115604400634766]], [[0.31163883209228516]], [[0.11135578155517578]], [[0.17723298072814941]], [[0.36434268951416016]], [[-0.7242796421051025]], [[-1.0796265602111816]], [[-0.23223638534545898]], [[-0.06881237030029297]], [[0.040450096130371094]], [[-0.26040518283843994]], [[0.43692779541015625]], [[0.009894296526908875]], [[0.04834747314453125]], [[-0.6105313301086426]], [[-0.09868621826171875]], [[0.1952601671218872]], [[0.25025129318237305]], [[-0.1227681040763855]], [[0.012392893433570862]], [[-1.1551249027252197]], [[-0.6751809120178223]], [[0.27086734771728516]], [[0.3318214416503906]], [[0.05504465103149414]], [[0.02987605333328247]], [[-0.2867889404296875]], [[-0.4499160051345825]], [[0.04514756053686142]], [[-0.001943914219737053]], [[-0.08317756652832031]], [[0.11937379837036133]], [[0.0]], [[0.0]], [[-0.17901325225830078]], [[-0.5197529792785645]], [[0.04530525207519531]], [[-0.19847869873046875]], [[0.1607210636138916]], [[-0.08080863952636719]], [[-0.3497505187988281]], [[-0.4134054183959961]], [[-0.3150639533996582]], [[0.10925769805908203]], [[-0.10661578178405762]], [[0.3711094856262207]], [[-0.09821867942810059]], [[-0.2879619598388672]], [[0.19746732711791992]], [[-0.6024656295776367]], [[1.1798110008239746]], [[-0.163069486618042]], [[-0.5850539207458496]], [[0.1254281997680664]], [[-0.047180354595184326]], [[0.056365013122558594]], [[0.21611881256103516]], [[-0.5246355533599854]], [[0.35551851987838745]], [[0.017551345750689507]], [[-0.6034889221191406]], [[0.3360788822174072]], [[-0.47838401794433594]], [[-0.449007511138916]], [[-0.7239668369293213]], [[0.5881268978118896]], [[0.17605924606323242]], [[0.18179607391357422]], [[0.6484737396240234]], [[-0.08983945846557617]], [[0.9738092422485352]], [[0.18219566345214844]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[-0.23151874542236328]], [[-0.3183095455169678]], [[-0.0693395733833313]], [[-0.056485652923583984]], [[-0.03947162628173828]], [[-0.260988712310791]], [[-0.19884109497070312]], [[0.79736328125]], [[0.0025788545608520508]], [[-0.015984535217285156]], [[-0.0012897253036499023]], [[0.0038700103759765625]], [[-0.01642453670501709]], [[0.005591869354248047]], [[-0.015954017639160156]], [[0.00802922248840332]], [[-0.0004787333309650421]], [[-0.000591278076171875]], [[0.03276538848876953]], [[0.007204771041870117]], [[0.017396211624145508]], [[0.0021700412034988403]], [[0.008937835693359375]], [[-0.42462992668151855]], [[-1.0638998746871948]], [[-0.45436859130859375]], [[-0.1977512240409851]], [[0.16856622695922852]], [[-0.8910989761352539]], [[-0.7217168807983398]], [[0.41931962966918945]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[-0.1952981948852539]], [[-0.5261383056640625]], [[-0.19075965881347656]], [[-0.7603964805603027]], [[-0.5770342350006104]], [[-0.5774350166320801]], [[-0.1009913980960846]], [[-1.3511791229248047]], [[0.015484459698200226]], [[0.10318517684936523]], [[0.01935294270515442]], [[0.015796512365341187]], [[-0.2008523941040039]], [[0.10736560821533203]], [[-0.26402968168258667]], [[-0.2325124591588974]], [[-1.1293392181396484]], [[-0.32776594161987305]], [[-0.6501502990722656]], [[-0.19797801971435547]], [[-0.13251447677612305]], [[-0.04382915049791336]], [[0.042588233947753906]], [[-0.12176847457885742]], [[-0.604215145111084]], [[0.5770561695098877]], [[-0.009601429104804993]], [[0.011026926338672638]], [[-0.17394161224365234]], [[-1.8102266788482666]], [[-0.004016394726932049]], [[0.4441053867340088]], [[-0.017999231815338135]], [[-0.07211154699325562]], [[0.0]], [[0.0]], [[-0.3218259811401367]], [[-0.05874896049499512]], [[0.31967639923095703]], [[-0.8733654022216797]], [[-1.0546834468841553]], [[-0.03999197483062744]], [[0.1558375358581543]], [[0.06452858448028564]], [[-0.3899409770965576]], [[0.14168167114257812]], [[-0.07440585643053055]], [[-0.06836798042058945]], [[-1.0900664329528809]], [[-0.37645721435546875]], [[-0.4290647506713867]], [[-1.0491008758544922]], [[-0.016864173114299774]], [[0.06154584884643555]], [[-1.1704912185668945]], [[0.2922399044036865]], [[-0.6397190093994141]], [[-0.15118515491485596]], [[0.0016124295070767403]], [[0.291780948638916]], [[-0.9136462211608887]], [[0.38416504859924316]], [[-0.7679028511047363]], [[-0.710059642791748]], [[-0.5874987244606018]], [[0.0005374866304919124]], [[-1.1508822441101074]], [[0.06333112716674805]], [[-0.12583771347999573]], [[-0.22880077362060547]], [[-0.866055965423584]], [[-0.29585063457489014]], [[0.18523263931274414]], [[0.08344364166259766]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[-0.04432964324951172]], [[1.2239303588867188]], [[0.47414302825927734]], [[-0.22148799896240234]], [[0.2704048156738281]], [[-0.049974024295806885]], [[-0.23661518096923828]], [[0.004257917404174805]], [[-0.00022459030151367188]], [[5.237641744315624e-06]], [[0.03453585505485535]], [[5.959300324320793e-07]], [[-0.00023164227604866028]], [[-0.007128894329071045]], [[0.0020613670349121094]], [[-0.00017996132373809814]], [[0.0010520368814468384]], [[0.00032951822504401207]], [[-0.0009657144546508789]], [[-0.0030884742736816406]], [[0.005077242851257324]], [[0.01538577675819397]], [[0.0003580451011657715]], [[-1.2023025192320347e-05]], [[9.957700967788696e-05]], [[-0.00022596120834350586]], [[-0.000981450080871582]], [[0.0011143684387207031]], [[0.0006127357482910156]], [[0.0002117156982421875]], [[0.0004200935363769531]], [[-0.0035669803619384766]], [[0.0015687942504882812]], [[-0.0011185407638549805]], [[-0.00035762786865234375]], [[0.00014865398406982422]], [[0.0]], [[0.0]], [[0.2694540023803711]], [[0.2994985580444336]], [[-0.00664520263671875]], [[0.1991558074951172]], [[-0.25322580337524414]], [[0.12588977813720703]], [[-0.10116291046142578]], [[0.04668474197387695]], [[0.39623212814331055]], [[0.019811630249023438]], [[0.19306468963623047]], [[-0.015414237976074219]], [[-0.005452156066894531]], [[0.05266904830932617]], [[-0.02033233642578125]], [[0.03507232666015625]], [[-0.04171633720397949]], [[0.002676248550415039]], [[0.012113094329833984]], [[0.03576850891113281]], [[0.004972934722900391]], [[-0.018936634063720703]], [[0.020246028900146484]], [[0.0031375885009765625]], [[-0.0017704963684082031]], [[-0.008822441101074219]], [[-0.0033087730407714844]], [[-0.024227142333984375]], [[-0.01262521743774414]], [[-0.0020264387130737305]], [[0.0003393888473510742]], [[-0.0029549598693847656]], [[0.006681919097900391]], [[0.04571247100830078]], [[0.05498790740966797]], [[-0.0006237030029296875]], [[-0.00010104849934577942]], [[0.0003539975732564926]], [[0.0]], [[0.0]], [[-0.04947948455810547]], [[-0.2176990509033203]], [[0.004530906677246094]], [[2.9325485229492188e-05]], [[-7.104873657226562e-05]], [[-0.001272439956665039]], [[-1.1920928955078125e-05]], [[0.0057405829429626465]], [[-0.0011014044284820557]], [[0.0018322467803955078]], [[7.796287536621094e-05]], [[1.0523945093154907e-06]], [[-1.239776611328125e-05]], [[-9.036064147949219e-05]], [[-3.540515899658203e-05]], [[1.4789402484893799e-06]], [[0.00010728836059570312]], [[1.7881393432617188e-06]], [[0.0004565715789794922]], [[0.0037713050842285156]], [[4.188716411590576e-05]], [[-0.0012238025665283203]], [[-0.0002270340919494629]], [[-0.0019274502992630005]], [[0.0015996471047401428]], [[-0.0008099079132080078]], [[-3.6597251892089844e-05]], [[-0.0006375312805175781]], [[-5.778670310974121e-05]], [[-9.208917617797852e-06]], [[-2.1532177925109863e-05]], [[-0.1324324607849121]], [[-0.006254225969314575]], [[-0.004974745213985443]], [[0.00010584807023406029]], [[7.593631744384766e-05]], [[-1.8715858459472656e-05]], [[-9.417533874511719e-06]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[5.872175097465515e-05]], [[-2.956390380859375e-05]], [[-5.0067901611328125e-05]], [[1.3828277587890625e-05]], [[3.981590270996094e-05]], [[0.0018463134765625]], [[0.016333788633346558]], [[-3.57162207365036e-07]], [[-5.245208740234375e-06]], [[-9.775161743164062e-06]], [[4.7031790018081665e-07]], [[9.775161743164062e-06]], [[1.621246337890625e-05]], [[-1.609325408935547e-05]], [[0.07371640205383301]], [[-0.0029659271240234375]], [[0.0022079944610595703]], [[-0.0033664703369140625]], [[-0.00081634521484375]], [[-3.094226121902466e-05]], [[4.4345855712890625e-05]], [[-3.3974647521972656e-06]], [[5.7220458984375e-06]], [[0.0004830360412597656]], [[5.9485435485839844e-05]], [[-5.340576171875e-05]], [[-0.014880180358886719]], [[-0.0020351409912109375]], [[0.010648488998413086]], [[0.005695343017578125]], [[-0.000102996826171875]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]]], \"firstDimensionName\": \"Layer\", \"secondDimensionName\": \"Neuron\"}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7f0e95954070>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ablate_feature_direction_display(full_text, best_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' nun', 'unter', ' sein', ' durch', ' einen', 'ungen', ' belie', ' keine', ' und', ' auf', ' dieser', ' bei', 'recht', ' sehr', ' mö', ' unter', ' zum', 'zw', 'igent', 'zeit']\n",
      "tensor([1.3300, 1.2846, 1.2522, 1.2375, 1.2310, 1.1838, 1.1765, 1.1692, 1.1676,\n",
      "        1.1579, 1.1498, 1.1394, 1.1206, 1.1199, 1.1132, 1.1127, 1.1083, 1.1004,\n",
      "        1.0921, 1.0913])\n"
     ]
    }
   ],
   "source": [
    "logit_lens(model,best_feature, smaller_dict, layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-7dddbb60-0c2e\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, TextNeuronActivations } from \"https://unpkg.com/circuitsvis@1.40.1/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-7dddbb60-0c2e\",\n",
       "      TextNeuronActivations,\n",
       "      {\"tokens\": [\"Include\", \" your\", \" own\", \" German\", \" text\", \".\", \" Ja\", \",\", \" das\", \" ist\", \" gut\", \".\", \"\\n\"], \"activations\": [[[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[2.570918560028076]], [[3.604458808898926]], [[7.990434169769287]], [[8.273178100585938]], [[7.29265832901001]], [[4.7365875244140625]], [[0.0]]], \"firstDimensionName\": \"Layer\", \"secondDimensionName\": \"Neuron\"}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7f0e951f35e0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_text = [\n",
    "    \"Include your own German text. Ja, das ist gut!\",\n",
    "]\n",
    "visualize_text(custom_text, best_feature, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTE TO LUCIA & LOVIS\n",
    "I haven't checked the next part of code at all, so beware!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Centric Viewpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go through datapoints & see if the features that activate on them make sense.\n",
    "d_point = 0\n",
    "# text = tokens_dataset[d_point]\n",
    "data_ind, sequence_pos = np.unravel_index(d_point, (datapoints, token_amount))\n",
    "feature_val, feature_ind = dictionary_activations[d_point].topk(10)\n",
    "data_ind = int(data_ind)\n",
    "sequence_pos = int(sequence_pos)\n",
    "full_tok = torch.tensor(dataset[data_ind][\"input_ids\"])\n",
    "full_text = []\n",
    "full_text.append(model.tokenizer.decode(full_tok))\n",
    "visualize_text(full_text, feature_ind, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the neuron/residual basis\n",
    "When we look at the weights of a feature, we are seeing the literal dimensions from the residual stream/neurons being read from the feature. \n",
    "\n",
    "Here I'm visualizing the weight values for the residual stream. If there are outliers, then it's mainly reading from that dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(weights*max_activation).topk(20), (weights*max_activation).topk(20, largest=False).values, (weights*max_activation > 0.2).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepend/Append tokens\n",
    "We can iterate over all tokens to check which ones activate a feature a lot to more rigorously test a hypothesis on what a feature means.\n",
    "\n",
    "Note: I'm literately running the model through all 50k tokens prepended to the text here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepend_all_tokens_and_get_feature_activation(model, minimal_activating_example, feature, setting=\"prepend\"):\n",
    "    tokens = model.to_tokens(minimal_activating_example, prepend_bos=False)\n",
    "\n",
    "    # Run through every number up to vocab size\n",
    "    vocab_size = model.cfg.d_vocab\n",
    "    batch_size = 256*2 # Define your desired batch size\n",
    "\n",
    "    dollar_feature_activations = torch.zeros(vocab_size)\n",
    "    for start in range(0, vocab_size, batch_size):\n",
    "        end = min(start + batch_size, vocab_size)\n",
    "\n",
    "        token_prep = torch.arange(start, end).to(device)\n",
    "        token_prep = token_prep.unsqueeze(1)  # Add a dimension for concatenation\n",
    "\n",
    "        # 1. Prepend to the tokens\n",
    "        if setting == \"prepend\":\n",
    "            tokens_catted = torch.cat((token_prep, tokens.repeat(end - start, 1)), dim=1).long()\n",
    "        elif setting == \"append\":\n",
    "            tokens_catted = torch.cat((tokens.repeat(end - start, 1), token_prep), dim=1).long()\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown setting: {setting}\")\n",
    "\n",
    "        # 2. Run through the model\n",
    "        with torch.no_grad():\n",
    "            _, cache = model.run_with_cache(tokens_catted.to(device))\n",
    "            neuron_act_batch = cache[cache_name]\n",
    "            _, act = smaller_auto_encoder(neuron_act_batch)\n",
    "\n",
    "        # 3. Get the feature\n",
    "        dollar_feature_activations[start:end] = act[:, -1, feature].cpu().squeeze()\n",
    "\n",
    "    k = 20\n",
    "    k_increasing_val, k_increasing_ind = dollar_feature_activations.topk(k)\n",
    "    k_decreasing_val, k_decreasing_ind = dollar_feature_activations.topk(k, largest=False)\n",
    "    if(setting == \"prepend\"):\n",
    "        print(f\"[token]{minimal_activating_example}\")\n",
    "    elif(setting == \"append\"):\n",
    "        print(f\"{minimal_activating_example}[token]\")\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown setting: {setting}\")\n",
    "    # Print indices converted to tokens\n",
    "    print(f\"Top-{k} increasing: {model.to_str_tokens(k_increasing_ind)}\")\n",
    "    # Print values\n",
    "    print(f\"Top-{k} increasing: {[f'{val:.2f}' for val in k_increasing_val]}\")\n",
    "    print(f\"Top-{k} decreasing: {model.to_str_tokens(k_decreasing_ind)}\")\n",
    "    print(f\"Top-{k} decreasing: {[f'{val:.2f}' for val in k_decreasing_val]}\")\n",
    "    print(f\"Number of 0 activations: {torch.sum(dollar_feature_activations == 0)}\")\n",
    "    if(setting == \"prepend\"):\n",
    "        best_text = \"\".join(model.to_str_tokens(dollar_feature_activations.argmax()) + [minimal_activating_example])\n",
    "    else:\n",
    "        best_text = \"\".join([minimal_activating_example] + model.to_str_tokens(dollar_feature_activations.argmax()))\n",
    "    return best_text\n",
    "\n",
    "best_text = \"\"\n",
    "for x in range(3):\n",
    "    # best_text = prepend_all_tokens_and_get_feature_activation(model, best_text, best_feature, setting=\"prepend\")\n",
    "    best_text = prepend_all_tokens_and_get_feature_activation(model, best_text, best_feature, setting=\"append\")\n",
    "# prepend_all_tokens_and_get_feature_activation(model, \" for all $\", best_feature, setting=\"prepend\")\n",
    "# prepend_all_tokens_and_get_feature_activation(model, \" tree\", best_feature, setting=\"prepend\")\n",
    "# prepend_all_tokens_and_get_feature_activation(model, \" tree\", best_feature, setting=\"append\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_text = \"\"\n",
    "for x in range(3):\n",
    "    best_text = prepend_all_tokens_and_get_feature_activation(model, best_text, best_feature, setting=\"prepend\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepend_all_tokens_and_get_feature_activation(model, \" for all $\", best_feature, setting=\"prepend\")\n",
    "# prepend_all_tokens_and_get_feature_activation(model, \"The\", best_feature, setting=\"append\")\n",
    "# prepend_all_tokens_and_get_feature_activation(model, \" tree\", best_feature, setting=\"append\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
