{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Activation Patching\n",
    "\n",
    "from transformer_lens import patching\n",
    "\n",
    "# TODO\n",
    "current_answer_tokens = answer_tokens[0]\n",
    "\n",
    "# cache for one input and its pair\n",
    "clean_tokens = model.to_tokens(prompts[0], prepend_bos=True)\n",
    "corrupted_tokens = model.to_tokens(prompts[1], prepend_bos=True)\n",
    "clean_tokens = clean_tokens.to(device)\n",
    "corrupted_tokens = corrupted_tokens.to(device)\n",
    "clean_logits, clean_cache = model.run_with_cache(clean_tokens)\n",
    "corrupted_logits, corrupted_cache = model.run_with_cache(corrupted_tokens)\n",
    "clean_logit_diff = logits_to_ave_logit_diff(clean_logits, answer_tokens)\n",
    "corrupted_logit_diff = logits_to_ave_logit_diff(corrupted_logits, answer_tokens)\n",
    "print(f\"Clean logit diff: {clean_logit_diff:.4f}\")\n",
    "print(f\"Corrupted logit diff: {corrupted_logit_diff:.4f}\")\n",
    "\n",
    "def ioi_metric(\n",
    "    logits: Float[Tensor, \"batch seq d_vocab\"], \n",
    "    answer_tokens: Float[Tensor, \"batch 2\"] = current_answer_tokens,\n",
    "    corrupted_logit_diff: float = corrupted_logit_diff,\n",
    "    clean_logit_diff: float = clean_logit_diff,\n",
    ") -> Float[Tensor, \"\"]:\n",
    "    '''\n",
    "    Linear function of logit diff, calibrated so that it equals 0 when performance is \n",
    "    same as on corrupted input, and 1 when performance is same as on clean input.\n",
    "    '''\n",
    "    patched_logit_diff = logits_to_ave_logit_diff(logits, answer_tokens)\n",
    "    return (patched_logit_diff - corrupted_logit_diff) / (clean_logit_diff - corrupted_logit_diff)\n",
    "                                                          \n",
    "\n",
    "act_patch_resid_pre = patching.get_act_patch_resid_pre(\n",
    "    model = model,\n",
    "    corrupted_tokens = corrupted_tokens,\n",
    "    clean_cache = clean_cache,\n",
    "    patching_metric = ioi_metric\n",
    ")\n",
    "\n",
    "labels = [f\"{tok} {i}\" for i, tok in enumerate(model.to_str_tokens(clean_tokens[0]))]\n",
    "\n",
    "imshow(\n",
    "    act_patch_resid_pre, \n",
    "    labels={\"x\": \"Position\", \"y\": \"Layer\"},\n",
    "    x=labels,\n",
    "    title=\"resid_pre Activation Patching\",\n",
    "    width=600\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final word translations\n",
    "\n",
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "translator = GoogleTranslator(src='fr', target='en')\n",
    "\n",
    "final_word_translations = []\n",
    "for item in french_data:\n",
    "    final_word = item.split()[-1]\n",
    "    translation = translator.translate(final_word)\n",
    "    final_word_translations.append(translation)\n",
    "\n",
    "write_data(final_word_translations, \"final_word_translations.json\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
