{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformer_lens import HookedTransformer\n",
    "from jaxtyping import Float\n",
    "from torch import Tensor\n",
    "import plotly.io as pio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import trange\n",
    "from collections import defaultdict, Counter\n",
    "from torchmetrics.regression import SpearmanCorrCoef\n",
    "import plotly_express as px\n",
    "import circuitsvis\n",
    "\n",
    "pio.renderers.default = \"notebook_connected+notebook\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.autograd.set_grad_enabled(False)\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "import haystack_utils\n",
    "import hook_utils\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model EleutherAI/pythia-70m into HookedTransformer\n",
      "data/german_europarl.json: Loaded 2000 examples with 152 to 2000 characters each.\n",
      "data/english_europarl.json: Loaded 2000 examples with 165 to 2000 characters each.\n"
     ]
    }
   ],
   "source": [
    "model = HookedTransformer.from_pretrained(\"EleutherAI/pythia-70m\",\n",
    "    center_unembed=True,\n",
    "    center_writing_weights=True,\n",
    "    fold_ln=True,\n",
    "    device=device)\n",
    "\n",
    "german_data = haystack_utils.load_json_data(\"data/german_europarl.json\")[:200]\n",
    "english_data = haystack_utils.load_json_data(\"data/english_europarl.json\")[:200]\n",
    "\n",
    "LAYER, NEURON = 3, 669\n",
    "\n",
    "\n",
    "german_prompt = \"beraten. H\\u00f6here Investitionen in Forschung und Entwicklung sowie die Erfassung und \\\n",
    "    Verarbeitung von zuverl\\u00e4ssigen Daten w\\u00fcrde zu einer solideren und nachhaltigen Gemeinsamen \\\n",
    "    Fischereipolitik f\\u00fchren.\\nAber obwohl der Satz, den ich von einem Wissenschaftler geh\\u00f6rt \\\n",
    "    habe (\\\"Das Problem ist nicht Geld, sondern Personal\\\") die Lage gut darstellt, werde ich nicht \\\n",
    "    diejenige sein, die sagt, dass die Fischereiforschung gut mit finanziellen Mitteln ausgestattet \\\n",
    "    ist. Ich werde vielmehr sagen, dass wir ein doppeltes Problem haben.\\nAn erster Stelle, Herr \\\n",
    "    Kommissar, die im Siebten Rahmenprogramm f\\u00fcr Meeresforschung festgelegten Betr\\u00e4ge, \\\n",
    "    die ein horizontales Thema h\\u00e4tten sein sollen, scheinen f\\u00fcr den integrierten Ansatz, \\\n",
    "    der bei dieser Angelegenheit gegenw\\u00e4rtig gew\\u00fcnscht wird, unzureichend zu sein.\\nAu\\u00dferdem, \\\n",
    "    Herr Kommissar, haben Wissenschaftler - und ich kann Ihnen versichern, dass ich vor und w\\u00e4hrend \\\n",
    "    der Ausarbeitung dieses Berichts mit vielen gesprochen habe - Probleme bei der Einreichung von Projekten \\\n",
    "    unter dem Siebten Forschungsrahmenprogramm. Diese Probleme sind\"\n",
    "\n",
    "english_prompt = \"given the generally greater adeptness of children at using audio-visual resources, in some \\\n",
    "    areas there are dangers of their obtaining access to unsuitable or harmful material. This is most obvious \\\n",
    "    in the fields of overt sexual material and gratuitous violence.\\nThe principles which have guided this \\\n",
    "    report are to encourage greater public awareness of these issues and to support parental responsibility \\\n",
    "    and to develop co-operation between the content providers, consumer organisations and the \\\n",
    "    respective authorities, both national and European. Self-regulation is considered to be the \\\n",
    "    main instrument, underpinned by legal requirements where necessary.\\nThe report, which \\\n",
    "    analyses the Commission's evaluation report, is primarily concerned with the Internet \\\n",
    "    and with video games, as it was felt important not to anticipate a possible future \\\n",
    "    review of the Television without Frontiers directive. The report calls for user-friendly content filter systems\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('<|endoftext|>', '<|endoftext|>'), ('<|padding|>', '<|endoftext|>'), ('<|padding|>', '<|padding|>'), ('!', '<|endoftext|>'), ('!', '!'), ('!', '<|padding|>'), ('\"', '!'), ('\"', '\"'), ('\"', '<|padding|>'), ('\"', '<|endoftext|>'), ('#', '<|endoftext|>'), ('#', '#'), ('#', '\"'), ('#', '<|padding|>'), ('#', '!'), ('$', '<|endoftext|>'), ('$', '!'), ('$', '$'), ('$', '\"'), ('$', '#'), ('$', '<|padding|>'), ('%', '%'), ('%', '<|endoftext|>'), ('%', '\"'), ('%', '#'), ('%', '<|padding|>'), ('%', '$'), ('%', '!'), ('&', '%'), ('&', '&'), ('&', '#'), ('&', '\"'), ('&', '<|endoftext|>'), ('&', '<|padding|>'), ('&', '!'), ('&', '$'), (\"'\", '\"'), (\"'\", \"'\"), (\"'\", '%'), (\"'\", '!'), (\"'\", '<|endoftext|>'), (\"'\", '<|padding|>'), (\"'\", '$'), (\"'\", '&'), (\"'\", '#'), ('(', '('), ('(', '#'), ('(', '$'), ('(', '\"'), ('(', '<|padding|>'), ('(', \"'\"), ('(', '<|endoftext|>'), ('(', '&'), ('(', '!'), ('(', '%'), (')', '('), (')', ')'), (')', '<|endoftext|>'), (')', '!'), (')', '\"'), (')', '$'), (')', \"'\"), (')', '<|padding|>'), (')', '#'), (')', '&'), (')', '%'), ('*', '<|endoftext|>'), ('*', '*'), ('*', '!'), ('*', ')'), ('*', '('), ('*', '%'), ('*', '#'), ('*', '<|padding|>'), ('*', '\"'), ('*', '$'), ('*', '&'), ('*', \"'\"), ('+', '#'), ('+', ')'), ('+', '+'), ('+', '('), ('+', '*'), ('+', '<|endoftext|>'), ('+', '\"'), ('+', \"'\"), ('+', '$'), ('+', '&'), ('+', '<|padding|>'), ('+', '%'), ('+', '!'), (',', '\"'), (',', '('), (',', ')'), (',', ','), (',', '#'), (',', '$'), (',', '+'), (',', \"'\"), (',', '<|padding|>')]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokens = model.to_tokens(english_prompt[:50] + ' ich bin haute')[0]\n",
    "# str_tokens = model.to_str_tokens(tokens)\n",
    "# _, cache = model.run_with_cache(tokens)\n",
    "# head_attention = circuitsvis.attention.attention_pattern(tokens=str_tokens, attention=cache['blocks.2.attn.hook_pattern'][0, 5, :, :])\n",
    "# sized_viz = SizeLimitedObject(head_attention)\n",
    "\n",
    "def mask_scores(attn_scores: Float[Tensor, \"query_nctx key_nctx\"]):\n",
    "    '''Mask the attention scores so that tokens don't attend to previous tokens.'''\n",
    "    # assert attn_scores.shape == (model.cfg.n_ctx, model.cfg.n_ctx)\n",
    "    mask = torch.tril(torch.ones_like(attn_scores)).bool()\n",
    "    neg_inf = torch.tensor(-1.0e6).to(attn_scores.device)\n",
    "    masked_attn_scores = torch.where(mask, attn_scores, neg_inf)\n",
    "    return masked_attn_scores\n",
    "\n",
    "layer = 2\n",
    "head_index = 5\n",
    "\n",
    "haystack_utils.clean_cache()\n",
    "W_E = model.W_E\n",
    "W_QK = model.W_Q[layer, head_index] @ model.W_K[layer, head_index].T\n",
    "# Bilinear form representing how much attention head token pays to each other token via L2H5\n",
    "pos_by_pos_scores = W_E @ W_QK @ W_E.T\n",
    "\n",
    "masked_scaled = mask_scores(pos_by_pos_scores / model.cfg.d_head ** 0.5)\n",
    "pos_by_pos_pattern = torch.softmax(masked_scaled, dim=-1)\n",
    "\n",
    "# The largest W_E W_QK W_E affinities are all random punctuation and the like.\n",
    "# top_indices = torch.topk(pos_by_pos_pattern.flatten(), 1000, dim=-1).indices.cpu().numpy()\n",
    "# first_tokens, second_tokens = np.unravel_index(top_indices, pos_by_pos_pattern.shape)\n",
    "# print(list(zip(model.to_str_tokens(first_tokens), model.to_str_tokens(second_tokens))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batched_dot_product(x: torch.Tensor, y: torch.Tensor):\n",
    "    return torch.vmap(torch.dot)(x, y)\n",
    "    \n",
    "def neuron_to_context_neuron_DLA(\n",
    "        model: HookedTransformer, \n",
    "        prompt: str | list[str], \n",
    "        pos=np.s_[-1:], \n",
    "        context_neuron=tuple[int, int]\n",
    ") -> tuple[Float[Tensor, \"component\"], list[str]]:\n",
    "    '''Gets full resid decomposition including all neurons. Unbatched.'''\n",
    "    tokens = model.to_tokens(prompt)\n",
    "    _, cache = model.run_with_cache(prompt)\n",
    "    layer, neuron = context_neuron\n",
    "    neuron_attrs, neuron_labels = cache.stack_neuron_results(layer, apply_ln=True, return_labels=True, pos_slice=pos)\n",
    "    neuron_attrs = neuron_attrs.squeeze(1)\n",
    "    \n",
    "    answer_residual_direction = model.W_in[layer, :, neuron].unsqueeze(0)  # [1 d_model]\n",
    "\n",
    "    results = []\n",
    "    for i in range(neuron_attrs.shape[1]):\n",
    "        results.append(batched_dot_product(neuron_attrs[:, i], answer_residual_direction.repeat(neuron_attrs.shape[0], 1)))\n",
    "    return torch.stack(results), neuron_labels\n",
    "\n",
    "def resid_to_context_neuron_DLA(\n",
    "        model: HookedTransformer, \n",
    "        prompt: str | list[str], \n",
    "        pos=np.s_[-1:], \n",
    "        context_neuron:tuple[int, int]=(0,0)\n",
    ") -> tuple[Float[Tensor, \"component\"], list[str]]:\n",
    "    '''Gets full resid decomposition including all neurons. Unbatched.'''\n",
    "    tokens = model.to_tokens(prompt)\n",
    "    _, cache = model.run_with_cache(prompt)\n",
    "    layer, neuron = context_neuron\n",
    "    all_attrs, labels = cache.get_full_resid_decomposition(layer, apply_ln=True, return_labels=True, pos_slice=pos)\n",
    "    all_attrs = all_attrs.squeeze(1)\n",
    "    \n",
    "    answer_residual_direction = model.W_in[layer, :, neuron].unsqueeze(0)  # [1 d_model]\n",
    "\n",
    "    results = []\n",
    "    for i in range(all_attrs.shape[1]):\n",
    "        results.append(batched_dot_product(all_attrs[:, i], answer_residual_direction.repeat(all_attrs.shape[0], 1)))\n",
    "    return torch.stack(results), labels\n",
    "\n",
    "def get_neuron_mean_acts(model: HookedTransformer, data: list[str], layer_neuron_dict: dict[int, list[int]]) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    sorted_layer_neuron_tuples = []\n",
    "    sorted_acts = []\n",
    "\n",
    "    for layer, neurons in layer_neuron_dict.items():\n",
    "        mean_acts = haystack_utils.get_mlp_activations(data, layer, model, context_crop_start=0, hook_pre=False, neurons=neurons, disable_tqdm=True)\n",
    "        sorted_layer_neuron_tuples.extend([(layer, neuron) for neuron in neurons])\n",
    "        sorted_acts.extend(mean_acts)\n",
    "        assert len(sorted_layer_neuron_tuples) == len(sorted_acts)\n",
    "\n",
    "    return sorted_layer_neuron_tuples, sorted_acts\n",
    "\n",
    "def get_unspecified_neurons(model: HookedTransformer, layer_neuron_dict: dict[int, list[int]]):\n",
    "    unspecified = []\n",
    "    for layer in range(model.cfg.n_layers):\n",
    "        for neuron in range(model.cfg.d_mlp):\n",
    "            if not neuron in layer_neuron_dict[layer]:\n",
    "                unspecified.append((layer, neuron))\n",
    "    return unspecified\n",
    "\n",
    "def get_neuron_loss_increases(model: HookedTransformer, data: list[str], prompt: str, positionwise: bool=False) -> torch.Tensor:\n",
    "    n_tokens = model.to_tokens(prompt).shape[1] - 1\n",
    "    original_loss = model([prompt], return_type='loss', loss_per_token=positionwise)\n",
    "    \n",
    "    losses = []\n",
    "    for layer in trange(model.cfg.n_layers):\n",
    "        mean_acts = haystack_utils.get_mlp_activations(data[:200], layer, model, disable_tqdm=True, context_crop_start=0)\n",
    "        for neuron in range(model.cfg.d_mlp):\n",
    "            hook = hook_utils.get_ablate_neuron_hook(layer, neuron, mean_acts[neuron])\n",
    "            with model.hooks([hook]):\n",
    "                ablated_loss = model([prompt], return_type='loss', loss_per_token=positionwise)\n",
    "                losses.append((ablated_loss - original_loss)[0])\n",
    "    return torch.stack(losses).reshape(n_tokens, model.cfg.n_layers * model.cfg.d_mlp)\n",
    "\n",
    "def compare_dla_and_ablation(model: HookedTransformer, dla_attrs_by_neuron: torch.Tensor, ablation_losses_by_neuron: torch.Tensor, num_neurons=20):\n",
    "    print(\"DLA:\")\n",
    "    values, indices = torch.topk(dla_attrs_by_neuron, num_neurons, dim=-1)\n",
    "    layer_indices, neuron_indices = np.unravel_index(indices.cpu().numpy(), (model.cfg.n_layers, model.cfg.d_mlp))\n",
    "    print(list(zip(layer_indices.tolist(), neuron_indices.tolist())))\n",
    "    print(dla_attrs_by_neuron[indices.tolist()])\n",
    "\n",
    "    print(\"Ablation:\")\n",
    "    loss_increases_by_neuron = ablation_losses_by_neuron\n",
    "    values, indices = torch.topk(loss_increases_by_neuron, num_neurons)\n",
    "    layer_indices, neuron_indices = np.unravel_index(indices.cpu().numpy()[:num_neurons], (model.cfg.n_layers, model.cfg.d_mlp))\n",
    "    print(list(zip(layer_indices.tolist(), neuron_indices.tolist())))\n",
    "    print(dla_attrs_by_neuron[indices.tolist()])\n",
    "\n",
    "def get_hook_inputs_for_token_index(model: HookedTransformer, data: list[str], loss_increases_by_neuron: torch.Tensor, k=40):\n",
    "    values, indices = torch.topk(loss_increases_by_neuron, k)\n",
    "\n",
    "    layer_indices, neuron_indices = np.unravel_index(indices.cpu().numpy(), (model.cfg.n_layers, model.cfg.d_mlp))\n",
    "    layer_neuron_dict = defaultdict(list)\n",
    "    for layer, neuron in zip(layer_indices, neuron_indices):\n",
    "        layer_neuron_dict[layer].append(neuron)\n",
    "\n",
    "    sorted_dla_layer_neuron_tuples = []\n",
    "    sorted_acts = []\n",
    "    for layer, neurons in layer_neuron_dict.items():\n",
    "        mean_acts = haystack_utils.get_mlp_activations(data, layer, model, context_crop_start=0, neurons=neurons, disable_tqdm=True)\n",
    "        sorted_dla_layer_neuron_tuples.extend([(layer, neuron) for neuron in neurons])\n",
    "        sorted_acts.extend(mean_acts)\n",
    "        assert len(sorted_dla_layer_neuron_tuples) == len(sorted_acts)\n",
    "\n",
    "    return sorted_dla_layer_neuron_tuples, sorted_acts\n",
    "\n",
    "def unravel_top_k(neuron_attrs: torch.Tensor, k: int=10):\n",
    "    values, indices = torch.topk(neuron_attrs, k)\n",
    "    layer_indices, neuron_indices = np.unravel_index(indices.cpu().numpy(), (model.cfg.n_layers, model.cfg.d_mlp))\n",
    "    return list(zip(layer_indices.tolist(), neuron_indices.tolist()))\n",
    "\n",
    "def resid_to_head_DLA(\n",
    "        model: HookedTransformer, \n",
    "        prompt: str | list[str], \n",
    "        head: tuple[int, int],\n",
    "        pos=np.s_[-1:], \n",
    "        \n",
    ") -> tuple[Float[Tensor, \"component\"], list[str]]:\n",
    "    '''Gets full resid decomposition and return the composition of each element of the given K matrix. Unbatched.'''\n",
    "    tokens = model.to_tokens(prompt)\n",
    "    _, cache = model.run_with_cache(prompt)\n",
    "    layer, head_index = head\n",
    "    all_attrs, labels = cache.get_full_resid_decomposition(layer, apply_ln=True, return_labels=True, pos_slice=pos)\n",
    "    all_attrs = all_attrs.squeeze(1)\n",
    "    answer_residual_direction = model.W_K[layer, head_index, :]\n",
    "    results = torch.zeros(all_attrs.shape[1], all_attrs.shape[0], answer_residual_direction.shape[1])\n",
    "    for i in range(all_attrs.shape[1]): # for each token\n",
    "        for j in range(answer_residual_direction.shape[1]): # for each direction in head input\n",
    "            token_attrs = all_attrs[:, i]\n",
    "            answer = answer_residual_direction[:, j].unsqueeze(0).repeat(token_attrs.shape[0], 1)\n",
    "            results[i, :, j] = batched_dot_product(token_attrs, answer)\n",
    "    return results, labels\n",
    "\n",
    "def resid_to_head_DLA_custom(\n",
    "        model: HookedTransformer, \n",
    "        prompt: str | list[str], \n",
    "        head: tuple[int, int]\n",
    "        \n",
    ") -> tuple[Float[Tensor, \"component\"], list[str]]:\n",
    "    '''For last two tokens, figure out which components contribute the most to them paying attention to each other.'''\n",
    "    _, cache = model.run_with_cache(prompt)\n",
    "    layer, head_index = head\n",
    "\n",
    "    all_attrs, labels = cache.get_full_resid_decomposition(layer, apply_ln=True, return_labels=True, pos_slice=np.s_[-2:])\n",
    "    all_attrs = all_attrs.squeeze(1).permute(1, 0, 2)\n",
    "\n",
    "    W_QK = model.W_Q[layer, head_index] @ model.W_K[layer, head_index].T\n",
    "\n",
    "    pos_by_pos_scores = all_attrs[0] @ W_QK @ all_attrs[1].T\n",
    "    masked_scaled = mask_scores(pos_by_pos_scores / model.cfg.d_head ** 0.5)\n",
    "    pos_by_pos_pattern = torch.softmax(masked_scaled, dim=-1)\n",
    "    return pos_by_pos_pattern, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tried to stack head results when they weren't cached. Computing head results now\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>                            <div id=\"8104c951-3168-4d7a-a3e6-82f9abc58c39\" class=\"plotly-graph-div\" style=\"height:500px; width:600px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"8104c951-3168-4d7a-a3e6-82f9abc58c39\")) {                    Plotly.newPlot(                        \"8104c951-3168-4d7a-a3e6-82f9abc58c39\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"x\":[\"L0H0\",\"L0H1\",\"L0H2\",\"L0H3\",\"L0H4\",\"L0H5\",\"L0H6\",\"L0H7\",\"L1H0\",\"L1H1\",\"L1H2\",\"L1H3\",\"L1H4\",\"L1H5\",\"L1H6\",\"L1H7\"],\"y\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15],\"z\":[[1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.4632693827152252,0.5367306470870972,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.34489163756370544,0.3307472765445709,0.32436108589172363,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.27641531825065613,0.26621687412261963,0.2210569679737091,0.23631085455417633,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.19541077315807343,0.21793724596500397,0.20045094192028046,0.18750615417957306,0.19869489967823029,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.1773979365825653,0.17918738722801208,0.16381609439849854,0.14936736226081848,0.17196772992610931,0.1582634598016739,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.10423929244279861,0.07342479377985,0.09165821969509125,0.08870353549718857,0.09311579167842865,0.12011886388063431,0.4287394881248474,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.15495333075523376,0.13144241273403168,0.11882641166448593,0.1331070363521576,0.12676440179347992,0.1238594800233841,0.08112625777721405,0.12992072105407715,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.11088477075099945,0.10911522060632706,0.10933369398117065,0.11862803995609283,0.11190470308065414,0.11174085736274719,0.10447848588228226,0.10914120078086853,0.1147729903459549,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.09957027435302734,0.09910217672586441,0.10169021785259247,0.10138300061225891,0.09730175882577896,0.1002226322889328,0.1012478619813919,0.09657914191484451,0.10082966834306717,0.10207322239875793,0.0,0.0,0.0,0.0,0.0,0.0],[0.09420011192560196,0.0924152135848999,0.08860649168491364,0.09327691793441772,0.0888608992099762,0.08818919956684113,0.0919017493724823,0.09064753353595734,0.08973709493875504,0.08933437615633011,0.09283044189214706,0.0,0.0,0.0,0.0,0.0],[0.0831414982676506,0.07038877159357071,0.08325966447591782,0.09588497877120972,0.07681271433830261,0.07859893888235092,0.07436787337064743,0.07894647121429443,0.08342412114143372,0.08466894179582596,0.08003688603639603,0.11046912521123886,0.0,0.0,0.0,0.0],[0.07209912687540054,0.057090550661087036,0.06085796654224396,0.07209755480289459,0.059755921363830566,0.06522641330957413,0.16246257722377777,0.04990190267562866,0.06312073022127151,0.06591323763132095,0.061891768127679825,0.06782718002796173,0.1417551189661026,0.0,0.0,0.0],[0.07114749401807785,0.07229353487491608,0.07250771671533585,0.07298088073730469,0.07291069626808167,0.07236993312835693,0.057146813720464706,0.07477374374866486,0.0719507560133934,0.07386544346809387,0.07298771291971207,0.07380769401788712,0.06405799835920334,0.07719960063695908,0.0,0.0],[0.06947960704565048,0.06685042381286621,0.06429514288902283,0.06740909069776535,0.06559551507234573,0.06610486656427383,0.07004039734601974,0.06466044485569,0.06606858223676682,0.06529852002859116,0.06612326204776764,0.06833826005458832,0.06830388307571411,0.06566251814365387,0.0657694861292839,0.0],[0.062147680670022964,0.06271183490753174,0.06356088072061539,0.06378868967294693,0.0621042437851429,0.06226065382361412,0.0649493858218193,0.05979595705866814,0.06245478615164757,0.06226305291056633,0.06229107081890106,0.061670150607824326,0.06337299942970276,0.0620250403881073,0.06223311275243759,0.06237052008509636]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"x: %{x}\\u003cbr\\u003ey: %{y}\\u003cbr\\u003ecolor: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"scaleanchor\":\"y\",\"constrain\":\"domain\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\",\"constrain\":\"domain\"},\"coloraxis\":{\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"margin\":{\"t\":60},\"autosize\":false,\"width\":600,\"height\":500},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('8104c951-3168-4d7a-a3e6-82f9abc58c39');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pattern, labels = resid_to_head_DLA_custom(model, german_prompt[:20], (2, 5))\n",
    "subset_tensor = pattern[:16, :16].cpu().numpy()\n",
    "df = pd.DataFrame(subset_tensor, columns=labels[:16])\n",
    "fig = px.imshow(df)\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=600,\n",
    "    height=500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'resid_to_head_DLA_custom' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m test_prompt \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m given the generally greater adeptness of children ich bin\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m results, labels \u001b[39m=\u001b[39m resid_to_head_DLA_custom(model, test_prompt, (\u001b[39m2\u001b[39m, \u001b[39m5\u001b[39m))\n\u001b[1;32m      4\u001b[0m results[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'resid_to_head_DLA_custom' is not defined"
     ]
    }
   ],
   "source": [
    "test_prompt = \" given the generally greater adeptness of children ich bin\"\n",
    "results, labels = resid_to_head_DLA(model, test_prompt, (2, 5), pos=np.s_[-2:])\n",
    "\n",
    "results[-1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upstream_for_prompt(prompt):\n",
    "    n_tokens = model.to_tokens(prompt).shape[1]\n",
    "    neuron_attrs_by_token, labels = neuron_to_context_neuron_DLA(model, prompt, np.s_[-n_tokens:], (3, 669))\n",
    "\n",
    "    counter = Counter()\n",
    "    for i in range(n_tokens):\n",
    "        counter.update(unravel_top_k(neuron_attrs_by_token[i], k=10))\n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2, 1449 reoccurs\n",
    "# print(\"sample prompt:\", upstream_for_prompt(german_prompt).most_common())\n",
    "n_tokens = model.to_tokens(german_prompt).shape[1]\n",
    "\n",
    "prompts = [] # german_prompt, english_prompt\n",
    "for token in [\" ä\", \" ö\", \" ü\", \" ß\"]:\n",
    "    prompts.append(\"\".join([token for _ in range(n_tokens)]))\n",
    "    print(token, upstream_for_prompt(prompts[-1]).most_common())\n",
    "\n",
    "neuron_attrs_by_token, labels = neuron_to_context_neuron_DLA(model, german_prompt, np.s_[-n_tokens:], (3, 669))\n",
    "\n",
    "# fig = px.histogram(neuron_attrs_by_token[3].cpu())\n",
    "# fig.show()\n",
    "\n",
    "# neuron_attrs_by_token, labels = neuron_to_context_neuron_DLA(model, english_prompt, np.s_[-n_tokens:], (3, 669))\n",
    "\n",
    "# fig = px.histogram(neuron_attrs_by_token[3].cpu())\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:42: UserWarning:\n",
      "\n",
      "Metric `SpearmanCorrcoef` will save all targets and predictions in the buffer. For large datasets, this may lead to large memory footprint.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9277, 0.9443, 0.9657, 0.7451])\n",
      "['0.467906', '0.456237', '0.246673', '0.520210', '0.170303', '0.207521']\n"
     ]
    }
   ],
   "source": [
    "# Get the rank correlation within long prompts of different types\n",
    "# Hopefully it's highly correlated\n",
    "# Get the rank correlation between samples or average of prompts of different types\n",
    "spearman = SpearmanCorrCoef()\n",
    "\n",
    "prompt_mean_rhos = torch.zeros(len(prompts))\n",
    "for prompt_n, prompt in enumerate(prompts):\n",
    "    n_tokens = model.to_tokens(prompt).shape[1]\n",
    "    neuron_attrs_by_token, _ = neuron_to_context_neuron_DLA(model, prompt, np.s_[-n_tokens:], (3, 669)) # tokens d_mlp\n",
    "    average_neuron_attrs = neuron_attrs_by_token.mean(dim=0) # d_mlp\n",
    "\n",
    "    rhos = torch.zeros(n_tokens)\n",
    "    for i in range(n_tokens):\n",
    "        rhos[i] = spearman(neuron_attrs_by_token[i], average_neuron_attrs)\n",
    "    prompt_mean_rhos[prompt_n] = rhos.mean()\n",
    "\n",
    "print(prompt_mean_rhos)\n",
    "\n",
    "average_neuron_attrs = []\n",
    "for prompt_n, prompt in enumerate(prompts):\n",
    "    n_tokens = model.to_tokens(prompt).shape[1]\n",
    "    neuron_attrs_by_token, _ = neuron_to_context_neuron_DLA(model, prompt, np.s_[-n_tokens:], (3, 669))\n",
    "    average_neuron_attrs.append(neuron_attrs_by_token.mean(dim=0))\n",
    "    \n",
    "rhos = []\n",
    "for i in range(len(average_neuron_attrs)):\n",
    "    for j in range(i + 1, len(average_neuron_attrs)):\n",
    "        if i == j:\n",
    "            continue\n",
    "        rhos.append(f'{spearman(average_neuron_attrs[i], average_neuron_attrs[j]).item():2f}')\n",
    "\n",
    "print(rhos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First run\n",
    "\n",
    "\n",
    "Ablate each neuron in turn and look at how it affects the context neuron value (meaned over all prompts)\n",
    "\n",
    "Check whether it activates for German words in an English context, both single common german chars and a full word\n",
    "Ablate each neuron in turn and look at how it affects the context neuron value (meaned over a German token position within an English)\n",
    "\n",
    "Collect a list\n",
    "\n",
    "Look for head that moves German tokens\n",
    "Look for head that moves German n-grams\n",
    "Look for n-gram detector and see if it moves from there\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.1671, -0.1619, -0.0637, -0.0139, -0.0676, -0.1653, -0.1330, -0.0700,\n",
      "        -0.1339, -0.1104,  0.2194,  2.8279], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Measure context neuron activation for many German tokens that never coalesce into German words\n",
    "# Measure context neuron activation for English words with a single German token mixed in\n",
    "# Measure above but make it semantically clear in the English that a German token is about to appear\n",
    "# Measure above but with a full German word\n",
    "# Measure above but semantically clear in English\n",
    "\n",
    "# Optional (if time permits):\n",
    "# Measure above but with common German unigrams\n",
    "\n",
    "# Need a way to measure at position\n",
    "\n",
    "test_prompt = \" given the generally greater adeptness of children ich\"\n",
    "test_prompt = \" given the generally greater adeptness of children ich bin\"\n",
    "# test_prompt = \" given the generally greater adeptness of children ich bin heute\"\n",
    "_, cache = model.run_with_cache(test_prompt)\n",
    "print(cache['blocks.3.mlp.hook_post'][0, :, 669])\n",
    "\n",
    "\n",
    "# check English tokenization, use ' und ' ' ich'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tried to stack head results when they weren't cached. Computing head results now\n"
     ]
    }
   ],
   "source": [
    "# items, labels = haystack_utils.DLA([test_prompt], model)\n",
    "\n",
    "items, labels = resid_to_context_neuron_DLA(model, test_prompt, context_neuron=(3, 669))\n",
    "# haystack_utils.line(items[0].cpu(), xticks=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>                            <div id=\"8f692aeb-8727-4760-a071-16b26416e947\" class=\"plotly-graph-div\" style=\"height:525px; width:800px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"8f692aeb-8727-4760-a071-16b26416e947\")) {                    Plotly.newPlot(                        \"8f692aeb-8727-4760-a071-16b26416e947\",                        [{\"hovertemplate\":\"variable=0\\u003cbr\\u003eindex=%{x}\\u003cbr\\u003evalue=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"0\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"0\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39],\"xaxis\":\"x\",\"y\":[0.002088308334350586,0.1444474458694458,0.3546367585659027,-0.06780257821083069,0.08851706981658936,0.0889049619436264,0.0941934883594513,0.22725149989128113,-0.09667462855577469,0.056362710893154144,0.1906663328409195,-0.06949122995138168,0.25177568197250366,0.09449432790279388,-0.024621164426207542,0.025522436946630478,0.04925411194562912,0.0683869943022728,-0.028935719281435013,0.02602200210094452,0.18807007372379303,3.6586594581604004,-0.0034448131918907166,0.06468778848648071,-0.0005175511469133198,0.0035867118276655674,-0.0029818161856383085,-0.0074820430018007755,-0.0015235834289342165,0.00226035644300282,-0.0009205900132656097,0.0019801906310021877,-0.005774284712970257,0.001626266399398446,0.016917165368795395,-0.002980566117912531,-0.00269389059394598,-0.0011445090640336275,0.003015659749507904,-0.013643576763570309],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"\"},\"tickmode\":\"array\",\"tickvals\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39],\"ticktext\":[\"L0H0\",\"L0H1\",\"L0H2\",\"L0H3\",\"L0H4\",\"L0H5\",\"L0H6\",\"L0H7\",\"L1H0\",\"L1H1\",\"L1H2\",\"L1H3\",\"L1H4\",\"L1H5\",\"L1H6\",\"L1H7\",\"L2H0\",\"L2H1\",\"L2H2\",\"L2H3\",\"L2H4\",\"L2H5\",\"L2H6\",\"L2H7\",\"L0N0\",\"L0N1\",\"L0N2\",\"L0N3\",\"L0N4\",\"L0N5\",\"L0N6\",\"L0N7\",\"L0N8\",\"L0N9\",\"L0N10\",\"L0N11\",\"L0N12\",\"L0N13\",\"L0N14\",\"L0N15\"],\"range\":[-0.2,39.2]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"width\":800,\"showlegend\":true},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('8f692aeb-8727-4760-a071-16b26416e947');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "haystack_utils.line(items[0, :40].cpu(), xticks=labels[:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<|endoftext|>', ' given', ' the', ' generally', ' greater', ' ad', 'ept', 'ness', ' of', ' children', ' ich', ' bin']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style='max-width: 300px; max-height: 300px; padding: 20px;'>\n",
       "            <div id=\"circuits-vis-73a23a9b-d9ac\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, AttentionPattern } from \"https://unpkg.com/circuitsvis@1.40.1/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-73a23a9b-d9ac\",\n",
       "      AttentionPattern,\n",
       "      {\"tokens\": [\"<|endoftext|>\", \" given\", \" the\", \" generally\", \" greater\", \" ad\", \"ept\", \"ness\", \" of\", \" children\", \" ich\", \" bin\"], \"attention\": [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.38292038440704346, 0.6170796155929565, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.40418052673339844, 0.4641099274158478, 0.1317095309495926, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4077094495296478, 0.19677691161632538, 0.09123349189758301, 0.304280161857605, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.48844972252845764, 0.1777666062116623, 0.09431897103786469, 0.1402750313282013, 0.09918973594903946, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4338633418083191, 0.12468212842941284, 0.1798505336046219, 0.08391767740249634, 0.06682445108890533, 0.1108618825674057, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4228573739528656, 0.05857255309820175, 0.09684813767671585, 0.05881066992878914, 0.06868778169155121, 0.06309432536363602, 0.2311292141675949, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5150706768035889, 0.0532209649682045, 0.028896857053041458, 0.0740375965833664, 0.063443623483181, 0.023601267486810684, 0.14908982813358307, 0.09263919293880463, 0.0, 0.0, 0.0, 0.0], [0.46110039949417114, 0.09533107280731201, 0.07822700589895248, 0.06142660230398178, 0.047260284423828125, 0.019056295976042747, 0.07927367091178894, 0.07156116515398026, 0.0867634266614914, 0.0, 0.0, 0.0], [0.39768874645233154, 0.09206660836935043, 0.0344347208738327, 0.058102332055568695, 0.06029237061738968, 0.042695749551057816, 0.07656775414943695, 0.05073842406272888, 0.06254489719867706, 0.12486841529607773, 0.0, 0.0], [0.4473658502101898, 0.05303807184100151, 0.14109167456626892, 0.006907439325004816, 0.01274929940700531, 0.021584615111351013, 0.05789531394839287, 0.027820883318781853, 0.018371785059571266, 0.026769859716296196, 0.18640519678592682, 0.0], [0.1565985083580017, 0.05220329761505127, 0.04348326474428177, 0.008560513146221638, 0.015288634225726128, 0.017784113064408302, 0.03905823454260826, 0.017686011269688606, 0.017141982913017273, 0.02947787195444107, 0.5415358543395996, 0.0611816942691803]]}\n",
       "    )\n",
       "    </script>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<__main__.SizeLimitedObject at 0x7f6d877f30a0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import circuitsvis\n",
    "\n",
    "class SizeLimitedObject:\n",
    "    def __init__(self, obj, max_width='500px', max_height='500px'):\n",
    "        self.obj = obj\n",
    "        self.max_width = max_width\n",
    "        self.max_height = max_height\n",
    "\n",
    "    def _repr_html_(self):\n",
    "        return f\"\"\"\n",
    "        <div style='max-width: {self.max_width}; max-height: {self.max_height}; padding: 20px;'>\n",
    "            {self.obj._repr_html_()}\n",
    "        </div>\n",
    "        \"\"\"\n",
    "\n",
    "tokens = model.to_str_tokens(model.to_tokens(test_prompt)[0])\n",
    "print(tokens)\n",
    "\n",
    "head_attention = circuitsvis.attention.attention_pattern(tokens=tokens, attention=cache['blocks.2.attn.hook_pattern'][0, 5, :, :])\n",
    "sized_viz = SizeLimitedObject(head_attention, max_height='300px', max_width='300px')\n",
    "sized_viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<|endoftext|>', ' given', ' the', ' generally', ' greater', ' ad', 'ept', 'ness', ' of', ' children', ' ich', ' bin']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style='max-width: 300px; max-height: 300px; padding: 20px;'>\n",
       "            <div id=\"circuits-vis-8b233957-7326\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, AttentionPattern } from \"https://unpkg.com/circuitsvis@1.40.1/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-8b233957-7326\",\n",
       "      AttentionPattern,\n",
       "      {\"tokens\": [\"<|endoftext|>\", \" given\", \" the\", \" generally\", \" greater\", \" ad\", \"ept\", \"ness\", \" of\", \" children\", \" ich\", \" bin\"], \"attention\": [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9896306395530701, 0.010369409807026386, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8154661655426025, 0.01396873313933611, 0.17056508362293243, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9100556373596191, 0.01900622807443142, 0.0562528520822525, 0.01468532532453537, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9089993834495544, 0.009036671370267868, 0.048758700489997864, 0.020837128162384033, 0.012368163093924522, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.893824577331543, 0.003816701704636216, 0.06830985844135284, 0.009255518205463886, 0.007440214045345783, 0.017353087663650513, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8741719126701355, 0.0023187792394310236, 0.061527229845523834, 0.007558194920420647, 0.0090409554541111, 0.04045884311199188, 0.004924035165458918, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8570711016654968, 0.010715845972299576, 0.0388299934566021, 0.006996987387537956, 0.007565699052065611, 0.034272823482751846, 0.02132454887032509, 0.023223018273711205, 0.0, 0.0, 0.0, 0.0], [0.7335038781166077, 0.008792842738330364, 0.04479844123125076, 0.013022185303270817, 0.012540486641228199, 0.026591818779706955, 0.011190946213901043, 0.020931951701641083, 0.1286274790763855, 0.0, 0.0, 0.0], [0.8436731100082397, 0.004253617953509092, 0.04015034809708595, 0.007567297667264938, 0.009247374720871449, 0.02078685164451599, 0.02563699521124363, 0.016233183443546295, 0.025963377207517624, 0.006487823557108641, 0.0, 0.0], [0.8299469351768494, 0.003165402915328741, 0.0230528824031353, 0.009475037455558777, 0.0046266973949968815, 0.037406034767627716, 0.006060219369828701, 0.017711849883198738, 0.04248584061861038, 0.016505500301718712, 0.009563605301082134, 0.0], [0.8142880201339722, 0.004258167929947376, 0.03519232198596001, 0.006426705047488213, 0.007830841466784477, 0.018745223060250282, 0.011619588360190392, 0.014615616761147976, 0.042751990258693695, 0.014181552454829216, 0.011368810199201107, 0.018721194937825203]]}\n",
       "    )\n",
       "    </script>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<__main__.SizeLimitedObject at 0x7f6d877f2200>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Head which maybe K composes with the last two tokens and L2H5?\n",
    "tokens = model.to_str_tokens(model.to_tokens(test_prompt)[0])\n",
    "print(tokens)\n",
    "\n",
    "head_attention = circuitsvis.attention.attention_pattern(tokens=tokens, attention=cache['blocks.0.attn.hook_pattern'][0, 6, :, :])\n",
    "sized_viz = SizeLimitedObject(head_attention, max_height='300px', max_width='300px')\n",
    "sized_viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 9.43 GiB (GPU 0; 47.54 GiB total capacity; 28.82 GiB already allocated; 8.44 GiB free; 38.04 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m W_QK \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mW_Q[layer, head_index] \u001b[39m@\u001b[39m model\u001b[39m.\u001b[39mW_K[layer, head_index]\u001b[39m.\u001b[39mT\n\u001b[1;32m     24\u001b[0m \u001b[39m# Bilinear form representing how much attention head token pays to each other token via L2H5\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m pos_by_pos_scores \u001b[39m=\u001b[39m W_E \u001b[39m@\u001b[39;49m W_QK \u001b[39m@\u001b[39;49m W_E\u001b[39m.\u001b[39;49mT\n\u001b[1;32m     27\u001b[0m masked_scaled \u001b[39m=\u001b[39m mask_scores(pos_by_pos_scores \u001b[39m/\u001b[39m model\u001b[39m.\u001b[39mcfg\u001b[39m.\u001b[39md_head \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m0.5\u001b[39m)\n\u001b[1;32m     28\u001b[0m pos_by_pos_pattern \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msoftmax(masked_scaled, dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 9.43 GiB (GPU 0; 47.54 GiB total capacity; 28.82 GiB already allocated; 8.44 GiB free; 38.04 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "def info(tensor: torch.Tensor):\n",
    "    print(tensor.shape, tensor.dtype, \"\\nnan count:\", tensor.isnan().sum().item())\n",
    "\n",
    "tokens = model.to_tokens(english_prompt[:50] + ' ich bin haute')[0]\n",
    "# str_tokens = model.to_str_tokens(tokens)\n",
    "# _, cache = model.run_with_cache(tokens)\n",
    "# head_attention = circuitsvis.attention.attention_pattern(tokens=str_tokens, attention=cache['blocks.2.attn.hook_pattern'][0, 5, :, :])\n",
    "# sized_viz = SizeLimitedObject(head_attention)\n",
    "\n",
    "def mask_scores(attn_scores: Float[Tensor, \"query_nctx key_nctx\"]):\n",
    "    '''Mask the attention scores so that tokens don't attend to previous tokens.'''\n",
    "    # assert attn_scores.shape == (model.cfg.n_ctx, model.cfg.n_ctx)\n",
    "    mask = torch.tril(torch.ones_like(attn_scores)).bool()\n",
    "    neg_inf = torch.tensor(-1.0e6).to(attn_scores.device)\n",
    "    masked_attn_scores = torch.where(mask, attn_scores, neg_inf)\n",
    "    return masked_attn_scores\n",
    "\n",
    "layer = 2\n",
    "head_index = 5\n",
    "\n",
    "haystack_utils.clean_cache()\n",
    "W_E = model.W_E\n",
    "W_QK = model.W_Q[layer, head_index] @ model.W_K[layer, head_index].T\n",
    "# Bilinear form representing how much attention head token pays to each other token via L2H5\n",
    "pos_by_pos_scores = W_E @ W_QK @ W_E.T\n",
    "\n",
    "masked_scaled = mask_scores(pos_by_pos_scores / model.cfg.d_head ** 0.5)\n",
    "pos_by_pos_pattern = torch.softmax(masked_scaled, dim=-1)\n",
    "\n",
    "top_indices = torch.topk(pos_by_pos_pattern.flatten(), 100, dim=-1).indices.cpu().numpy()\n",
    "first_tokens, second_tokens = np.unravel_index(top_indices, pos_by_pos_pattern.shape)\n",
    "print(list(zip(model.to_str_tokens(first_tokens), model.to_str_tokens(second_tokens))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# head_attention = circuitsvis.attention.attention_pattern(tokens=tokens, attention=pos_by_pos_pattern)\n",
    "# sized_viz = SizeLimitedObject(head_attention, max_height='300px', max_width='300px')\n",
    "# sized_viz\n",
    "\n",
    "# from transformer_lens import FactoredMatrix\n",
    "# fm = FactoredMatrix(model.W_Q[layer, head_index], model.W_K[layer, head_index].T)\n",
    "# print(fm.__dict__)\n",
    "\n",
    "# german_tokens = model.to_tokens(\"ich haute de ä ö ü ß\")[0]\n",
    "# subset_tensor = (pos_by_pos_pattern[german_tokens] @ pos_by_pos_pattern).cpu().numpy()\n",
    "\n",
    "# Doesn't show anything interesting, just evenly distributed fractional pattern\n",
    "# subset_tensor = pos_by_pos_pattern[:100, :100].cpu().numpy()\n",
    "# df = pd.DataFrame(subset_tensor)\n",
    "# fig = px.imshow(df)\n",
    "# fig.show()\n",
    "\n",
    "# tokens = model.to_tokens(english_prompt[:300] + ' ich bin haute')[0]\n",
    "# str_tokens = model.to_str_tokens(tokens)\n",
    "# _, cache = model.run_with_cache(tokens)\n",
    "# head_attention = circuitsvis.attention.attention_pattern(tokens=str_tokens, attention=cache['blocks.2.attn.hook_pattern'][0, 5, :, :])\n",
    "# sized_viz = SizeLimitedObject(head_attention)\n",
    "# sized_viz"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
