{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "from transformer_lens import HookedTransformer\n",
    "from jaxtyping import Float, Int, Bool\n",
    "from torch import Tensor\n",
    "from tqdm.auto import tqdm\n",
    "import plotly.io as pio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px \n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from IPython.display import display, HTML\n",
    "from datasets import load_dataset\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import os\n",
    "import plotly.graph_objects as go\n",
    "from scipy.stats import norm\n",
    "from einops import einsum\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pio.renderers.default = \"notebook_connected+notebook\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.autograd.set_grad_enabled(False)\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "import haystack_utils\n",
    "from haystack_utils import get_mlp_activations\n",
    "from hook_utils import get_ablate_neuron_hook, save_activation\n",
    "from pythia_160m_utils import get_neuron_accuracy, ablation_effect\n",
    "import plotting_utils\n",
    "from plotting_utils import plot_neuron_acts, color_binned_histogram\n",
    "import hook_utils\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/tiny_stories_chatgpt.json', 'r') as f:\n",
    "    prompts = json.load(f)\n",
    "\n",
    "filtered_prompts = [prompt for prompt in prompts if not prompt.startswith(\"Once\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model roneneldan/TinyStories-1M into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "model = HookedTransformer.from_pretrained(\"roneneldan/TinyStories-1M\",\n",
    "    center_unembed=True,\n",
    "    center_writing_weights=True,\n",
    "    fold_ln=True,\n",
    "    device=\"cuda\")\n",
    "\n",
    "# large_acts_df = plotting_utils.get_neuron_moments(model, prompts,\n",
    "#                                                   [[i, j] for i in range(8) for j in range(256)], hook_pre=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Once', 'One', 'Yesterday', 'At', 'There', 'Today', 'On', 'Em', 'When', 'In']\n",
      "[' upon', 'bie', 'ancer', 'itting', 'll', 'aj', 'packs', 'upon', 'uttering', ' haven']\n",
      "[' a', ' an', ' the', ' some', ' two', ' something', ' another', ' one', ' very', ' many']\n",
      "[' time', ' day', ' week', ' evening', ' morning', ' afternoon', ' night', ' Sunday', ' way', ' year']\n"
     ]
    }
   ],
   "source": [
    "# Similar words stored near in the embed\n",
    "tokens = model.to_tokens(\"Once upon a time\", prepend_bos=False)\n",
    "logits = model.W_E[tokens].squeeze(0) @ model.W_U\n",
    "\n",
    "for i in range(4):\n",
    "    values, indices = torch.topk(logits[i], 10)\n",
    "    print(model.to_str_tokens(indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-5.6169e-09, device='cuda:0') tensor(0.2188, device='cuda:0')\n",
      "['cow', 'ns', 'ridge', 'wo', ' seventeen', 'eight', 'umbers', 'please', 'ucks', 'icians']\n"
     ]
    }
   ],
   "source": [
    "# Associations\n",
    "tokens = model.to_tokens(\"cow\", prepend_bos=False)\n",
    "associated_tokens = []\n",
    "for string in \"grass brown field moo meat milk udders animal\".split(' '):\n",
    "    token = model.to_tokens(string, prepend_bos=False)\n",
    "    associated_tokens.append(token[0, 0])\n",
    "associated_tokens = torch.stack(associated_tokens)\n",
    "logits = (model.W_E[tokens].squeeze(0) @ model.W_U).squeeze(0)\n",
    "mean_logit = logits.mean(0)\n",
    "mean_associated_logit = logits[associated_tokens].mean(0)\n",
    "\n",
    "print(mean_logit, mean_associated_logit)\n",
    "\n",
    "values, indices = torch.topk(logits, 10)\n",
    "print(model.to_str_tokens(indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ac28344c1cc43d19b9986165aa44803",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, there was a big bear who\n"
     ]
    }
   ],
   "source": [
    "print(model.generate('Once'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7d18ae589e549ba94ccfe738cb0de51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, there was a little girl named Lily. She loved to play outside in the park\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "429269a99d0243f3a97762fedcac7665",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attn 0 Once upon a time, there was a little girl named Lily. She loved to play with her toys and\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89abe66fedf048a89e11a33545794d2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP 0 Once time time time time time time time time time time time time time time time time time time time time\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bb3f181c64a4935afb950136fcc37da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attn 1 Once upon a time, there was a little girl named Lily and she went on a big day playing outside\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bf34bd5299747c49c47ead476cfe53e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP 1 Once,,,,,,,,,,,,,,,,,,,,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0683bb0e9f3e4cd2b8522b1346d665f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attn 2 Once upon a time, there was a big little little little little little little little little little little little little\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6be3ebbcb5e74a22b079099cdbd210e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP 2 Once, to a pretty pretty pretty pretty pretty pretty pretty pretty pretty. to look to the blue blue blue\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9669d3c8904d404e8fd63d95c0562861",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attn 3 Once upon a time, in a big, big, big, big, big, big, big,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4593140b7bcc490ba794d4b9bc12b2d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP 3 Once,, little little little little little little little little little little little little little little little little little little\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ced4136fd3d64940b2c95690e811cc88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attn 4 Once upon a time, there was a little girl named Lilymymymymymymymymymy\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e74fa20805d4d08997b58b5f76d979e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP 4 Once were her mommy asked to pack inside,\"Mommy\" oh oh oh oh oh oh oh\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "549a42c07e1b4f89b0bec1292c657c25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attn 5 Once upon a time, a little girl named Lily. She loved to play outside in the forest. One\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daa2a6b3616948d79e5d77b4e6b16826",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP 5 Once mom,,,,, but then,,, but then,,,, but then,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bca0765de66149c5957ce7b2531835cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attn 6 Once upon a time, there was a little girl named Lily. She was very sad and her favorite toy\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8259fe7ac328431eae3de23d77724445",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP 6 Once upon a time, upon a a a a a a a a a and princess. She and princess\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42f512e6d2364608af4363047e68e96c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attn 7 Once upon a time, there was a little girl named Timmy. Timmy was very sad because he\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e86a49d31ccf48849952b5929d1b9d7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP 7 Once?\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate heaps of token sequences and average their cache, then find the difference with the OUAT neurons\n",
    "# Ablate components until OUAT fails\n",
    "# n-l AND?\n",
    "\n",
    "_, cache = model.run_with_cache(model.to_tokens(prompts)[:, :40])\n",
    "\n",
    "def rand_hook(value, hook):\n",
    "    cache_val = cache[hook.name][:value.size(0), :value.size(1), :value.size(2)]\n",
    "    mean_val = cache_val.mean(dim=0)\n",
    "    broadcasted_val = mean_val.unsqueeze(0).expand_as(value)\n",
    "    value = broadcasted_val\n",
    "    return value\n",
    "\n",
    "prompt = \"Once\"\n",
    "print(model.generate(prompt, 20, temperature=0))\n",
    "for layer in range(model.cfg.n_layers):\n",
    "    with model.hooks([(f'blocks.{layer}.hook_attn_out', rand_hook)]):\n",
    "        print(f\"Attn {layer}\", model.generate(prompt, 20, temperature=0))\n",
    "    with model.hooks([(f'blocks.{layer}.hook_mlp_out', rand_hook)]):\n",
    "        print(f\"MLP {layer}\", model.generate(prompt, 20, temperature=0))\n",
    "\n",
    "# Necessary components:\n",
    "# MLP0, MLP1, MLP2, MLP3, MLP4, MLP5, MLP7 (every MLP but 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ablate by cosine sim - degrades around 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure out which neurons directly write to each vocab\n",
    "# And see if we can ablate everything else\n",
    "\n",
    "tokens = model.to_tokens(\"Once upon a time\", prepend_bos=False)  # [1, 4]\n",
    "token_dirs = model.tokens_to_residual_directions(tokens)[0]  # [4, 64]\n",
    "token_dirs_reshaped = token_dirs.unsqueeze(1).unsqueeze(1)  # [4, 1, 1, 64]\n",
    "W_out_reshaped = model.W_out.unsqueeze(0)  # [1, 8, 256, 64]\n",
    "\n",
    "cosine_sim = torch.nn.CosineSimilarity(dim=-1, eps=1e-6)\n",
    "result = cosine_sim(token_dirs_reshaped, W_out_reshaped)  # [4, 8, 256]\n",
    "\n",
    "_, cache = model.run_with_cache(tokens)\n",
    "acts = [cache[f'blocks.{layer}.mlp.hook_post'][0] for layer in range(model.cfg.n_layers)] # [[batch pos]]*n_layers\n",
    "acts = torch.stack(acts, dim=1) # \n",
    "\n",
    "\n",
    "layer_neuron_tuples = []\n",
    "for token_index in range(result.size(0)):\n",
    "    values, indices = torch.topk(result[token_index].view(-1), 20, dim=-1)\n",
    "    layer_indices, neuron_indices = np.unravel_index(indices.cpu().numpy(), (8, 256))\n",
    "    layer_neuron_tuples.extend(zip(layer_indices.tolist(), neuron_indices.tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfe68b77dff24c43bc388aa7d4b3deb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once in a time, a little girl named Amy was\n"
     ]
    }
   ],
   "source": [
    "layer_neuron_dict = haystack_utils.get_neurons_by_layer(layer_neuron_tuples)\n",
    "\n",
    "sorted_layer_neuron_tuples = []\n",
    "sorted_acts = []\n",
    "\n",
    "for layer in layer_neuron_dict.keys():\n",
    "    neurons = layer_neuron_dict[layer]\n",
    "    mean_acts = haystack_utils.get_mlp_activations(filtered_prompts, layer, model, context_crop_start=2, hook_pre=False, neurons=neurons, disable_tqdm=True)\n",
    "    sorted_layer_neuron_tuples.extend([(layer, neuron) for neuron in neurons])\n",
    "    sorted_acts.extend(mean_acts)\n",
    "    assert len(sorted_layer_neuron_tuples) == len(sorted_acts)\n",
    "\n",
    "hooks = hook_utils.get_ablate_context_neurons_hooks(sorted_layer_neuron_tuples, sorted_acts)\n",
    "with model.hooks(hooks):\n",
    "    print(model.generate(\"Once\", 10, temperature=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ablate by DLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batched_dot_product(x, y):\n",
    "    return torch.vmap(torch.dot)(x, y)\n",
    "    \n",
    "\n",
    "def mlp_DLA(prompt: str, model: HookedTransformer) -> tuple[Float[Tensor, \"component\"], list[str]]:\n",
    "    tokens = model.to_tokens(prompt)\n",
    "    answers = tokens[:, 1:]\n",
    "    tokens = tokens[:, :-1]\n",
    "    answer_residual_directions = model.tokens_to_residual_directions(answers)  # [pos d_model]\n",
    "    _, cache = model.run_with_cache(tokens)\n",
    "    neurons, labels = cache.get_full_resid_decomposition(-1, expand_neurons=True, apply_ln=True, return_labels=True)\n",
    "\n",
    "    results = []\n",
    "    for i in range(4):\n",
    "        results.append(batched_dot_product(neurons.reshape(4, 2179, 64)[i], answer_residual_directions.squeeze(0).unsqueeze(1).repeat(1, 2179, 1)[i]))\n",
    "    return torch.stack(results), labels\n",
    "\n",
    "\n",
    "def get_unspecified_neurons(model: HookedTransformer, neurons: list[tuple[int, int]]):\n",
    "    layer_dict = haystack_utils.get_neurons_by_layer(neurons)\n",
    "    unspecified = []\n",
    "    for layer in range(model.cfg.n_layers):\n",
    "        for neuron in range(model.cfg.d_mlp):\n",
    "            if not neuron in layer_dict[layer]:\n",
    "                unspecified.append((layer, neuron))\n",
    "    return unspecified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tried to stack head results when they weren't cached. Computing head results now\n"
     ]
    }
   ],
   "source": [
    "attrs, labels = mlp_DLA(\"Once upon a time\", model)\n",
    "# haystack_utils.line(neuron_attrs[0].cpu().numpy(), xlabel=\"Correct logit\", ylabel=\"\", title=\"DLA per neuron in layer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_indices = [i for i in range(len(labels)) if 'N' in labels[i]]\n",
    "neuron_labels = [labels[i] for i in neuron_indices]\n",
    "neuron_attrs = attrs[:, neuron_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3, 238), (0, 4), (0, 35), (0, 5), (0, 34)]\n",
      "[(0, 78), (0, 22), (2, 236), (2, 125), (5, 164)]\n"
     ]
    }
   ],
   "source": [
    "dla_layer_neuron_tuples = []\n",
    "for token_index in range(4):\n",
    "    values, indices = torch.topk(neuron_attrs[token_index], 5, dim=-1)\n",
    "    layer_indices, neuron_indices = np.unravel_index(indices.cpu().numpy(), (model.cfg.n_layers, model.cfg.d_mlp))\n",
    "    dla_layer_neuron_tuples.extend(zip(layer_indices.tolist(), neuron_indices.tolist()))\n",
    "\n",
    "print(dla_layer_neuron_tuples[:5])\n",
    "print(layer_neuron_tuples[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "587df220bf67490ba77d089ba8cf7244",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, there was a little girl named\n"
     ]
    }
   ],
   "source": [
    "layer_neuron_dict = haystack_utils.get_neurons_by_layer(dla_layer_neuron_tuples)\n",
    "\n",
    "sorted_layer_neuron_tuples = []\n",
    "sorted_acts = []\n",
    "\n",
    "for layer in layer_neuron_dict.keys():\n",
    "    neurons = layer_neuron_dict[layer]\n",
    "    mean_acts = haystack_utils.get_mlp_activations(filtered_prompts, layer, model, context_crop_start=2, hook_pre=False, neurons=neurons, disable_tqdm=True)\n",
    "    sorted_layer_neuron_tuples.extend([(layer, neuron) for neuron in neurons])\n",
    "    sorted_acts.extend(mean_acts)\n",
    "    assert len(sorted_layer_neuron_tuples) == len(sorted_acts)\n",
    "\n",
    "hooks = hook_utils.get_ablate_context_neurons_hooks(sorted_layer_neuron_tuples, sorted_acts)\n",
    "with model.hooks(hooks):\n",
    "    print(model.generate(\"Once\", 10, temperature=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17f87bbe35624477ae00d408bf79f4a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OnceOnceOnceOnceOnceOnceOnceOnceOnceOnceOnce\n"
     ]
    }
   ],
   "source": [
    "dla_layer_neuron_tuples = []\n",
    "for token_index in range(4):\n",
    "    values, indices = torch.topk(neuron_attrs[token_index].view(-1), 5, dim=-1)\n",
    "    layer_indices, neuron_indices = np.unravel_index(indices.cpu().numpy(), (8, 256))\n",
    "    dla_layer_neuron_tuples.extend(zip(layer_indices.tolist(), neuron_indices.tolist()))\n",
    "\n",
    "unspecified_neuron_tuples = get_unspecified_neurons(model, dla_layer_neuron_tuples)\n",
    "layer_neuron_dict = haystack_utils.get_neurons_by_layer(unspecified_neuron_tuples)\n",
    "\n",
    "sorted_layer_neuron_tuples = []\n",
    "sorted_acts = []\n",
    "\n",
    "for layer in layer_neuron_dict.keys():\n",
    "    neurons = layer_neuron_dict[layer]\n",
    "    mean_acts = haystack_utils.get_mlp_activations(filtered_prompts, layer, model, context_crop_start=2, hook_pre=False, neurons=neurons, disable_tqdm=True)\n",
    "    sorted_layer_neuron_tuples.extend([(layer, neuron) for neuron in neurons])\n",
    "    sorted_acts.extend(mean_acts)\n",
    "    assert len(sorted_layer_neuron_tuples) == len(sorted_acts)\n",
    "\n",
    "hooks = hook_utils.get_ablate_context_neurons_hooks(sorted_layer_neuron_tuples, sorted_acts)\n",
    "with model.hooks(hooks):\n",
    "    print(model.generate(\"Once\", 10, temperature=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
