{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the German neurons are ablated, the model makes predictions on certain tokens that result in extremely high losses. Investigating these tokens, and the correct \"next token\" prediction, shows that many form German bigrams. The most prevalent are:\n",
    "\n",
    "20 ('id', 'ig')\n",
    "7 ('rt', 'ige')\n",
    "5 (' Vert', 'rag')\n",
    "5 ('he', 'ben')\n",
    "4 ('ät', 'ig')\n",
    "4 ('nd', 'liche')\n",
    "\n",
    "We should run these bigrams with and without the German neurons ablated, then investigate which neurons have the most different activations at the position of the first bigram token. We'll do this using the raw logit difference.\n",
    "\n",
    "Q: should we use single token prompts with the first token in each bigrams, or should we create prompts that end in the bigram?\n",
    "A: we will create prompts the end in the bigram because models behave inconsistently for the first few tokens in each prompt, and we don't want this behaviour affecting our results.\n",
    "\n",
    "Q: how will we create the prompts?\n",
    "A: look at the word the token was used in, use GPT to generate prompts that end in this word.\n",
    "\n",
    "20 ('id', 'ig') - Verteidigung, Verteidiger, Rechtsverteidigung\n",
    "7 ('rt', 'ige') - auswärtige, sofortige, neuartigen\n",
    "5 (' Vert', 'rag') - Vertragsbediensteten, vertraglichen\n",
    "5 ('he', 'ben') - hervorheben, entheben\n",
    "4 ('ät', 'ig') - tätig, Tätigkeit, Berufstätigen, bestätigt, gewalttätigen\n",
    "4 ('nd', 'liche') - gründliche, selbstverständlichen, unmißverständlicher, ländlichen, unmissverständlichere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From GPT4\n",
    "\n",
    "prompts = {}\n",
    "words = ['Verteidigung', 'auswärtige', 'Vertragsbediensteten', 'hervorheben', 'tätig', 'gründliche']\n",
    "\n",
    "prompts['Verteidigung'] = [\n",
    "    'Ich verbringe viel Zeit mit dem Studium der Theorie und Praxis der Verteidigung',\n",
    "    'In seiner Rede betonte der Minister die Notwendigkeit einer starken nationalen Verteidigung'\n",
    "    'Es ist wichtig, dass wir ein geeignetes Budget für die Verteidigung',\n",
    "    'Sein Fokus liegt auf der Verbesserung seiner Techniken in der Verteidigung',\n",
    "    'Das Angriffsspiel ist wichtig, aber wir dürfen die Bedeutung der Verteidigung',\n",
    "    'Als Anwalt hat sie viele Jahre Erfahrung in der Verteidigung',\n",
    "    'Die Verteidigung',\n",
    "    'In der Militärstrategie ist die beste Angriffstaktik oft eine gute Verteidigung',\n",
    "    'Der Anwalt führte eine starke und überzeugende Verteidigung',\n",
    "    'Die Regierung hat die Stärkung der Verteidigung',]\n",
    "\n",
    "prompts['auswärtige'] = [\n",
    "    'Meine Tätigkeit erfordert viele Reisen, daher bin ich oft auswärtige',\n",
    "    'Er ist als diplomatischer Berater für alle auswärtige',\n",
    "    'Der Minister für auswärtige',\n",
    "    'Sie ist Expertin für auswärtige',\n",
    "    'Die Behörde für auswärtige',\n",
    "    'Es ist wichtig, sich über auswärtige',\n",
    "    'Wir sollten uns auf die auswärtige',\n",
    "    'In seiner Rolle überwacht er auswärtige',\n",
    "    'Der Diplomat hat eine lange Karriere in auswärtige',\n",
    "    'Die Universität bietet einen Studiengang in auswärtige']\n",
    "\n",
    "prompts['Vertragsbediensteten'] = [\n",
    "    'Nach seiner Ausbildung begann er seine Karriere als einer der Vertragsbediensteten',\n",
    "    'Das Unternehmen hat eine Reihe von Vertragsbediensteten',\n",
    "    'Die Rechte und Pflichten der Vertragsbediensteten',\n",
    "    'Die Bezahlung der Vertragsbediensteten',\n",
    "    'Wegen des hohen Arbeitsaufkommens werden zusätzliche Vertragsbediensteten',\n",
    "    'Der Status der Vertragsbediensteten',\n",
    "    'Die Gesundheits- und Sicherheitsvorschriften gelten auch für die Vertragsbediensteten',\n",
    "    'Alle Vertragsbediensteten müssen eine Verschwiegenheitserklärung',\n",
    "    'Die Firma plant, das Team der Vertragsbediensteten',\n",
    "    'Die Schulung neuer Vertragsbediensteten']\n",
    "\n",
    "prompts['hervorheben'] = [\n",
    "    'In Ihrem Lebenslauf sollten Sie Ihre besonderen Fähigkeiten und Erfahrungen hervorheben',\n",
    "    'Die hellen Farben im Bild sollen die Dynamik und Energie der Szene hervorheben',\n",
    "    'Bei der Präsentation sollten Sie die Hauptpunkte hervorheben',\n",
    "    'Die Wissenschaftler wollen die Bedeutung ihrer Forschungsergebnisse hervorheben',\n",
    "    'Die Autorin nutzte Metaphern, um die Emotionen ihrer Charaktere hervorheben',\n",
    "    'Mit diesem Marketingstrategieplan wollen wir die Einzigartigkeit unseres Produkts hervorheben',\n",
    "    'Es ist wichtig, in der Debatte die Fakten zu hervorheben',\n",
    "    'In seinem Vortrag versuchte der Redner, die Relevanz des Themas für das Publikum hervorheben',\n",
    "    'Beim Design des Hauses wurde besonderer Wert darauf gelegt, die natürlichen Materialien hervorheben',\n",
    "    'Im Interview konnte sie ihre umfangreichen Kenntnisse und Erfahrungen hervorheben']\n",
    "\n",
    "prompts['tätig'] = [\n",
    "    'Nach seinem Studium war er viele Jahre in der Marketingbranche tätig',\n",
    "    'Sie ist als Freiwillige in einer gemeinnützigen Organisation tätig',\n",
    "    'Ich bin seit über zehn Jahren als Lehrer tätig',\n",
    "    'Er ist hauptsächlich in der Beratung von Start-up-Unternehmen tätig',\n",
    "    'Als Journalistin war sie vor allem im politischen Bereich tätig',\n",
    "    'Mein Bruder ist als Softwareentwickler tätig',\n",
    "    'In ihrer Freizeit ist sie in verschiedenen sozialen Projekten tätig',\n",
    "    'Nach seinem Ruhestand ist er ehrenamtlich in der Gemeinde tätig',\n",
    "    'Sie ist als Autorin tätig und hat bereits mehrere Bücher veröffentlicht',\n",
    "    'Als Anwalt ist er vor allem in den Bereichen Strafrecht und Zivilrecht tätig']\n",
    "\n",
    "prompts['gründliche'] = [\n",
    "    'Bevor wir mit dem Projekt fortfahren, benötigen wir eine gründliche',\n",
    "    'Der Erfolg der Operation hängt von einer gründlichen',\n",
    "    'Das Gesetz erfordert eine gründliche',\n",
    "    'Vor dem Kauf eines Gebrauchtwagens sollte man eine gründliche',\n",
    "    'Die Ermittlungen in dem Fall erfordern eine gründliche',\n",
    "    'Die Studie liefert eine gründliche',\n",
    "    'Das Projektteam hat eine gründliche',\n",
    "    'Vor dem Abschluss des Geschäfts wird eine gründliche',\n",
    "    'Die Wartung des Systems erfordert eine gründliche',\n",
    "    'Die Durchführung einer gründliche']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to run through each set of prompts. For each prompt we tokenize, then traverse backwards through the model until we find the last token of our bigrams.\n",
    "We concatenate any tokens after this one. This gives us our final dataset.\n",
    "\n",
    "Next, we do a forward pass with the German neurons ablated and unablated, and save the cache. There's an existing method to do this.\n",
    "We select the MLP activations at the second to last position. \n",
    "We average the MLP activations.\n",
    "We compare the average difference in neuron activation at that position, and select the neurons with the largest average difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import einsum\n",
    "from tqdm.auto import tqdm\n",
    "import seaborn as sns\n",
    "from transformer_lens import HookedTransformer, ActivationCache, utils\n",
    "from datasets import load_dataset\n",
    "from einops import einsum\n",
    "import pandas as pd\n",
    "from transformer_lens import utils\n",
    "from rich.table import Table, Column\n",
    "from rich import print as rprint\n",
    "from jaxtyping import Float, Int, Bool\n",
    "from torch import Tensor\n",
    "import einops\n",
    "import functools\n",
    "from transformer_lens.hook_points import HookPoint\n",
    "# import circuitsvis\n",
    "from IPython.display import HTML\n",
    "from plotly.express import line\n",
    "import plotly.express as px\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "import gc\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from plotly.subplots import make_subplots\n",
    "# Plotly needs a different renderer for VSCode/Notebooks vs Colab argh\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"notebook_connected\"\n",
    "\n",
    "from haystack_utils import load_txt_data, get_mlp_activations, line\n",
    "import haystack_utils\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model pythia-70m-v0 into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.autograd.set_grad_enabled(False)\n",
    "torch.set_grad_enabled(False)\n",
    "model = HookedTransformer.from_pretrained(\"pythia-70m-v0\", fold_ln=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in prompts.items():\n",
    "    print(key)\n",
    "    print(value[0])\n",
    "    loss = haystack_utils.get_average_loss(prompt, model, batch_size=1, crop_context=-1, fwd_hooks=[], positionwise=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
