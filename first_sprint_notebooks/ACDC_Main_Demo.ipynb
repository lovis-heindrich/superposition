{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0b47b9e8",
      "metadata": {
        "papermill": {
          "duration": 0.041811,
          "end_time": "2023-06-16T20:31:36.014649",
          "exception": false,
          "start_time": "2023-06-16T20:31:35.972838",
          "status": "completed"
        },
        "tags": [],
        "id": "0b47b9e8"
      },
      "source": [
        "<h1>ACDC Main Demo</h1>\n",
        "\n",
        "<p>This notebook (which doubles as a script) shows several use cases of ACDC</p>\n",
        "\n",
        "<p>The codebase is built on top of https://github.com/neelnanda-io/TransformerLens (source version)</p>\n",
        "\n",
        "<h3>Setup:</h3>\n",
        "<p>Janky code to do different setup when run in a Colab notebook vs VSCode (adapted from e.g <a href=\"https://github.com/neelnanda-io/TransformerLens/blob/5c89b7583e73ce96db5e46ef86a14b15f303dde6/demos/Activation_Patching_in_TL_Demo.ipynb\">this notebook</a>)</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "1597b7a2",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-16T20:31:36.024659Z",
          "iopub.status.busy": "2023-06-16T20:31:36.024086Z",
          "iopub.status.idle": "2023-06-16T20:31:36.333575Z",
          "shell.execute_reply": "2023-06-16T20:31:36.332749Z"
        },
        "papermill": {
          "duration": 0.317476,
          "end_time": "2023-06-16T20:31:36.336163",
          "exception": false,
          "start_time": "2023-06-16T20:31:36.018687",
          "status": "completed"
        },
        "tags": [],
        "id": "1597b7a2",
        "outputId": "fd545594-c158-4469-8f2e-fc899707e1c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running as a Colab notebook\n",
            "Running as a outside of colab\n",
            "Running as a notebook\n",
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    import google.colab\n",
        "\n",
        "    IN_COLAB = True\n",
        "    print(\"Running as a Colab notebook\")\n",
        "\n",
        "    import subprocess # to install graphviz dependencies\n",
        "    command = ['apt-get', 'install', 'graphviz-dev']\n",
        "    subprocess.run(command, check=True)\n",
        "\n",
        "    import os # make images folder\n",
        "    os.mkdir(\"ims/\")\n",
        "\n",
        "    from IPython import get_ipython\n",
        "    ipython = get_ipython()\n",
        "\n",
        "    ipython.run_line_magic( # install ACDC\n",
        "        \"pip\",\n",
        "        \"install git+https://github.com/ArthurConmy/Automatic-Circuit-Discovery.git@9d5844a\",\n",
        "    )\n",
        "\n",
        "except Exception as e:\n",
        "    IN_COLAB = False\n",
        "    print(\"Running as a outside of colab\")\n",
        "\n",
        "    import numpy # crucial to not get cursed error\n",
        "    import plotly\n",
        "\n",
        "    plotly.io.renderers.default = \"colab\"  # added by Arthur so running as a .py notebook with #%% generates .ipynb notebooks that display in colab\n",
        "    # disable this option when developing rather than generating notebook outputs\n",
        "\n",
        "    import os # make images folder\n",
        "    if not os.path.exists(\"ims/\"):\n",
        "        os.mkdir(\"ims/\")\n",
        "\n",
        "    from IPython import get_ipython\n",
        "\n",
        "    ipython = get_ipython()\n",
        "    if ipython is not None:\n",
        "        print(\"Running as a notebook\")\n",
        "        ipython.run_line_magic(\"load_ext\", \"autoreload\")  # type: ignore\n",
        "        ipython.run_line_magic(\"autoreload\", \"2\")  # type: ignore\n",
        "    else:\n",
        "        print(\"Running as a script\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b1f2708",
      "metadata": {
        "papermill": {
          "duration": 0.004304,
          "end_time": "2023-06-16T20:31:36.347791",
          "exception": false,
          "start_time": "2023-06-16T20:31:36.343487",
          "status": "completed"
        },
        "tags": [],
        "id": "6b1f2708"
      },
      "source": [
        "<h2>Imports etc</h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "7db2c14f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-16T20:31:36.356428Z",
          "iopub.status.busy": "2023-06-16T20:31:36.356000Z",
          "iopub.status.idle": "2023-06-16T20:31:41.470277Z",
          "shell.execute_reply": "2023-06-16T20:31:41.469167Z"
        },
        "papermill": {
          "duration": 5.122868,
          "end_time": "2023-06-16T20:31:41.474131",
          "exception": false,
          "start_time": "2023-06-16T20:31:36.351263",
          "status": "completed"
        },
        "tags": [],
        "id": "7db2c14f",
        "outputId": "ed2d4c87-d9be-4f78-a1ed-8d554c53cab8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.autograd.grad_mode.set_grad_enabled at 0x7ff5a1d643a0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "import wandb\n",
        "import IPython\n",
        "from IPython.display import Image, display\n",
        "import torch\n",
        "import gc\n",
        "from tqdm import tqdm\n",
        "import networkx as nx\n",
        "import os\n",
        "import torch\n",
        "import huggingface_hub\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import einops\n",
        "from tqdm import tqdm\n",
        "import yaml\n",
        "from transformers import AutoModelForCausalLM, AutoConfig, AutoTokenizer\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "import plotly.io as pio\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "from transformer_lens.hook_points import HookedRootModule, HookPoint\n",
        "from transformer_lens.HookedTransformer import (\n",
        "    HookedTransformer,\n",
        ")\n",
        "try:\n",
        "    from acdc.tracr_task.utils import (\n",
        "        get_all_tracr_things,\n",
        "        get_tracr_model_input_and_tl_model,\n",
        "    )\n",
        "except Exception as e:\n",
        "    print(f\"Could not import `tracr` because {e}; the rest of the file should work but you cannot use the tracr tasks\")\n",
        "from acdc.docstring.utils import get_all_docstring_things\n",
        "from acdc.acdc_utils import (\n",
        "    make_nd_dict,\n",
        "    reset_network,\n",
        "    shuffle_tensor,\n",
        "    cleanup,\n",
        "    ct,\n",
        "    TorchIndex,\n",
        "    Edge,\n",
        "    EdgeType,\n",
        ")  # these introduce several important classes !!!\n",
        "\n",
        "from acdc.TLACDCCorrespondence import TLACDCCorrespondence\n",
        "from acdc.TLACDCInterpNode import TLACDCInterpNode\n",
        "from acdc.TLACDCExperiment import TLACDCExperiment\n",
        "\n",
        "from acdc.acdc_utils import (\n",
        "    kl_divergence,\n",
        ")\n",
        "from acdc.ioi.utils import (\n",
        "    get_all_ioi_things,\n",
        "    get_gpt2_small,\n",
        ")\n",
        "from acdc.induction.utils import (\n",
        "    get_all_induction_things,\n",
        "    get_validation_data,\n",
        "    get_good_induction_candidates,\n",
        "    get_mask_repeat_candidates,\n",
        ")\n",
        "from acdc.greaterthan.utils import get_all_greaterthan_things\n",
        "from acdc.acdc_graphics import (\n",
        "    build_colorscheme,\n",
        "    show,\n",
        ")\n",
        "import argparse\n",
        "\n",
        "torch.autograd.set_grad_enabled(False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f362f095",
      "metadata": {
        "papermill": {
          "duration": 0.00547,
          "end_time": "2023-06-16T20:31:41.490727",
          "exception": false,
          "start_time": "2023-06-16T20:31:41.485257",
          "status": "completed"
        },
        "tags": [],
        "id": "f362f095"
      },
      "source": [
        "<h2>ACDC Experiment Setup</h2>\n",
        "<p>We use a `parser to set all the options for the ACDC experiment.\n",
        "This is still usable in notebooks! We can pass a string to the parser, see below.\n",
        "We'll reproduce </p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "656136b5",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-16T20:31:41.504158Z",
          "iopub.status.busy": "2023-06-16T20:31:41.503343Z",
          "iopub.status.idle": "2023-06-16T20:31:41.568774Z",
          "shell.execute_reply": "2023-06-16T20:31:41.567807Z"
        },
        "papermill": {
          "duration": 0.076191,
          "end_time": "2023-06-16T20:31:41.572393",
          "exception": false,
          "start_time": "2023-06-16T20:31:41.496202",
          "status": "completed"
        },
        "tags": [],
        "id": "656136b5"
      },
      "outputs": [],
      "source": [
        "parser = argparse.ArgumentParser(description=\"Used to launch ACDC runs. Only task and threshold are required\")\n",
        "\n",
        "task_choices = ['ioi', 'docstring', 'induction', 'tracr-reverse', 'tracr-proportion', 'greaterthan']\n",
        "parser.add_argument('--task', type=str, required=True, choices=task_choices, help=f'Choose a task from the available options: {task_choices}')\n",
        "parser.add_argument('--threshold', type=float, required=True, help='Value for THRESHOLD')\n",
        "parser.add_argument('--first-cache-cpu', type=str, required=False, default=\"True\", help='Value for FIRST_CACHE_CPU (the old name for the `online_cache`)')\n",
        "parser.add_argument('--second-cache-cpu', type=str, required=False, default=\"True\", help='Value for SECOND_CACHE_CPU (the old name for the `corrupted_cache`)')\n",
        "parser.add_argument('--zero-ablation', action='store_true', help='Use zero ablation')\n",
        "parser.add_argument('--using-wandb', action='store_true', help='Use wandb')\n",
        "parser.add_argument('--wandb-entity-name', type=str, required=False, default=\"remix_school-of-rock\", help='Value for WANDB_ENTITY_NAME')\n",
        "parser.add_argument('--wandb-group-name', type=str, required=False, default=\"default\", help='Value for WANDB_GROUP_NAME')\n",
        "parser.add_argument('--wandb-project-name', type=str, required=False, default=\"acdc\", help='Value for WANDB_PROJECT_NAME')\n",
        "parser.add_argument('--wandb-run-name', type=str, required=False, default=None, help='Value for WANDB_RUN_NAME')\n",
        "parser.add_argument(\"--wandb-dir\", type=str, default=\"/tmp/wandb\")\n",
        "parser.add_argument(\"--wandb-mode\", type=str, default=\"online\")\n",
        "parser.add_argument('--indices-mode', type=str, default=\"normal\")\n",
        "parser.add_argument('--names-mode', type=str, default=\"normal\")\n",
        "parser.add_argument('--device', type=str, default=\"cuda\")\n",
        "parser.add_argument('--reset-network', type=int, default=0, help=\"Whether to reset the network we're operating on before running interp on it\")\n",
        "parser.add_argument('--metric', type=str, default=\"kl_div\", help=\"Which metric to use for the experiment\")\n",
        "parser.add_argument('--torch-num-threads', type=int, default=0, help=\"How many threads to use for torch (0=all)\")\n",
        "parser.add_argument('--seed', type=int, default=1234)\n",
        "parser.add_argument(\"--max-num-epochs\",type=int, default=100_000)\n",
        "parser.add_argument('--single-step', action='store_true', help='Use single step, mostly for testing')\n",
        "\n",
        "if ipython is not None:\n",
        "    # we are in a notebook\n",
        "    # you can put the command you would like to run as the ... in r\"\"\"...\"\"\"\n",
        "    args = parser.parse_args(\n",
        "        [line.strip() for line in r\"\"\"--task=induction\\\n",
        "--zero-ablation\\\n",
        "--threshold=0.71\\\n",
        "--indices-mode=reverse\\\n",
        "--first-cache-cpu=False\\\n",
        "--second-cache-cpu=False\\\n",
        "--max-num-epochs=100000\"\"\".split(\"\\\\\\n\")]\n",
        "    )\n",
        "else:\n",
        "    # read from command line\n",
        "    args = parser.parse_args()\n",
        "\n",
        "# process args\n",
        "\n",
        "if args.torch_num_threads > 0:\n",
        "    torch.set_num_threads(args.torch_num_threads)\n",
        "torch.manual_seed(args.seed)\n",
        "\n",
        "TASK = args.task\n",
        "if args.first_cache_cpu is None: # manage default\n",
        "    ONLINE_CACHE_CPU = True\n",
        "elif args.first_cache_cpu.lower() == \"false\":\n",
        "    ONLINE_CACHE_CPU = False\n",
        "elif args.first_cache_cpu.lower() == \"true\":\n",
        "    ONLINE_CACHE_CPU = True\n",
        "else:\n",
        "    raise ValueError(f\"first_cache_cpu must be either True or False, got {args.first_cache_cpu}\")\n",
        "if args.second_cache_cpu is None:\n",
        "    CORRUPTED_CACHE_CPU = True\n",
        "elif args.second_cache_cpu.lower() == \"false\":\n",
        "    CORRUPTED_CACHE_CPU = False\n",
        "elif args.second_cache_cpu.lower() == \"true\":\n",
        "    CORRUPTED_CACHE_CPU = True\n",
        "else:\n",
        "    raise ValueError(f\"second_cache_cpu must be either True or False, got {args.second_cache_cpu}\")\n",
        "THRESHOLD = args.threshold  # only used if >= 0.0\n",
        "ZERO_ABLATION = True if args.zero_ablation else False\n",
        "USING_WANDB = True if args.using_wandb else False\n",
        "WANDB_ENTITY_NAME = args.wandb_entity_name\n",
        "WANDB_PROJECT_NAME = args.wandb_project_name\n",
        "WANDB_RUN_NAME = args.wandb_run_name\n",
        "WANDB_GROUP_NAME = args.wandb_group_name\n",
        "INDICES_MODE = args.indices_mode\n",
        "NAMES_MODE = args.names_mode\n",
        "DEVICE = args.device\n",
        "RESET_NETWORK = args.reset_network\n",
        "SINGLE_STEP = True if args.single_step else False"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e01a8eb3",
      "metadata": {
        "papermill": {
          "duration": 0.005464,
          "end_time": "2023-06-16T20:31:41.585485",
          "exception": false,
          "start_time": "2023-06-16T20:31:41.580021",
          "status": "completed"
        },
        "tags": [],
        "id": "e01a8eb3"
      },
      "source": [
        "<h2>Setup Task</h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "30203fcd",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-16T20:31:41.598833Z",
          "iopub.status.busy": "2023-06-16T20:31:41.598355Z",
          "iopub.status.idle": "2023-06-16T20:31:43.384439Z",
          "shell.execute_reply": "2023-06-16T20:31:43.383456Z"
        },
        "lines_to_next_cell": 2,
        "papermill": {
          "duration": 1.797198,
          "end_time": "2023-06-16T20:31:43.388612",
          "exception": false,
          "start_time": "2023-06-16T20:31:41.591414",
          "status": "completed"
        },
        "tags": [],
        "id": "30203fcd",
        "outputId": "3463f198-c97b-4e59-f124-7858392a55ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded pretrained model redwood_attn_2l into HookedTransformer\n"
          ]
        }
      ],
      "source": [
        "second_metric = None  # some tasks only have one metric\n",
        "use_pos_embed = TASK.startswith(\"tracr\")\n",
        "\n",
        "if TASK == \"ioi\":\n",
        "    num_examples = 100\n",
        "    things = get_all_ioi_things(\n",
        "        num_examples=num_examples, device=DEVICE, metric_name=args.metric\n",
        "    )\n",
        "elif TASK == \"tracr-reverse\":\n",
        "    num_examples = 6\n",
        "    things = get_all_tracr_things(\n",
        "        task=\"reverse\",\n",
        "        metric_name=args.metric,\n",
        "        num_examples=num_examples,\n",
        "        device=DEVICE,\n",
        "    )\n",
        "elif TASK == \"tracr-proportion\":\n",
        "    num_examples = 50\n",
        "    things = get_all_tracr_things(\n",
        "        task=\"proportion\",\n",
        "        metric_name=args.metric,\n",
        "        num_examples=num_examples,\n",
        "        device=DEVICE,\n",
        "    )\n",
        "elif TASK == \"induction\":\n",
        "    num_examples = 10 if IN_COLAB else 50\n",
        "    seq_len = 300\n",
        "    # TODO initialize the `tl_model` with the right model\n",
        "    things = get_all_induction_things(\n",
        "        num_examples=num_examples, seq_len=seq_len, device=DEVICE, metric=args.metric\n",
        "    )\n",
        "elif TASK == \"docstring\":\n",
        "    num_examples = 50\n",
        "    seq_len = 41\n",
        "    things = get_all_docstring_things(\n",
        "        num_examples=num_examples,\n",
        "        seq_len=seq_len,\n",
        "        device=DEVICE,\n",
        "        metric_name=args.metric,\n",
        "        correct_incorrect_wandb=True,\n",
        "    )\n",
        "elif TASK == \"greaterthan\":\n",
        "    num_examples = 100\n",
        "    things = get_all_greaterthan_things(\n",
        "        num_examples=num_examples, metric_name=args.metric, device=DEVICE\n",
        "    )\n",
        "else:\n",
        "    raise ValueError(f\"Unknown task {TASK}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2896ef21",
      "metadata": {
        "papermill": {
          "duration": 0.006475,
          "end_time": "2023-06-16T20:31:43.406352",
          "exception": false,
          "start_time": "2023-06-16T20:31:43.399877",
          "status": "completed"
        },
        "tags": [],
        "id": "2896ef21"
      },
      "source": [
        "<p> Let's define the four most important objects for ACDC experiments:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "0332ba8b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-16T20:31:43.420474Z",
          "iopub.status.busy": "2023-06-16T20:31:43.420030Z",
          "iopub.status.idle": "2023-06-16T20:31:43.471430Z",
          "shell.execute_reply": "2023-06-16T20:31:43.470503Z"
        },
        "papermill": {
          "duration": 0.062585,
          "end_time": "2023-06-16T20:31:43.475183",
          "exception": false,
          "start_time": "2023-06-16T20:31:43.412598",
          "status": "completed"
        },
        "tags": [],
        "id": "0332ba8b"
      },
      "outputs": [],
      "source": [
        "validation_metric = things.validation_metric # metric we use (e.g KL divergence)\n",
        "toks_int_values = things.validation_data # clean data x_i\n",
        "toks_int_values_other = things.validation_patch_data # corrupted data x_i'\n",
        "tl_model = things.tl_model # transformerlens model\n",
        "\n",
        "if RESET_NETWORK:\n",
        "    reset_network(TASK, DEVICE, tl_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b9edc14",
      "metadata": {
        "papermill": {
          "duration": 0.005822,
          "end_time": "2023-06-16T20:31:43.491324",
          "exception": false,
          "start_time": "2023-06-16T20:31:43.485502",
          "status": "completed"
        },
        "tags": [],
        "id": "0b9edc14"
      },
      "source": [
        "<h2>Setup ACDC Experiment</h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "3dab87de",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-16T20:31:43.504960Z",
          "iopub.status.busy": "2023-06-16T20:31:43.504514Z",
          "iopub.status.idle": "2023-06-16T20:31:45.441765Z",
          "shell.execute_reply": "2023-06-16T20:31:45.440672Z"
        },
        "papermill": {
          "duration": 1.950511,
          "end_time": "2023-06-16T20:31:45.447745",
          "exception": true,
          "start_time": "2023-06-16T20:31:43.497234",
          "status": "failed"
        },
        "tags": [],
        "id": "3dab87de",
        "outputId": "0f041970-b49d-4c19-8820-64be85896157",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:cache_all is deprecated and will eventually be removed, use add_caching_hooks or run_with_cache\n",
            "/usr/local/lib/python3.10/dist-packages/acdc/TLACDCExperiment.py:130: UserWarning:\n",
            "\n",
            "We shall overwrite the ref_ds with zeros.\n",
            "\n",
            "WARNING:root:cache_all is deprecated and will eventually be removed, use add_caching_hooks or run_with_cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['blocks.1.hook_resid_post', 'blocks.1.attn.hook_result', 'blocks.1.attn.hook_q', 'blocks.1.hook_q_input', 'blocks.1.attn.hook_k', 'blocks.1.hook_k_input', 'blocks.1.attn.hook_v', 'blocks.1.hook_v_input', 'blocks.0.attn.hook_result', 'blocks.0.attn.hook_q', 'blocks.0.hook_q_input', 'blocks.0.attn.hook_k', 'blocks.0.hook_k_input', 'blocks.0.attn.hook_v', 'blocks.0.hook_v_input', 'blocks.0.hook_resid_pre'])\n",
            "ln_final.hook_normalized\n",
            "ln_final.hook_scale\n",
            "blocks.1.hook_resid_post\n",
            "blocks.1.hook_attn_out\n",
            "blocks.1.attn.hook_result\n",
            "blocks.1.attn.hook_z\n",
            "blocks.1.attn.hook_pattern\n",
            "blocks.1.attn.hook_attn_scores\n",
            "blocks.1.attn.hook_v\n",
            "blocks.1.attn.hook_k\n",
            "blocks.1.attn.hook_q\n",
            "blocks.1.ln1.hook_normalized\n",
            "blocks.1.ln1.hook_scale\n",
            "blocks.1.hook_v_input\n",
            "blocks.1.hook_k_input\n",
            "blocks.1.hook_q_input\n",
            "blocks.1.hook_resid_pre\n",
            "blocks.0.hook_resid_post\n",
            "blocks.0.hook_attn_out\n",
            "blocks.0.attn.hook_result\n",
            "blocks.0.attn.hook_z\n",
            "blocks.0.attn.hook_pattern\n",
            "blocks.0.attn.hook_attn_scores\n",
            "blocks.0.attn.hook_v\n",
            "blocks.0.attn.hook_k\n",
            "blocks.0.attn.hook_q\n",
            "blocks.0.ln1.hook_normalized\n",
            "blocks.0.ln1.hook_scale\n",
            "blocks.0.hook_v_input\n",
            "blocks.0.hook_k_input\n",
            "blocks.0.hook_q_input\n",
            "blocks.0.hook_resid_pre\n",
            "hook_pos_embed\n",
            "hook_embed\n",
            "self.current_node=TLACDCInterpNode(blocks.1.hook_resid_post, [:])\n",
            "Adding sender hooks...\n",
            "Done corrupting things\n",
            "Adding sender hooks...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-13296b5a7f3b>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mtl_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m exp = TLACDCExperiment(\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtl_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTHRESHOLD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/acdc/TLACDCExperiment.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, ds, ref_ds, threshold, metric, second_metric, verbose, hook_verbose, parallel_hypotheses, remove_redundant, monotone_metric, online_cache_cpu, corrupted_cache_cpu, zero_ablation, show_full_index, using_wandb, wandb_entity_name, wandb_project_name, wandb_run_name, wandb_group_name, wandb_notes, wandb_dir, wandb_mode, use_pos_embed, skip_edges, add_sender_hooks, add_receiver_hooks, indices_mode, names_mode, wandb_config, early_exit)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msecond_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msecond_metric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_cur_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/acdc/TLACDCExperiment.py\u001b[0m in \u001b[0;36mupdate_cur_metric\u001b[0;34m(self, recalc_metric, recalc_edges, initial)\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate_cur_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecalc_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecalc_edges\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecalc_metric\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcur_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msecond_metric\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_lens/HookedTransformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, return_type, loss_per_token, prepend_bos, stop_at_layer, past_kv_cache)\u001b[0m\n\u001b[1;32m    373\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munembed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresidual\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [batch, pos, d_vocab]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreturn_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"logits\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_lens/components.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, residual)\u001b[0m\n\u001b[1;32m     56\u001b[0m     ) -> Float[torch.Tensor, \"batch pos d_vocab_out\"]:\n\u001b[1;32m     57\u001b[0m         return (\n\u001b[0;32m---> 58\u001b[0;31m             einsum(\n\u001b[0m\u001b[1;32m     59\u001b[0m                 \u001b[0;34m\"batch pos d_model, d_model vocab -> batch pos vocab\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[0mresidual\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 2.81 GiB (GPU 0; 15.77 GiB total capacity; 12.79 GiB already allocated; 20.12 MiB free; 14.71 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ],
      "source": [
        "# Make notes for potential wandb run\n",
        "try:\n",
        "    with open(__file__, \"r\") as f:\n",
        "        notes = f.read()\n",
        "except:\n",
        "    notes = \"No notes generated, expected when running in an .ipynb file\"\n",
        "\n",
        "tl_model.reset_hooks()\n",
        "\n",
        "# Save some mem\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# Setup wandb if needed\n",
        "if WANDB_RUN_NAME is None or IPython.get_ipython() is not None:\n",
        "    WANDB_RUN_NAME = f\"{ct()}{'_randomindices' if INDICES_MODE=='random' else ''}_{THRESHOLD}{'_zero' if ZERO_ABLATION else ''}\"\n",
        "else:\n",
        "    assert WANDB_RUN_NAME is not None, \"I want named runs, always\"\n",
        "\n",
        "tl_model.reset_hooks()\n",
        "exp = TLACDCExperiment(\n",
        "    model=tl_model,\n",
        "    threshold=THRESHOLD,\n",
        "    using_wandb=USING_WANDB,\n",
        "    wandb_entity_name=WANDB_ENTITY_NAME,\n",
        "    wandb_project_name=WANDB_PROJECT_NAME,\n",
        "    wandb_run_name=WANDB_RUN_NAME,\n",
        "    wandb_group_name=WANDB_GROUP_NAME,\n",
        "    wandb_notes=notes,\n",
        "    wandb_dir=args.wandb_dir,\n",
        "    wandb_mode=args.wandb_mode,\n",
        "    wandb_config=args,\n",
        "    zero_ablation=ZERO_ABLATION,\n",
        "    ds=toks_int_values,\n",
        "    ref_ds=toks_int_values_other,\n",
        "    metric=validation_metric,\n",
        "    second_metric=second_metric,\n",
        "    verbose=True,\n",
        "    indices_mode=INDICES_MODE,\n",
        "    names_mode=NAMES_MODE,\n",
        "    corrupted_cache_cpu=CORRUPTED_CACHE_CPU,\n",
        "    hook_verbose=False,\n",
        "    online_cache_cpu=ONLINE_CACHE_CPU,\n",
        "    add_sender_hooks=True,\n",
        "    use_pos_embed=use_pos_embed,\n",
        "    add_receiver_hooks=False,\n",
        "    remove_redundant=False,\n",
        "    show_full_index=use_pos_embed,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce1b6665",
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "ce1b6665"
      },
      "source": [
        "<h2>Run steps of ACDC: iterate over a NODE in the model's computational graph</h2>\n",
        "<p>WARNING! This will take a few minutes to run, but there should be rolling nice pictures too : )</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0315a9d",
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "a0315a9d"
      },
      "outputs": [],
      "source": [
        "for i in range(args.max_num_epochs):\n",
        "    exp.step(testing=False)\n",
        "\n",
        "    show(\n",
        "        exp.corr,\n",
        "        f\"ims/img_new_{i+1}.png\",\n",
        "        show_full_index=use_pos_embed,\n",
        "    )\n",
        "\n",
        "    if IN_COLAB or ipython is not None:\n",
        "        # so long as we're not running this as a script, show the image!\n",
        "        display(Image(f\"ims/img_new_{i+1}.png\"))\n",
        "\n",
        "    print(i, \"-\" * 50)\n",
        "    print(exp.count_no_edges())\n",
        "\n",
        "    if i == 0:\n",
        "        exp.save_edges(\"edges.pkl\")\n",
        "\n",
        "    if exp.current_node is None or SINGLE_STEP:\n",
        "        break\n",
        "\n",
        "exp.save_edges(\"another_final_edges.pkl\")\n",
        "\n",
        "if USING_WANDB:\n",
        "    edges_fname = f\"edges.pth\"\n",
        "    exp.save_edges(edges_fname)\n",
        "    artifact = wandb.Artifact(edges_fname, type=\"dataset\")\n",
        "    artifact.add_file(edges_fname)\n",
        "    wandb.log_artifact(artifact)\n",
        "    os.remove(edges_fname)\n",
        "    wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee1e5fa1",
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "ee1e5fa1"
      },
      "source": [
        "<h2>Save the final subgraph of the model</h2>\n",
        "<p>There are more than `exp.count_no_edges()` here because we include some \"placeholder\" edges needed to make ACDC work that only matter internally (they don't help vizualization)</p>\n",
        "<p>We recover minimal induction machinery! `embed -> a0.0_v -> a1.6k`</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebcc5ebc",
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "ebcc5ebc"
      },
      "outputs": [],
      "source": [
        "exp.save_subgraph(\n",
        "    return_it=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ad31780",
      "metadata": {
        "id": "6ad31780"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 12.210943,
      "end_time": "2023-06-16T20:31:46.783558",
      "environment_variables": {},
      "exception": true,
      "input_path": "notebooks/_converted/main_demo.ipynb",
      "output_path": "notebooks/colabs/ACDC_Main_Demo.ipynb",
      "parameters": {},
      "start_time": "2023-06-16T20:31:34.572615",
      "version": "2.4.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
      }
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}