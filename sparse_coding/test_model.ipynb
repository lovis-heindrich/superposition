{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import plotly.io as pio\n",
    "import einops\n",
    "from transformer_lens import HookedTransformerConfig, HookedTransformer\n",
    "\n",
    "pio.renderers.default = \"notebook_connected\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "torch.autograd.set_grad_enabled(False)\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "sys.path.append('../')  # Add the parent directory to the system path\n",
    "import utils.haystack_utils as haystack_utils\n",
    "\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_neo_weights(neo, cfg: HookedTransformerConfig):\n",
    "    state_dict = {}\n",
    "\n",
    "    state_dict[\"embed.W_E\"] = neo[f'transformer.wte.weight']\n",
    "    state_dict[\"pos_embed.W_pos\"] = torch.zeros(2048, 768).to(device)\n",
    "    state_dict[\"pos_embed.W_pos\"][:256] = neo['transformer.wpe.weight']\n",
    "\n",
    "    for l in range(cfg.n_layers):\n",
    "        state_dict[f\"blocks.{l}.ln1.w\"] = neo[f'transformer.h.{l}.ln_1.weight']\n",
    "        state_dict[f\"blocks.{l}.ln1.b\"] = neo[f'transformer.h.{l}.ln_1.bias']\n",
    "\n",
    "        W_Q = neo[f'transformer.h.{l}.attn.attention.q_proj.weight']\n",
    "        W_K = neo[f'transformer.h.{l}.attn.attention.k_proj.weight']\n",
    "        W_V = neo[f'transformer.h.{l}.attn.attention.v_proj.weight']\n",
    "        W_Q = einops.rearrange(W_Q, \"(i h) m->i m h\", i=cfg.n_heads)\n",
    "        W_K = einops.rearrange(W_K, \"(i h) m->i m h\", i=cfg.n_heads)\n",
    "        W_V = einops.rearrange(W_V, \"(i h) m->i m h\", i=cfg.n_heads)\n",
    "        state_dict[f\"blocks.{l}.attn.W_Q\"] = W_Q\n",
    "        state_dict[f\"blocks.{l}.attn.W_K\"] = W_K\n",
    "        state_dict[f\"blocks.{l}.attn.W_V\"] = W_V\n",
    "\n",
    "        state_dict[f\"blocks.{l}.attn.b_Q\"] = torch.zeros(cfg.n_heads, cfg.d_head).to(device)\n",
    "        state_dict[f\"blocks.{l}.attn.b_K\"] = torch.zeros(cfg.n_heads, cfg.d_head).to(device)\n",
    "        state_dict[f\"blocks.{l}.attn.b_V\"] = torch.zeros(cfg.n_heads, cfg.d_head).to(device)\n",
    "\n",
    "        W_O = neo[f'transformer.h.{l}.attn.attention.out_proj.weight']\n",
    "        W_O = einops.rearrange(W_O, \"m (i h)->i h m\", i=cfg.n_heads)\n",
    "        state_dict[f\"blocks.{l}.attn.W_O\"] = W_O\n",
    "        state_dict[f\"blocks.{l}.attn.b_O\"] = neo[f'transformer.h.{l}.attn.attention.out_proj.bias']\n",
    "\n",
    "        state_dict[f\"blocks.{l}.ln2.w\"] = neo[f'transformer.h.{l}.ln_2.weight']\n",
    "        state_dict[f\"blocks.{l}.ln2.b\"] = neo[f'transformer.h.{l}.ln_2.bias']\n",
    "\n",
    "        state_dict[f\"blocks.{l}.mlp.W_in\"] = neo[f'transformer.h.{l}.mlp.c_fc.weight'].T\n",
    "        state_dict[f\"blocks.{l}.mlp.b_in\"] = neo[f'transformer.h.{l}.mlp.c_fc.bias']\n",
    "\n",
    "        state_dict[f\"blocks.{l}.mlp.W_out\"] = neo[f'transformer.h.{l}.mlp.c_proj.weight'].T\n",
    "        state_dict[f\"blocks.{l}.mlp.b_out\"] = neo[f'transformer.h.{l}.mlp.c_proj.bias']\n",
    "    state_dict[\"ln_final.w\"] = neo['transformer.ln_f.weight']\n",
    "    state_dict[\"ln_final.b\"] = neo['transformer.ln_f.bias']\n",
    "\n",
    "    state_dict[\"unembed.W_U\"] = neo['lm_head.weight'].T\n",
    "    state_dict[\"unembed.b_U\"] = torch.zeros(cfg.d_vocab).to(device)\n",
    "    return state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/data/tiny-stories-33M/15_vocal_bush.json: Loaded 40 examples with 2 to 23 characters each.\n",
      "Loaded pretrained model tiny-stories-33M into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "model_name = \"tiny-stories-33M\"\n",
    "save_name = \"15_vocal_bush\"\n",
    "checkpoint_state_dict = torch.load(f\"/workspace/data/{model_name}/{save_name}_10000.pt\")\n",
    "cfg = haystack_utils.load_json_data(f\"/workspace/data/{model_name}/{save_name}.json\")\n",
    "model = HookedTransformer.from_pretrained(\n",
    "    \"tiny-stories-33M\",\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "hooked_transformer_cfg = HookedTransformerConfig(\n",
    "    cfg['num_layers'], \n",
    "    cfg['hidden_size'], \n",
    "    cfg['window_size'], \n",
    "    cfg['hidden_size'] // cfg['num_heads'],\n",
    "    act_fn=cfg['activation_function'],\n",
    "    d_mlp=4 * cfg['hidden_size'],\n",
    "    d_vocab=cfg['vocab_size'],\n",
    "    ) \n",
    "\n",
    "checkpoint_state_dict = convert_neo_weights(checkpoint_state_dict, hooked_transformer_cfg)\n",
    "haystack_utils.clean_cache()\n",
    "model.load_and_process_state_dict(checkpoint_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6e07a7f3641479d824026aefce3c1fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Sally and Lucy walked over to the and her. saw big and and, sun the in sky She to. smiled said \" you a'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate(\"Sally and Lucy walked over to the\", 20, temperature=0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
