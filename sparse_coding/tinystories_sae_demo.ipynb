{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_lens import HookedTransformer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import json\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model tiny-stories-2L-33M into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "model = HookedTransformer.from_pretrained(\"tiny-stories-2L-33M\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(\n",
    "        self, d_hidden: int, d_in: int, dtype=torch.float32, seed=47\n",
    "    ):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(seed)\n",
    "        self.W_enc = nn.Parameter(\n",
    "            torch.nn.init.kaiming_uniform_(torch.empty(d_in, d_hidden, dtype=dtype))\n",
    "        )\n",
    "        self.W_dec = nn.Parameter(\n",
    "            torch.nn.init.kaiming_uniform_(torch.empty(d_hidden, d_in, dtype=dtype))\n",
    "        )\n",
    "        self.b_enc = nn.Parameter(torch.zeros(d_hidden, dtype=dtype))\n",
    "        self.b_dec = nn.Parameter(torch.zeros(d_in, dtype=dtype))\n",
    "\n",
    "        self.W_dec.data[:] = self.W_dec / self.W_dec.norm(dim=-1, keepdim=True)\n",
    "        self.d_hidden = d_hidden\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x_cent = x - self.b_dec\n",
    "        acts = F.relu(x_cent @ self.W_enc + self.b_enc)\n",
    "        x_reconstruct = acts @ self.W_dec + self.b_dec\n",
    "        return x_reconstruct, acts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoEncoder()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path = \"/workspace/tiny-stories-2L-33M\"\n",
    "run_name = \"189_giddy_water\"\n",
    "\n",
    "with open(f\"{save_path}/{run_name}.json\", \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "d_in = cfg[\"d_in\"]\n",
    "d_hidden = cfg[\"d_in\"] * cfg[\"expansion_factor\"]\n",
    "hook_name = f\"blocks.{cfg['layer']}.{cfg['act']}\"\n",
    "\n",
    "encoder = AutoEncoder(d_hidden, d_in)\n",
    "encoder.load_state_dict(torch.load(f\"{save_path}/{run_name}.pt\"))\n",
    "encoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example prompt, more here: https://huggingface.co/datasets/roneneldan/TinyStories\n",
    "prompt = 'Once upon a time, in a big forest, there lived a rhinoceros named Roxy. Roxy loved to climb. She climbed trees, rocks, and hills. One day, Roxy found an icy hill. She had never seen anything like it before. It was shiny and cold, and she wanted to climb it.\\n\\nRoxy tried to climb the icy hill, but it was very slippery. She tried again and again, but she kept falling down. Roxy was sad. She wanted to climb the icy hill so much. Then, she saw a little bird named Billy. Billy saw that Roxy was sad and asked, \"Why are you sad, Roxy?\"\\n\\nRoxy told Billy about the icy hill and how she couldn\\'t climb it. Billy said, \"I have an idea! Let\\'s find some big leaves to put under your feet. They will help you climb the icy hill.\" Roxy and Billy looked for big leaves and found some. Roxy put the leaves under her feet and tried to climb the icy hill again.\\n\\nThis time, Roxy didn\\'t slip. She climbed and climbed until she reached the top of the icy hill. Roxy was so happy! She and Billy played on the icy hill all day. From that day on, Roxy and Billy were the best of friends, and they climbed and played together all the time. And Roxy learned that with a little help from a friend, she could climb anything.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original model loss: 0.87\n",
      "Active SAE directions (L0): 33.10\n",
      "Model reconstruction loss: 1.17\n"
     ]
    }
   ],
   "source": [
    "loss, cache = model.run_with_cache(prompt, return_type=\"loss\")\n",
    "print(f\"Original model loss: {loss:.2f}\")\n",
    "\n",
    "# Use SAE to reconstruct the MLP activations\n",
    "x_reconstruct, acts = encoder(cache[hook_name])\n",
    "print(f\"Active SAE directions (L0): {(acts>0).sum(-1).float().mean():.2f}\")\n",
    "\n",
    "# Run model through the SAE\n",
    "def sae_hook(value, hook):\n",
    "    value = x_reconstruct\n",
    "    return value\n",
    "\n",
    "with model.hooks(fwd_hooks=[(hook_name, sae_hook)]):\n",
    "    reconstruct_loss = model(prompt, return_type=\"loss\")\n",
    "print(f\"Model reconstruction loss: {reconstruct_loss:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
