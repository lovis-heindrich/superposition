{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "import requests\n",
    "import logging\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from transformer_lens import HookedTransformer\n",
    "from tqdm.auto import tqdm\n",
    "import plotly.io as pio\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import wandb\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import torch.nn.init as init\n",
    "from pathlib import Path\n",
    "from jaxtyping import Int, Float\n",
    "from torch import Tensor\n",
    "import einops\n",
    "from collections import Counter\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from ipywidgets import interact, IntSlider\n",
    "from process_tiny_stories_data import load_tinystories_validation_prompts, load_tinystories_tokens\n",
    "\n",
    "pio.renderers.default = \"notebook_connected\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "torch.autograd.set_grad_enabled(False)\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "logging.basicConfig(format='(%(levelname)s) %(asctime)s: %(message)s', level=logging.INFO, datefmt='%I:%M:%S')\n",
    "sys.path.append('../')  # Add the parent directory to the system path\n",
    "\n",
    "import utils.haystack_utils as haystack_utils\n",
    "from sparse_coding.train_autoencoder import AutoEncoder\n",
    "from utils.autoencoder_utils import custom_forward, AutoEncoderConfig, evaluate_autoencoder_reconstruction, get_encoder_feature_frequencies\n",
    "import utils.haystack_utils as haystack_utils\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model tiny-stories-2L-33M into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "model_name = \"tiny-stories-2L-33M\"\n",
    "model = HookedTransformer.from_pretrained(\n",
    "    model_name,\n",
    "    center_unembed=True,\n",
    "    center_writing_weights=True,\n",
    "    fold_ln=True,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "def load_encoder(save_name, model_name):\n",
    "    with open(f\"{model_name}/{save_name}.json\", \"r\") as f:\n",
    "        cfg = json.load(f)\n",
    "\n",
    "    cfg = AutoEncoderConfig(\n",
    "        cfg[\"layer\"], cfg[\"act\"], cfg[\"expansion_factor\"], cfg[\"l1_coeff\"]\n",
    "    )\n",
    "\n",
    "    if cfg.act_name == \"hook_mlp_out\":\n",
    "        d_in = model.cfg.d_model\n",
    "    else:\n",
    "        d_in = model.cfg.d_mlp\n",
    "    d_hidden = d_in * cfg.expansion_factor\n",
    "\n",
    "    encoder = AutoEncoder(d_hidden, cfg.l1_coeff, d_in)\n",
    "    encoder.load_state_dict(torch.load(os.path.join(model_name, save_name + \".pt\")))\n",
    "    encoder.to(device)\n",
    "    return encoder, cfg\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_acts(prompt: str, model: HookedTransformer, encoder: AutoEncoder, cfg: AutoEncoderConfig):\n",
    "    _, cache = model.run_with_cache(prompt, names_filter=cfg.encoder_hook_point)\n",
    "    acts = cache[cfg.encoder_hook_point].squeeze(0)\n",
    "    _, _, mid_acts, _, _ = encoder(acts)\n",
    "    return mid_acts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Perhaps filter out L1 features by their unembed kurtosis (so we know they're meaningful)\n",
    "# 2. Run prompt with autoencoder and record the highly activating features (potentially excluding those from step 1)\n",
    "# 3. Run prompt once for each highly activating feature in L0, ablating it, and take the difference in each highly activating feature in L1\n",
    "# 4. Break if any are above an arbitrary threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_names = [f.split(\".\")[0] for f in os.listdir(model_name) if f.endswith('.pt')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
