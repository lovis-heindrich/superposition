{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "import requests\n",
    "import logging\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from transformer_lens import HookedTransformer\n",
    "from tqdm.auto import tqdm\n",
    "import plotly.io as pio\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import wandb\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import torch.nn.init as init\n",
    "from pathlib import Path\n",
    "from jaxtyping import Int, Float\n",
    "from torch import Tensor\n",
    "import einops\n",
    "from collections import Counter\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from ipywidgets import interact, IntSlider\n",
    "from process_tiny_stories_data import load_tinystories_validation_prompts, load_tinystories_tokens\n",
    "\n",
    "pio.renderers.default = \"notebook_connected\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "torch.autograd.set_grad_enabled(False)\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "logging.basicConfig(format='(%(levelname)s) %(asctime)s: %(message)s', level=logging.INFO, datefmt='%I:%M:%S')\n",
    "sys.path.append('../')  # Add the parent directory to the system path\n",
    "\n",
    "import utils.haystack_utils as haystack_utils\n",
    "from sparse_coding.train_autoencoder import AutoEncoder\n",
    "from utils.autoencoder_utils import custom_forward, AutoEncoderConfig, evaluate_autoencoder_reconstruction, get_encoder_feature_frequencies\n",
    "import utils.haystack_utils as haystack_utils\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model tiny-stories-2L-33M into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "model_name = \"tiny-stories-2L-33M\"\n",
    "model = HookedTransformer.from_pretrained(\n",
    "    model_name,\n",
    "    center_unembed=True,\n",
    "    center_writing_weights=True,\n",
    "    fold_ln=True,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "def load_encoder(save_name, model_name):\n",
    "    with open(f\"{model_name}/{save_name}.json\", \"r\") as f:\n",
    "        cfg = json.load(f)\n",
    "\n",
    "    cfg = AutoEncoderConfig(\n",
    "        cfg[\"layer\"], cfg[\"act\"], cfg[\"expansion_factor\"], cfg[\"l1_coeff\"]\n",
    "    )\n",
    "\n",
    "    if cfg.act_name == \"hook_mlp_out\":\n",
    "        d_in = model.cfg.d_model\n",
    "    else:\n",
    "        d_in = model.cfg.d_mlp\n",
    "    d_hidden = d_in * cfg.expansion_factor\n",
    "\n",
    "    encoder = AutoEncoder(d_hidden, cfg.l1_coeff, d_in)\n",
    "    encoder.load_state_dict(torch.load(os.path.join(model_name, save_name + \".pt\")))\n",
    "    encoder.to(device)\n",
    "    return encoder, cfg\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_acts(prompt: str, model: HookedTransformer, encoder: AutoEncoder, cfg: AutoEncoderConfig):\n",
    "    _, cache = model.run_with_cache(prompt, names_filter=cfg.encoder_hook_point)\n",
    "    acts = cache[cfg.encoder_hook_point].squeeze(0)\n",
    "    _, _, mid_acts, _, _ = encoder(acts)\n",
    "    return mid_acts\n",
    "\n",
    "\n",
    "def get_max_activations(prompts: list[str], model: HookedTransformer, encoder: AutoEncoder, cfg: AutoEncoderConfig):\n",
    "    activations = []\n",
    "    indices = []\n",
    "    for prompt in tqdm(prompts):\n",
    "        acts = get_acts(prompt, model, encoder, cfg)[0, :-1]\n",
    "        value, index = acts.max(0)\n",
    "        activations.append(value)\n",
    "        indices.append(index)\n",
    "\n",
    "    max_activation_per_prompt = torch.stack(activations)  # n_prompt x d_enc\n",
    "    max_activation_token_index = torch.stack(indices)\n",
    "\n",
    "    total_activations = max_activation_per_prompt.sum(0)\n",
    "    print(f\"Active directions on validation data: {total_activations.nonzero().shape[0]} out of {total_activations.shape[0]}\")\n",
    "    return max_activation_per_prompt, max_activation_token_index\n",
    "\n",
    "\n",
    "def get_token_kurtosis_for_decoder(model: HookedTransformer, layer: int, decoder: torch.Tensor):\n",
    "    '''Return excess kurtosis over all decoder features' cosine sims with the unembed (higher is better)'''\n",
    "    W_out = model.W_out[layer]\n",
    "    resid_dirs = torch.nn.functional.normalize(decoder @ W_out, dim=-1)\n",
    "    unembed = torch.nn.functional.normalize(model.unembed.W_U, dim=0)\n",
    "    cosine_sims = einops.einsum(resid_dirs, unembed, 'd_hidden d_model, d_model d_vocab -> d_hidden d_vocab')\n",
    "    \n",
    "    mean = einops.repeat(cosine_sims.mean(dim=-1), f'd_hidden -> d_hidden {cosine_sims.shape[1]}')\n",
    "    std = einops.repeat(cosine_sims.std(dim=-1), f'd_hidden -> d_hidden {cosine_sims.shape[1]}')\n",
    "    kurt = torch.mean((cosine_sims - mean / std) ** 4, dim=-1) - 3\n",
    "    return kurt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. List of clean features\n",
    "# 2. Sort by indirect ablation increase\n",
    "# 3. Sort for things in layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "l0_encoder, l0_config = load_encoder('18_morning_sun', model_name)\n",
    "l1_encoder, l1_config = load_encoder('2_upbeat_snowball', model_name)\n",
    "\n",
    "# l1_kurtosis = get_token_kurtosis_for_decoder(model, 1, l1_encoder.W_dec)\n",
    "# px.histogram(pd.DataFrame({\"kurtosis\": l1_kurtosis.cpu()}))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(INFO) 10:21:59: Loaded 21990 TinyStories validation prompts\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f57c90193d84748b0a6d68b50828472",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active directions on validation data: 16384 out of 16384\n"
     ]
    }
   ],
   "source": [
    "prompts = load_tinystories_validation_prompts()[:10000]\n",
    "max_activations, max_activation_token_indies = get_max_activations(prompts, model, l0_encoder, l0_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_activation_token_indices = max_activation_token_indies\n",
    "max_activations_l0 = max_activations\n",
    "max_activation_token_indices_l0 = max_activation_token_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16384, 16384])\n"
     ]
    }
   ],
   "source": [
    "cosine_sims = torch.nn.functional.normalize(l0_encoder.W_dec, dim=-1) @ torch.nn.functional.normalize(l1_encoder.W_enc, dim=0)\n",
    "cosine_sims = torch.tril(cosine_sims)\n",
    "print(cosine_sims.shape)\n",
    "\n",
    "all_sims = cosine_sims.flatten().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# px.histogram(all_sims[torch.randperm(len(all_sims))][:10_000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, indices = torch.topk(all_sims, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(15671) tensor(1008)\n"
     ]
    }
   ],
   "source": [
    "def i_to_row_col(i: int, n_cols: int = len(cosine_sims)):\n",
    "    row = i // n_cols\n",
    "    col = i % n_cols\n",
    "    return row, col\n",
    "\n",
    "l0_dir, l1_dir = i_to_row_col(indices[0], len(cosine_sims))\n",
    "print(l0_dir, l1_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 16384])\n"
     ]
    }
   ],
   "source": [
    "print(max_activations_l0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dad8d6e605b4b659b6770a9c00259b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# one prompt\n",
    "# save direction activations\n",
    "# get index of max direction activation per prompt from pre-existing data\n",
    "# return loss per token, original and ablated\n",
    "# index into loss with positions where directions active, calculate loss increase\n",
    "\n",
    "\n",
    "def custom_forward(\n",
    "    enc: AutoEncoder, x: Float[Tensor, \"batch d_in\"], neuron: int, activation: float\n",
    "):\n",
    "    x_cent = x - enc.b_dec\n",
    "    acts = F.relu(x_cent @ enc.W_enc + enc.b_enc)\n",
    "    acts[:, neuron] = activation\n",
    "    x_reconstruct = acts @ enc.W_dec + enc.b_dec\n",
    "    return x_reconstruct, acts\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_autoencoder_reconstruction_per_token(prompt: str, pos: int, autoencoder: AutoEncoder, cfg: AutoEncoderConfig, model: HookedTransformer, direction: int):\n",
    "    \n",
    "    def encode_activations_hook(value, hook):\n",
    "        _, x_reconstruct, _, _, _ = autoencoder(value[:, pos])\n",
    "        value[:, pos] = x_reconstruct\n",
    "        return value\n",
    "\n",
    "    reconstruct_hooks = [(f\"blocks.{cfg.layer}.{cfg.act_name}\", encode_activations_hook)]\n",
    "\n",
    "    def zero_ablate_hook(value, hook):\n",
    "        x_reconstruct, _ = custom_forward(autoencoder, value[:, pos], direction, 0)\n",
    "        value[:, pos] = x_reconstruct\n",
    "        return value\n",
    "    \n",
    "    zero_ablate_hooks = [(f\"blocks.{cfg.layer}.{cfg.act_name}\", zero_ablate_hook)]\n",
    "    \n",
    "    original_loss = model(prompt, return_type=\"loss\", loss_per_token=True)[0, pos].item()\n",
    "    with model.hooks(reconstruct_hooks):\n",
    "        reconstruct_loss = model(prompt, return_type=\"loss\", loss_per_token=True)[0, pos].item()\n",
    "    with model.hooks(zero_ablate_hooks):\n",
    "        zero_ablate_loss = model(prompt, return_type=\"loss\", loss_per_token=True)[0, pos].item()\n",
    "    \n",
    "    return original_loss, reconstruct_loss, zero_ablate_loss\n",
    "\n",
    "\n",
    "dirs = [i_to_row_col(i) for i in indices]\n",
    "data = []\n",
    "for l0_dir, l1_dir in tqdm(dirs[:15]):\n",
    "    # max_activations_l0[:, l0_dir]\n",
    "    values, prompt_indices = torch.topk(max_activations_l0[:, l0_dir], k=50)\n",
    "    \n",
    "    original_losses = []\n",
    "    reconstruct_losses = []\n",
    "    zero_ablate_losses = []\n",
    "    for i in prompt_indices:\n",
    "        prompt = prompts[i]\n",
    "        pos_index = max_activation_token_indices_l0[i, l0_dir].item()\n",
    "        original_loss, reconstruct_loss, zero_ablate_loss = evaluate_autoencoder_reconstruction_per_token(prompt, pos_index, l0_encoder, l0_config, model, l0_dir)\n",
    "        original_losses.append(original_loss)\n",
    "        reconstruct_losses.append(reconstruct_loss)\n",
    "        zero_ablate_losses.append(zero_ablate_loss)\n",
    "    data.append([l0_dir, l1_dir, np.mean(original_losses), np.mean(reconstruct_losses), np.mean(zero_ablate_losses)])\n",
    "df = pd.DataFrame(data, columns=[\"l0_dir\", \"l1_dir\", \"original_loss\", \"reconstruct_loss\", \"zero_ablate_loss\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l0_dir</th>\n",
       "      <th>l1_dir</th>\n",
       "      <th>original_loss</th>\n",
       "      <th>reconstruct_loss</th>\n",
       "      <th>zero_ablate_loss</th>\n",
       "      <th>loss_increase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tensor(3078)</td>\n",
       "      <td>tensor(2717)</td>\n",
       "      <td>1.139115</td>\n",
       "      <td>1.449524</td>\n",
       "      <td>1.500091</td>\n",
       "      <td>0.050567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tensor(3084)</td>\n",
       "      <td>tensor(555)</td>\n",
       "      <td>1.577442</td>\n",
       "      <td>1.571623</td>\n",
       "      <td>1.600115</td>\n",
       "      <td>0.028491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tensor(6306)</td>\n",
       "      <td>tensor(4666)</td>\n",
       "      <td>1.218571</td>\n",
       "      <td>1.254769</td>\n",
       "      <td>1.273814</td>\n",
       "      <td>0.019044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tensor(12738)</td>\n",
       "      <td>tensor(1970)</td>\n",
       "      <td>1.065921</td>\n",
       "      <td>1.106483</td>\n",
       "      <td>1.125427</td>\n",
       "      <td>0.018944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>tensor(9183)</td>\n",
       "      <td>tensor(7899)</td>\n",
       "      <td>1.170940</td>\n",
       "      <td>1.397148</td>\n",
       "      <td>1.412604</td>\n",
       "      <td>0.015456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tensor(5471)</td>\n",
       "      <td>tensor(2663)</td>\n",
       "      <td>0.781454</td>\n",
       "      <td>0.889481</td>\n",
       "      <td>0.900346</td>\n",
       "      <td>0.010865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>tensor(15319)</td>\n",
       "      <td>tensor(525)</td>\n",
       "      <td>1.029166</td>\n",
       "      <td>1.284547</td>\n",
       "      <td>1.291323</td>\n",
       "      <td>0.006776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tensor(12974)</td>\n",
       "      <td>tensor(7589)</td>\n",
       "      <td>3.265839</td>\n",
       "      <td>4.267891</td>\n",
       "      <td>4.269192</td>\n",
       "      <td>0.001301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tensor(15192)</td>\n",
       "      <td>tensor(12425)</td>\n",
       "      <td>1.819522</td>\n",
       "      <td>1.998446</td>\n",
       "      <td>1.999414</td>\n",
       "      <td>0.000969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tensor(15339)</td>\n",
       "      <td>tensor(9325)</td>\n",
       "      <td>0.621281</td>\n",
       "      <td>0.651502</td>\n",
       "      <td>0.649526</td>\n",
       "      <td>-0.001977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tensor(15671)</td>\n",
       "      <td>tensor(1008)</td>\n",
       "      <td>1.075191</td>\n",
       "      <td>1.242980</td>\n",
       "      <td>1.240349</td>\n",
       "      <td>-0.002631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tensor(11051)</td>\n",
       "      <td>tensor(9308)</td>\n",
       "      <td>1.636264</td>\n",
       "      <td>1.778775</td>\n",
       "      <td>1.771391</td>\n",
       "      <td>-0.007384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>tensor(10119)</td>\n",
       "      <td>tensor(8119)</td>\n",
       "      <td>1.152321</td>\n",
       "      <td>1.179017</td>\n",
       "      <td>1.170368</td>\n",
       "      <td>-0.008649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>tensor(10027)</td>\n",
       "      <td>tensor(8491)</td>\n",
       "      <td>0.493853</td>\n",
       "      <td>0.470211</td>\n",
       "      <td>0.460408</td>\n",
       "      <td>-0.009804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tensor(8021)</td>\n",
       "      <td>tensor(4981)</td>\n",
       "      <td>1.725295</td>\n",
       "      <td>1.781789</td>\n",
       "      <td>1.758424</td>\n",
       "      <td>-0.023365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           l0_dir         l1_dir  original_loss  reconstruct_loss  \\\n",
       "1    tensor(3078)   tensor(2717)       1.139115          1.449524   \n",
       "4    tensor(3084)    tensor(555)       1.577442          1.571623   \n",
       "3    tensor(6306)   tensor(4666)       1.218571          1.254769   \n",
       "2   tensor(12738)   tensor(1970)       1.065921          1.106483   \n",
       "12   tensor(9183)   tensor(7899)       1.170940          1.397148   \n",
       "9    tensor(5471)   tensor(2663)       0.781454          0.889481   \n",
       "14  tensor(15319)    tensor(525)       1.029166          1.284547   \n",
       "8   tensor(12974)   tensor(7589)       3.265839          4.267891   \n",
       "10  tensor(15192)  tensor(12425)       1.819522          1.998446   \n",
       "6   tensor(15339)   tensor(9325)       0.621281          0.651502   \n",
       "0   tensor(15671)   tensor(1008)       1.075191          1.242980   \n",
       "7   tensor(11051)   tensor(9308)       1.636264          1.778775   \n",
       "13  tensor(10119)   tensor(8119)       1.152321          1.179017   \n",
       "11  tensor(10027)   tensor(8491)       0.493853          0.470211   \n",
       "5    tensor(8021)   tensor(4981)       1.725295          1.781789   \n",
       "\n",
       "    zero_ablate_loss  loss_increase  \n",
       "1           1.500091       0.050567  \n",
       "4           1.600115       0.028491  \n",
       "3           1.273814       0.019044  \n",
       "2           1.125427       0.018944  \n",
       "12          1.412604       0.015456  \n",
       "9           0.900346       0.010865  \n",
       "14          1.291323       0.006776  \n",
       "8           4.269192       0.001301  \n",
       "10          1.999414       0.000969  \n",
       "6           0.649526      -0.001977  \n",
       "0           1.240349      -0.002631  \n",
       "7           1.771391      -0.007384  \n",
       "13          1.170368      -0.008649  \n",
       "11          0.460408      -0.009804  \n",
       "5           1.758424      -0.023365  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"loss_increase\"] = df[\"zero_ablate_loss\"] - df[\"reconstruct_loss\"]\n",
    "df.sort_values(\"loss_increase\", ascending=False, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004270189322327611"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Percentage increase\n",
    "((df[\"zero_ablate_loss\"] - df[\"reconstruct_loss\"]) / df[\"reconstruct_loss\"]).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10807562473493677"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((df[\"reconstruct_loss\"] - df[\"original_loss\"]) / df[\"original_loss\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a54c73a45ede4046bb37970b9159ab69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "l0_acts = []\n",
    "l1_acts = []\n",
    "for prompt in tqdm(prompts[:500]):\n",
    "    l0_act = get_acts(prompt, model, l0_encoder, l0_config).cpu()\n",
    "    l1_act = get_acts(prompt, model, l1_encoder, l1_config).cpu()\n",
    "    l0_acts.append(l0_act)\n",
    "    l1_acts.append(l1_act)\n",
    "l0_acts = torch.cat(l0_acts, dim=0)\n",
    "l1_acts = torch.cat(l1_acts, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(35.4037)\n",
      "tensor(88.1443)\n"
     ]
    }
   ],
   "source": [
    "l0_norm = l0_acts.abs().sum(-1).mean()\n",
    "print(l0_norm)\n",
    "l1_norm = l1_acts.abs().sum(-1).mean()\n",
    "print(l1_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "del l0_acts, l1_acts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
