{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "import requests\n",
    "import logging\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from transformer_lens import HookedTransformer\n",
    "from tqdm.auto import tqdm\n",
    "import plotly.io as pio\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import wandb\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import torch.nn.init as init\n",
    "from pathlib import Path\n",
    "from jaxtyping import Int, Float\n",
    "from torch import Tensor\n",
    "import einops\n",
    "from collections import Counter\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from ipywidgets import interact, IntSlider\n",
    "from process_tiny_stories_data import load_tinystories_validation_prompts, load_tinystories_tokens\n",
    "from typing import Literal\n",
    "\n",
    "\n",
    "pio.renderers.default = \"notebook_connected\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "torch.autograd.set_grad_enabled(False)\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "logging.basicConfig(format='(%(levelname)s) %(asctime)s: %(message)s', level=logging.INFO, datefmt='%I:%M:%S')\n",
    "sys.path.append('../')  # Add the parent directory to the system path\n",
    "\n",
    "import utils.haystack_utils as haystack_utils\n",
    "from sparse_coding.train_autoencoder import AutoEncoder\n",
    "from utils.autoencoder_utils import custom_forward, AutoEncoderConfig, evaluate_autoencoder_reconstruction, get_encoder_feature_frequencies, load_encoder, get_acts\n",
    "import utils.haystack_utils as haystack_utils\n",
    "from utils.plotting_utils import line\n",
    "from sparse_coding.spacy_tag import make_spacy_feature_df\n",
    "\n",
    "from utils.probing_utils import train_probe\n",
    "import utils.probing_utils as probing_utils\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-trf==3.7.3\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_trf-3.7.3/en_core_web_trf-3.7.3-py3-none-any.whl (457.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m457.4/457.4 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-trf==3.7.3) (3.7.2)\n",
      "Requirement already satisfied: spacy-curated-transformers<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-trf==3.7.3) (0.2.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (8.2.1)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (0.9.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (4.66.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (2.5.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (68.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (23.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (1.24.1)\n",
      "Requirement already satisfied: curated-transformers<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy-curated-transformers<0.3.0,>=0.2.0->en-core-web-trf==3.7.3) (0.1.1)\n",
      "Requirement already satisfied: curated-tokenizers<0.1.0,>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from spacy-curated-transformers<0.3.0,>=0.2.0->en-core-web-trf==3.7.3) (0.0.8)\n",
      "Requirement already satisfied: torch>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from spacy-curated-transformers<0.3.0,>=0.2.0->en-core-web-trf==3.7.3) (2.1.1)\n",
      "Requirement already satisfied: regex>=2022 in /usr/local/lib/python3.10/dist-packages (from curated-tokenizers<0.1.0,>=0.0.7->spacy-curated-transformers<0.3.0,>=0.2.0->en-core-web-trf==3.7.3) (2023.10.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.5 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (2.14.5)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (2022.12.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (0.1.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->spacy-curated-transformers<0.3.0,>=0.2.0->en-core-web-trf==3.7.3) (3.9.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->spacy-curated-transformers<0.3.0,>=0.2.0->en-core-web-trf==3.7.3) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->spacy-curated-transformers<0.3.0,>=0.2.0->en-core-web-trf==3.7.3) (3.0)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->spacy-curated-transformers<0.3.0,>=0.2.0->en-core-web-trf==3.7.3) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->spacy-curated-transformers<0.3.0,>=0.2.0->en-core-web-trf==3.7.3) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->spacy-curated-transformers<0.3.0,>=0.2.0->en-core-web-trf==3.7.3) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->spacy-curated-transformers<0.3.0,>=0.2.0->en-core-web-trf==3.7.3) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->spacy-curated-transformers<0.3.0,>=0.2.0->en-core-web-trf==3.7.3) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->spacy-curated-transformers<0.3.0,>=0.2.0->en-core-web-trf==3.7.3) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->spacy-curated-transformers<0.3.0,>=0.2.0->en-core-web-trf==3.7.3) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->spacy-curated-transformers<0.3.0,>=0.2.0->en-core-web-trf==3.7.3) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->spacy-curated-transformers<0.3.0,>=0.2.0->en-core-web-trf==3.7.3) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->spacy-curated-transformers<0.3.0,>=0.2.0->en-core-web-trf==3.7.3) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->spacy-curated-transformers<0.3.0,>=0.2.0->en-core-web-trf==3.7.3) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->spacy-curated-transformers<0.3.0,>=0.2.0->en-core-web-trf==3.7.3) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->spacy-curated-transformers<0.3.0,>=0.2.0->en-core-web-trf==3.7.3) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.12.0->spacy-curated-transformers<0.3.0,>=0.2.0->en-core-web-trf==3.7.3) (12.3.101)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.12.0->spacy-curated-transformers<0.3.0,>=0.2.0->en-core-web-trf==3.7.3) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_trf')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['python', '-m', 'spacy', 'download', 'en_core_web_trf'], returncode=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "subprocess.run(['python', '-m', 'spacy', 'download', 'en_core_web_trf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(INFO) 08:09:01: Loaded 21990 TinyStories validation prompts\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model tiny-stories-2L-33M into HookedTransformer\n",
      "torch.Size([40, 304])\n",
      "Starting spacy processing of dataset...\n",
      "Finished spacy processing of dataset.\n",
      "1701418166.560078 0\n"
     ]
    }
   ],
   "source": [
    "haystack_utils.clean_cache()\n",
    "os.environ[\"PYTORCH_MPS_HIGH_WATERMARK_RATIO\"] = \"0.2\"\n",
    "\n",
    "model_name = \"tiny-stories-2L-33M\"\n",
    "print_name = \"TinyStories 2L 33M\"\n",
    "\n",
    "model = HookedTransformer.from_pretrained(\n",
    "    model_name,\n",
    "    center_unembed=True,\n",
    "    center_writing_weights=True,\n",
    "    fold_ln=True,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "n_prompts = 40\n",
    "prompts = load_tinystories_validation_prompts(data_path='data/tinystories')[:n_prompts]\n",
    "tokens = model.to_tokens(prompts)\n",
    "print(tokens.shape)\n",
    "try:\n",
    "    df = make_spacy_feature_df(model, tokens)\n",
    "except:\n",
    "    try:\n",
    "        df = make_spacy_feature_df(model, tokens)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40, 304])\n"
     ]
    }
   ],
   "source": [
    "df[[\"is_spacy_adj\"]]\n",
    "print(tokens.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look for encoder features that go on particular spacy attributes\n",
    "save_name = '18_morning_sun'\n",
    "encoder, cfg = load_encoder(save_name, model_name, model, save_path='/workspace')\n",
    "\n",
    "# acts = []\n",
    "# for i in range(len(tokens)):\n",
    "#     acts.append(get_acts(tokens[i], model, encoder, cfg))\n",
    "# acts = torch.cat(acts).cpu()\n",
    "\n",
    "# threshold = 0.1\n",
    "# f1_scores = {}\n",
    "# for series_name, series in tqdm(df.items()):\n",
    "#     neuron_binarized = (acts > threshold).T\n",
    "#     for i in range(len(neuron_binarized)):\n",
    "#         f1_scores[(series_name, i)] = f1_score(series, neuron_binarized[i])\n",
    "\n",
    "# new_f1_scores = {}\n",
    "# for key, value in f1_scores.items():\n",
    "#     col, direction = key\n",
    "#     if col not in new_f1_scores:\n",
    "#         new_f1_scores[col] = {}\n",
    "#     new_f1_scores[col][direction] = value\n",
    "\n",
    "# with open('/workspace/data/spacy_f1s_2.json', 'w') as f:\n",
    "#     json.dump(new_f1_scores, f)\n",
    "with open('/workspace/data/spacy_f1s.json', 'r') as f:\n",
    "    new_f1_scores = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0', 0.0), ('1', 0.0), ('2', 0.0), ('3', 0.0), ('4', 0.012048192771084336)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(list(new_f1_scores.items())[0][1].items())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "good_uns = defaultdict(list)\n",
    "interesting_directions = []\n",
    "for col, items in new_f1_scores.items():\n",
    "    # there are hundred of punctuation dirs and they're probably less interesting\n",
    "    if col == \"is_spacy_punct\":\n",
    "        continue\n",
    "    for direction, f1 in items.items():\n",
    "        if f1 > 0.4:\n",
    "            interesting_directions.append(direction)\n",
    "            good_uns[col].append(direction)\n",
    "\n",
    "\n",
    "# del good_uns[\"is_spacy_punct\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n",
      "66\n"
     ]
    }
   ],
   "source": [
    "\n",
    "good_uns\n",
    "cols_with_dirs = list((col, [int(dir) for dir in dirs]) for col, dirs in good_uns.items())\n",
    "print(len(cols_with_dirs))\n",
    "print(len(set(interesting_directions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting spacy processing of dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b33d5c2d7c74af29ac142677a1ab12c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished spacy processing of dataset.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83772423943946128475194c669d9db1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1701420222.20287 0\n"
     ]
    }
   ],
   "source": [
    "# Round two of what we just did above, but now only collecting acts data for the positive and negative classes of the direction/spacy attribute tuples we are interested in.\n",
    "haystack_utils.clean_cache()\n",
    "n_prompts = 200\n",
    "prompts = load_tinystories_validation_prompts(data_path='data/tinystories')[:n_prompts]\n",
    "tokens = model.to_tokens(prompts)\n",
    "df = make_spacy_feature_df(model, tokens, use_tqdm=True)\n",
    "\n",
    "def train_probe(\n",
    "    positive_data: torch.Tensor, negative_data: torch.Tensor\n",
    ") -> tuple[float, float]:\n",
    "    labels = np.concatenate([np.ones(len(positive_data)), np.zeros(len(negative_data))])\n",
    "    data = np.concatenate([positive_data.cpu().numpy(), negative_data.cpu().numpy()])\n",
    "    scaler = preprocessing.StandardScaler().fit(data)\n",
    "    data = scaler.transform(data)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        data, labels, test_size=0.2, random_state=42\n",
    "    )\n",
    "    probe = probing_utils.get_probe(x_train, y_train, max_iter=2000)\n",
    "    f1, mcc = probing_utils.get_probe_score(probe, x_test, y_test)\n",
    "    return f1, mcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "interesting_directions_ints = [int(dir) for dir in interesting_directions]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72191e272494485da43a848f486baefc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         False\n",
      "1         False\n",
      "2         False\n",
      "3         False\n",
      "4         False\n",
      "          ...  \n",
      "209195    False\n",
      "209196    False\n",
      "209197    False\n",
      "209198    False\n",
      "209199    False\n",
      "Name: is_spacy_det, Length: 209200, dtype: bool\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "tensor([[False,  True,  True,  ..., False, False, False],\n        [False,  True,  True,  ..., False, False, False],\n        [False,  True,  True,  ..., False, False, False],\n        ...,\n        [False,  True,  True,  ..., False, False, False],\n        [False,  True,  True,  ..., False, False, False],\n        [False,  True,  True,  ...,  True,  True,  True]], device='cuda:0')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/root/superposition/sparse_coding/spacy_investigate.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B149.36.0.90/root/superposition/sparse_coding/spacy_investigate.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# WIP filter out 0s\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B149.36.0.90/root/superposition/sparse_coding/spacy_investigate.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mprint\u001b[39m(token_attributes)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B149.36.0.90/root/superposition/sparse_coding/spacy_investigate.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m token_attributes \u001b[39m=\u001b[39m token_attributes[tokens \u001b[39m!=\u001b[39;49m \u001b[39m50256\u001b[39;49m]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B149.36.0.90/root/superposition/sparse_coding/spacy_investigate.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m# dir_acts = acts[:, interesting_directions_ints.index(dir)]\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B149.36.0.90/root/superposition/sparse_coding/spacy_investigate.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m dir_acts \u001b[39m=\u001b[39m acts[tokens \u001b[39m!=\u001b[39m \u001b[39m50256\u001b[39m, interesting_directions_ints\u001b[39m.\u001b[39mindex(\u001b[39mdir\u001b[39m)]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py:1040\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1037\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n\u001b[1;32m   1039\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1040\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_value(key)\n\u001b[1;32m   1042\u001b[0m \u001b[39m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[1;32m   1043\u001b[0m \u001b[39m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[1;32m   1044\u001b[0m \u001b[39mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py:1156\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1153\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[label]\n\u001b[1;32m   1155\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1156\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(label)\n\u001b[1;32m   1158\u001b[0m \u001b[39mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1159\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/range.py:418\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Hashable):\n\u001b[0;32m--> 418\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key)\n\u001b[1;32m    419\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n\u001b[1;32m    420\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: tensor([[False,  True,  True,  ..., False, False, False],\n        [False,  True,  True,  ..., False, False, False],\n        [False,  True,  True,  ..., False, False, False],\n        ...,\n        [False,  True,  True,  ..., False, False, False],\n        [False,  True,  True,  ..., False, False, False],\n        [False,  True,  True,  ...,  True,  True,  True]], device='cuda:0')"
     ]
    }
   ],
   "source": [
    "acts = []\n",
    "for i in range(len(tokens)):\n",
    "    act = get_acts(tokens[i], model, encoder, cfg)\n",
    "    acts.append(act[:, interesting_directions_ints])\n",
    "\n",
    "acts = torch.cat(acts, dim=0).cpu() # batch d_interesting\n",
    "# compare acts and spacy annotations to get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_tokens = tokens.flatten().cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e661043f4ae4cc6b64c8b74fed39d3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2738 positive class activations, 10000 negative class activations\n",
      "2207 positive class activations, 10000 negative class activations\n",
      "1156 positive class activations, 10000 negative class activations\n",
      "1156 positive class activations, 10000 negative class activations\n",
      "1156 positive class activations, 10000 negative class activations\n",
      "1156 positive class activations, 10000 negative class activations\n",
      "1156 positive class activations, 10000 negative class activations\n",
      "214 positive class activations, 10000 negative class activations\n",
      "214 positive class activations, 10000 negative class activations\n",
      "214 positive class activations, 10000 negative class activations\n",
      "214 positive class activations, 10000 negative class activations\n",
      "214 positive class activations, 10000 negative class activations\n",
      "214 positive class activations, 10000 negative class activations\n",
      "214 positive class activations, 10000 negative class activations\n",
      "214 positive class activations, 10000 negative class activations\n",
      "214 positive class activations, 10000 negative class activations\n",
      "214 positive class activations, 10000 negative class activations\n",
      "214 positive class activations, 10000 negative class activations\n",
      "1607 positive class activations, 10000 negative class activations\n",
      "738 positive class activations, 10000 negative class activations\n",
      "738 positive class activations, 10000 negative class activations\n",
      "124 positive class activations, 10000 negative class activations\n",
      "124 positive class activations, 10000 negative class activations\n",
      "124 positive class activations, 10000 negative class activations\n",
      "124 positive class activations, 10000 negative class activations\n",
      "1182 positive class activations, 10000 negative class activations\n",
      "1182 positive class activations, 10000 negative class activations\n",
      "1182 positive class activations, 10000 negative class activations\n",
      "88 positive class activations, 10000 negative class activations\n",
      "1606 positive class activations, 10000 negative class activations\n",
      "206 positive class activations, 10000 negative class activations\n",
      "206 positive class activations, 10000 negative class activations\n",
      "206 positive class activations, 10000 negative class activations\n",
      "206 positive class activations, 10000 negative class activations\n",
      "206 positive class activations, 10000 negative class activations\n",
      "206 positive class activations, 10000 negative class activations\n",
      "206 positive class activations, 10000 negative class activations\n",
      "206 positive class activations, 10000 negative class activations\n",
      "206 positive class activations, 10000 negative class activations\n",
      "206 positive class activations, 10000 negative class activations\n",
      "206 positive class activations, 10000 negative class activations\n",
      "1068 positive class activations, 10000 negative class activations\n",
      "511 positive class activations, 10000 negative class activations\n",
      "511 positive class activations, 10000 negative class activations\n",
      "511 positive class activations, 10000 negative class activations\n",
      "511 positive class activations, 10000 negative class activations\n",
      "511 positive class activations, 10000 negative class activations\n",
      "511 positive class activations, 10000 negative class activations\n",
      "45 positive class activations, 10000 negative class activations\n",
      "213 positive class activations, 10000 negative class activations\n",
      "213 positive class activations, 10000 negative class activations\n",
      "213 positive class activations, 10000 negative class activations\n",
      "213 positive class activations, 10000 negative class activations\n",
      "213 positive class activations, 10000 negative class activations\n",
      "213 positive class activations, 10000 negative class activations\n",
      "213 positive class activations, 10000 negative class activations\n",
      "213 positive class activations, 10000 negative class activations\n",
      "929 positive class activations, 10000 negative class activations\n",
      "324 positive class activations, 10000 negative class activations\n",
      "324 positive class activations, 10000 negative class activations\n",
      "324 positive class activations, 10000 negative class activations\n",
      "1488 positive class activations, 10000 negative class activations\n",
      "259 positive class activations, 10000 negative class activations\n",
      "259 positive class activations, 10000 negative class activations\n",
      "352 positive class activations, 10000 negative class activations\n",
      "352 positive class activations, 10000 negative class activations\n",
      "2480 positive class activations, 10000 negative class activations\n",
      "215 positive class activations, 10000 negative class activations\n",
      "48 positive class activations, 10000 negative class activations\n",
      "48 positive class activations, 10000 negative class activations\n",
      "48 positive class activations, 10000 negative class activations\n",
      "48 positive class activations, 10000 negative class activations\n",
      "48 positive class activations, 10000 negative class activations\n",
      "48 positive class activations, 10000 negative class activations\n",
      "692 positive class activations, 10000 negative class activations\n",
      "692 positive class activations, 10000 negative class activations\n",
      "692 positive class activations, 10000 negative class activations\n",
      "692 positive class activations, 10000 negative class activations\n",
      "692 positive class activations, 10000 negative class activations\n",
      "297 positive class activations, 10000 negative class activations\n",
      "297 positive class activations, 10000 negative class activations\n",
      "297 positive class activations, 10000 negative class activations\n",
      "297 positive class activations, 10000 negative class activations\n",
      "297 positive class activations, 10000 negative class activations\n",
      "297 positive class activations, 10000 negative class activations\n",
      "297 positive class activations, 10000 negative class activations\n",
      "390 positive class activations, 10000 negative class activations\n",
      "2162 positive class activations, 10000 negative class activations\n",
      "19 positive class activations, 10000 negative class activations\n",
      "4 positive class activations, 10000 negative class activations\n",
      "8 positive class activations, 10000 negative class activations\n",
      "8 positive class activations, 10000 negative class activations\n",
      "8 positive class activations, 10000 negative class activations\n",
      "8 positive class activations, 10000 negative class activations\n",
      "10000 positive class activations, 10000 negative class activations\n"
     ]
    }
   ],
   "source": [
    "f1s = []\n",
    "mccs = []\n",
    "for col, dirs in tqdm(cols_with_dirs):\n",
    "    for dir in dirs:\n",
    "        token_attributes = df[[col]].squeeze(1)\n",
    "        attr_tensor = torch.tensor(token_attributes)[flattened_tokens != 50256] # 1 batch\n",
    "        dir_acts = acts[flattened_tokens != 50256, interesting_directions_ints.index(dir)]\n",
    "\n",
    "        pos_class = dir_acts[attr_tensor == True][:10_000]\n",
    "        neg_class = dir_acts[attr_tensor == False][:10_000]\n",
    "        print(f\"{len(pos_class)} positive class activations, {len(neg_class)} negative class activations\")\n",
    "        f1, mcc = train_probe(\n",
    "            pos_class.unsqueeze(-1),\n",
    "            neg_class.unsqueeze(-1),\n",
    "        )\n",
    "        f1s.append(f1)\n",
    "        mccs.append(mcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4621621621621621, 0.42214532871972316, 0.622093023255814, 0.5934718100890208, 0.4147157190635452, 0.7238605898123326, 0.4252491694352159, 0.6666666666666666, 0.7246376811594203, 0.5806451612903226, 0.5806451612903226, 0.7777777777777778, 0.7428571428571429, 0.36363636363636365, 0.8108108108108109, 0.7945205479452054, 0.456140350877193, 0.4827586206896552, 0.6602316602316602, 0.3316062176165803, 0.3316062176165803, 0.2631578947368421, 0.16216216216216214, 0.25641025641025644, 0.16666666666666669, 0.6518105849582172, 0.5971014492753624, 0.7225130890052355, 0.16, 0.6499032882011605, 0.6774193548387097, 0.7384615384615384, 0.6333333333333334, 0.5090909090909091, 0.7941176470588235, 0.7575757575757575, 0.39215686274509803, 0.8000000000000002, 0.8115942028985507, 0.4230769230769231, 0.36, 0.49122807017543857, 0.39999999999999997, 0.4794520547945206, 0.1951219512195122, 0.41958041958041964, 0.5263157894736842, 0.3357664233576642, 0.0, 0.47457627118644075, 0.42857142857142855, 0.8354430379746834, 0.42857142857142855, 0.8, 0.7777777777777778, 0.2745098039215686, 0.625, 0.29914529914529914, 0.5360824742268041, 0.5624999999999999, 0.34146341463414637, 0.2209302325581395, 0.21428571428571425, 0.41269841269841273, 0.4166666666666667, 0.21428571428571425, 0.5310734463276836, 0.16666666666666669, 0.45454545454545453, 0.6923076923076924, 0.45454545454545453, 0.7407407407407407, 0.5833333333333334, 0.5833333333333334, 0.14012738853503182, 0.39999999999999997, 0.37569060773480667, 0.38674033149171266, 0.2303030303030303, 0.475, 0.7884615384615384, 0.28169014084507044, 0.7676767676767677, 0.7551020408163265, 0.1515151515151515, 0.5121951219512195, 0.22916666666666669, 0.4084507042253521, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.0954524988743809]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c37d8635ccf04452b0de4d8feb73ccb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f1s)\n",
    "\n",
    "attrs = []\n",
    "for col, dirs in tqdm(cols_with_dirs):\n",
    "    for dir in dirs:\n",
    "        attrs.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/workspace/data/spacy_summary_stats.json', 'w') as f:\n",
    "    json.dump({\n",
    "        \"f1s\": f1s,\n",
    "        \"mccs\": mccs,\n",
    "        \"dirs\": interesting_directions,\n",
    "        \"attrs\": attrs\n",
    "    }, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.symlink('/workspace', 'workspace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_spacy_num\n",
      "is_spacy_num\n",
      "is_spacy_num\n",
      "is_spacy_nummod\n",
      "is_spacy_nummod\n",
      "is_spacy_nummod\n",
      "is_spacy_nummod\n",
      "is_spacy_acl\n",
      "is_spacy_acl\n",
      "is_spacy_acl\n",
      "is_perf_aspect\n",
      "is_perf_aspect\n",
      "is_perf_aspect\n",
      "is_ORDINAL\n",
      "Map labels:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label mapping for component: parser\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/spacy/glossary.py:20: UserWarning:\n",
      "\n",
      "[W118] Term 'predet' not found in glossary. It may however be explained in documentation for the corpora used to train the language. Please check `nlp.meta[\"sources\"]` for any relevant links.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ROOT': 'root',\n",
       " 'acl': 'clausal modifier of noun (adjectival clause)',\n",
       " 'acomp': 'adjectival complement',\n",
       " 'advcl': 'adverbial clause modifier',\n",
       " 'advmod': 'adverbial modifier',\n",
       " 'agent': 'agent',\n",
       " 'amod': 'adjectival modifier',\n",
       " 'appos': 'appositional modifier',\n",
       " 'attr': 'attribute',\n",
       " 'aux': 'auxiliary',\n",
       " 'auxpass': 'auxiliary (passive)',\n",
       " 'case': 'case marking',\n",
       " 'cc': 'coordinating conjunction',\n",
       " 'ccomp': 'clausal complement',\n",
       " 'compound': 'compound',\n",
       " 'conj': 'conjunct',\n",
       " 'csubj': 'clausal subject',\n",
       " 'csubjpass': 'clausal subject (passive)',\n",
       " 'dative': 'dative',\n",
       " 'dep': 'unclassified dependent',\n",
       " 'det': 'determiner',\n",
       " 'dobj': 'direct object',\n",
       " 'expl': 'expletive',\n",
       " 'intj': 'interjection',\n",
       " 'mark': 'marker',\n",
       " 'meta': 'meta modifier',\n",
       " 'neg': 'negation modifier',\n",
       " 'nmod': 'modifier of nominal',\n",
       " 'npadvmod': 'noun phrase as adverbial modifier',\n",
       " 'nsubj': 'nominal subject',\n",
       " 'nsubjpass': 'nominal subject (passive)',\n",
       " 'nummod': 'numeric modifier',\n",
       " 'oprd': 'object predicate',\n",
       " 'parataxis': 'parataxis',\n",
       " 'pcomp': 'complement of preposition',\n",
       " 'pobj': 'object of preposition',\n",
       " 'poss': 'possession modifier',\n",
       " 'preconj': 'pre-correlative conjunction',\n",
       " 'predet': None,\n",
       " 'prep': 'prepositional modifier',\n",
       " 'prt': 'particle',\n",
       " 'punct': 'punctuation',\n",
       " 'quantmod': 'modifier of quantifier',\n",
       " 'relcl': 'relative clause modifier',\n",
       " 'xcomp': 'open clausal complement'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, f1 in enumerate(f1s):\n",
    "    if f1 > 0.75:\n",
    "        print(attrs[i])\n",
    "\n",
    "\n",
    "# explanations of attributes\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_trf\")\n",
    "\n",
    "for component in nlp.pipe_names:\n",
    "    if component == \"parser\":\n",
    "        tags = nlp.pipe_labels[component]\n",
    "        if len(tags)!=0:\n",
    "            print(f\"Label mapping for component: {component}\")\n",
    "            display(dict(list(zip(tags, [spacy.explain(tag) for tag in tags]))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
