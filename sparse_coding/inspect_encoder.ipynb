{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "import requests\n",
    "import logging\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from transformer_lens import HookedTransformer\n",
    "from tqdm.auto import tqdm\n",
    "import plotly.io as pio\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import wandb\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import torch.nn.init as init\n",
    "from pathlib import Path\n",
    "from jaxtyping import Int, Float\n",
    "from torch import Tensor\n",
    "import einops\n",
    "from collections import Counter\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from ipywidgets import interact, IntSlider\n",
    "from process_tiny_stories_data import load_tinystories_validation_prompts, load_tinystories_tokens\n",
    "from typing import Literal\n",
    "from transformer_lens.utils import test_prompt\n",
    "import pickle\n",
    "from ipywidgets import interact, IntSlider, SelectionSlider\n",
    "from transformer_lens.utils import test_prompt\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "pio.renderers.default = \"notebook_connected\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "torch.autograd.set_grad_enabled(False)\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "logging.basicConfig(format='(%(levelname)s) %(asctime)s: %(message)s', level=logging.INFO, datefmt='%I:%M:%S')\n",
    "sys.path.append('../')  # Add the parent directory to the system path\n",
    "\n",
    "import utils.haystack_utils as haystack_utils\n",
    "from sparse_coding.train_autoencoder import AutoEncoder\n",
    "from utils.autoencoder_utils import AutoEncoderConfig, eval_direction_tokens_global, get_activations, get_acts, load_encoder, eval_ablation_token_rank, get_direction_ablation_hook, get_top_activating_examples_for_direction, evaluate_direction_ablation_single_prompt\n",
    "import utils.haystack_utils as haystack_utils\n",
    "from utils.plotting_utils import line, multiple_line, plot_square_heatmap\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(INFO) 12:26:22: Loaded 21990 TinyStories validation prompts\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model tiny-stories-2L-33M into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "model_name = \"tiny-stories-2L-33M\"\n",
    "model = HookedTransformer.from_pretrained(\n",
    "    model_name,\n",
    "    center_unembed=True,\n",
    "    center_writing_weights=True,\n",
    "    fold_ln=True,\n",
    "    device=device,\n",
    ")\n",
    "model.set_use_attn_result(True)\n",
    "prompts = load_tinystories_validation_prompts()[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85_rich_puddle 1 0.0001\n"
     ]
    }
   ],
   "source": [
    "run_name = \"85_rich_puddle\"\n",
    "encoder, cfg = load_encoder(run_name, model_name, model)\n",
    "cfg.run_name = run_name\n",
    "print(cfg.run_name, cfg.layer, cfg.l1_coeff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:48<00:00, 102.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active directions on validation data: 12816 out of 16384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "run_name = cfg.run_name\n",
    "max_activations, max_activation_token_indices = get_activations(encoder, cfg, run_name, prompts, model, save_activations=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_examples(prompts: list[str], activations: Float[Tensor, \"n_prompts d_enc\"], direction: int, encoder: AutoEncoder, cfg: AutoEncoderConfig, n=5):\n",
    "    top_idxs = activations[:, direction].argsort(descending=True)[:n].cpu().tolist()\n",
    "    for prompt_index in top_idxs:\n",
    "        prompt = prompts[prompt_index]\n",
    "        prompt_tokens = model.to_str_tokens(model.to_tokens(prompt))\n",
    "        acts = get_acts(prompt, model, encoder, cfg)\n",
    "        direction_act = acts[:, direction].cpu().tolist()\n",
    "        max_direction_act = max(direction_act)\n",
    "        if max_direction_act > 0:\n",
    "            haystack_utils.clean_print_strings_as_html(prompt_tokens, direction_act, max_value=max_direction_act)\n",
    "\n",
    "def print_direction_example(direction, n=10):\n",
    "    print_top_examples(prompts, max_activations, direction, encoder, cfg, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9912bade13c4b798da19d1ef49423fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='direction', max=16383), IntSlider(value=5, description='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.print_direction_example(direction, n=10)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interact(print_direction_example, \n",
    "         direction=IntSlider(min=0, max=encoder.d_hidden-1, step=1, value=0),\n",
    "         n=IntSlider(min=1, max=20, step=1, value=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
