{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_lens import HookedTransformer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import json\n",
    "from huggingface_hub import PyTorchModelHubMixin\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model tiny-stories-2L-33M into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "model_name = \"tiny-stories-2L-33M\"\n",
    "model = HookedTransformer.from_pretrained(model_name, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseAutoEncoder(nn.Module, PyTorchModelHubMixin):\n",
    "    def __init__(\n",
    "        self, config=None\n",
    "    ):\n",
    "        super().__init__()\n",
    "        if config is None:\n",
    "            raise ValueError(\"Config not provided\")\n",
    "        torch.manual_seed(config[\"seed\"])\n",
    "        d_in = config[\"d_in\"]\n",
    "        d_hidden = config[\"d_hidden\"]\n",
    "        dtype = getattr(torch, config[\"dtype\"])\n",
    "        self.W_enc = nn.Parameter(\n",
    "            torch.nn.init.kaiming_uniform_(torch.empty(d_in, d_hidden, dtype=dtype))\n",
    "        )\n",
    "        self.W_dec = nn.Parameter(\n",
    "            torch.nn.init.kaiming_uniform_(torch.empty(d_hidden, d_in, dtype=dtype))\n",
    "        )\n",
    "        self.b_enc = nn.Parameter(torch.zeros(d_hidden, dtype=dtype))\n",
    "        self.b_dec = nn.Parameter(torch.zeros(d_in, dtype=dtype))\n",
    "\n",
    "        self.W_dec.data[:] = self.W_dec / self.W_dec.norm(dim=-1, keepdim=True)\n",
    "        self.d_hidden = d_hidden\n",
    "        \n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x_cent = x - self.b_dec\n",
    "        acts = F.relu(x_cent @ self.W_enc + self.b_enc)\n",
    "        x_reconstruct = acts @ self.W_dec + self.b_dec\n",
    "        return x_reconstruct, acts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_names = {\n",
    "    \"l1\": \"l1\",\n",
    "    \"sqrt\": \"l1_sqrt\",\n",
    "    \"pure_sqrt\": \"sqrt\",\n",
    "    \"combined_hoyer_l1\": \"l1_hoyer\",\n",
    "    \"combined_hoyer_sqrt\": \"l1_sqrt_hoyer\",\n",
    "    \"combined_hoyer_pure_sqrt\": \"sqrt_hoyer\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_encoder(run_name, model_name):\n",
    "    save_path = f\"/workspace/{model_name}\"\n",
    "\n",
    "    with open(f\"{save_path}/{run_name}.json\", \"r\") as f:\n",
    "        cfg = json.load(f)\n",
    "\n",
    "    d_in = cfg[\"d_in\"]\n",
    "    d_hidden = cfg[\"d_in\"] * cfg[\"expansion_factor\"]\n",
    "    hook_name = f\"blocks.{cfg['layer']}.{cfg['act']}\"\n",
    "\n",
    "    sae_config = {\"d_in\": d_in, \"d_hidden\": d_hidden, \"dtype\":\"float32\", \"seed\":cfg[\"seed\"], \"wandb_name\": cfg[\"wandb_name\"], \"hook_name\": hook_name, \"layer\": cfg[\"layer\"], \"model\": cfg[\"model\"], \"regularization\": cfg[\"reg\"], \"wandb_id\": cfg[\"wandb_name\"].split(\"-\")[-1]}\n",
    "    encoder = SparseAutoEncoder(sae_config)\n",
    "    encoder.load_state_dict(torch.load(f\"{save_path}/{run_name}.pt\"))\n",
    "    #encoder.to(device)\n",
    "    return encoder, sae_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_models = [\"228_earnest_voice\", \"229_comfy_haze\", \"230_divine_resonance\", \"236_dainty_bush\",\n",
    "             \"262_azure_violet\", \"263_crimson_sunset\", \"264_prime_capybara\", \"265_tough_lake\",\n",
    "             \"266_avid_firebrand\", \"267_flowing_elevator\", \"268_earnest_breeze\", \"269_pretty_violet\",\n",
    "            \"273_spring_moon\", \"278_clear_plant\", \"277_icy_cherry\",\n",
    "            \"289_giddy_firebrand\", \"290_neat_microwave\", \"291_lucky_voice\"]\n",
    "\n",
    "def upload_to_HF(encoder_name, model_name):\n",
    "    encoder, cfg = load_encoder(encoder_name, model_name)\n",
    "    name = f'SAE-{cfg[\"model\"]}-L{cfg[\"layer\"]}-{cfg[\"wandb_id\"]}'\n",
    "    #encoder.save_pretrained(name, config=sae_config)\n",
    "    encoder.push_to_hub(name, config=cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for encoder_name in l1_models:\n",
    "#     upload_to_HF(encoder_name, \"tiny-stories-2L-33M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3d460b74b2f4110a0dae4d345298776",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/537M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoder = SparseAutoEncoder.from_pretrained(\"lovish/SAE-tiny-stories-2L-33M-L1-291\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
