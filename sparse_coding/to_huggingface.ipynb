{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_lens import HookedTransformer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import json\n",
    "from huggingface_hub import PyTorchModelHubMixin\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model tiny-stories-2L-33M into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "model_name = \"tiny-stories-2L-33M\"\n",
    "model = HookedTransformer.from_pretrained(model_name, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseAutoEncoder(nn.Module, PyTorchModelHubMixin):\n",
    "    def __init__(\n",
    "        self, config=None\n",
    "    ):\n",
    "        super().__init__()\n",
    "        if config is None:\n",
    "            raise ValueError(\"Config not provided\")\n",
    "        torch.manual_seed(config[\"seed\"])\n",
    "        d_in = config[\"d_in\"]\n",
    "        d_hidden = config[\"d_hidden\"]\n",
    "        dtype = getattr(torch, config[\"dtype\"])\n",
    "        self.W_enc = nn.Parameter(\n",
    "            torch.nn.init.kaiming_uniform_(torch.empty(d_in, d_hidden, dtype=dtype))\n",
    "        )\n",
    "        self.W_dec = nn.Parameter(\n",
    "            torch.nn.init.kaiming_uniform_(torch.empty(d_hidden, d_in, dtype=dtype))\n",
    "        )\n",
    "        self.b_enc = nn.Parameter(torch.zeros(d_hidden, dtype=dtype))\n",
    "        self.b_dec = nn.Parameter(torch.zeros(d_in, dtype=dtype))\n",
    "\n",
    "        self.W_dec.data[:] = self.W_dec / self.W_dec.norm(dim=-1, keepdim=True)\n",
    "        self.d_hidden = d_hidden\n",
    "        \n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x_cent = x - self.b_dec\n",
    "        acts = F.relu(x_cent @ self.W_enc + self.b_enc)\n",
    "        x_reconstruct = acts @ self.W_dec + self.b_dec\n",
    "        return x_reconstruct, acts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_names = {\n",
    "    \"l1\": \"l1\",\n",
    "    \"sqrt\": \"l1_sqrt\",\n",
    "    \"pure_sqrt\": \"sqrt\",\n",
    "    \"combined_hoyer_l1\": \"l1_hoyer\",\n",
    "    \"combined_hoyer_sqrt\": \"l1_sqrt_hoyer\",\n",
    "    \"combined_hoyer_pure_sqrt\": \"sqrt_hoyer\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_encoder(run_name, model_name=None):\n",
    "    save_path = f\"/workspace\"\n",
    "    if model_name is not None:\n",
    "        save_path = f\"/workspace/{model_name}\"\n",
    "\n",
    "    with open(f\"{save_path}/{run_name}.json\", \"r\") as f:\n",
    "        cfg = json.load(f)\n",
    "\n",
    "    d_in = cfg[\"d_in\"]\n",
    "    d_hidden = cfg[\"d_in\"] * cfg[\"expansion_factor\"]\n",
    "    hook_name = f\"blocks.{cfg['layer']}.{cfg['act']}\"\n",
    "\n",
    "    sae_config = {\"d_in\": d_in, \"d_hidden\": d_hidden, \"dtype\":\"float32\", \"seed\":cfg[\"seed\"], \"wandb_name\": cfg[\"wandb_name\"], \"hook_name\": hook_name, \"layer\": cfg[\"layer\"], \"model\": cfg[\"model\"], \"regularization\": cfg[\"reg\"], \"wandb_id\": cfg[\"wandb_name\"].split(\"-\")[-1]}\n",
    "    encoder = SparseAutoEncoder(sae_config)\n",
    "    encoder.load_state_dict(torch.load(f\"{save_path}/{run_name}.pt\"))\n",
    "    #encoder.to(device)\n",
    "    return encoder, sae_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_models = [\"228_earnest_voice\", \"229_comfy_haze\", \"230_divine_resonance\", \"236_dainty_bush\",\n",
    "             \"262_azure_violet\", \"263_crimson_sunset\", \"264_prime_capybara\", \"265_tough_lake\",\n",
    "             \"266_avid_firebrand\", \"267_flowing_elevator\", \"268_earnest_breeze\", \"269_pretty_violet\",\n",
    "            \"273_spring_moon\", \"278_clear_plant\", \"277_icy_cherry\",\n",
    "            \"289_giddy_firebrand\", \"290_neat_microwave\", \"291_lucky_voice\"]\n",
    "\n",
    "def upload_to_HF(encoder_name, model_name):\n",
    "    encoder, cfg = load_encoder(encoder_name, model_name)\n",
    "    name = f'SAE-{cfg[\"model\"]}-L{cfg[\"layer\"]}-{cfg[\"wandb_id\"]}'\n",
    "    #encoder.save_pretrained(name, config=sae_config)\n",
    "    encoder.push_to_hub(name, config=cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['101_gallant_night', '110_proud_lake', '11_soft_microwave', '15_clean_paper', '16_rosy_resonance', '19_classic_snow', '22_smooth_frost', '23_decent_tree', '28_kind_violet', '5_peach_sea', '6_crisp_morning', '6_dark_hill']\n"
     ]
    }
   ],
   "source": [
    "# Read all filenames from the /workspace directory\n",
    "import os\n",
    "import re\n",
    "\n",
    "directory = \"/workspace\"\n",
    "files = os.listdir(directory)\n",
    "models = [file[:-3] for file in files if re.match(r\"^\\d+_.+\\.pt$\", file)]\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "pythia_models = ['101_gallant_night', '110_proud_lake', '11_soft_microwave', '15_clean_paper', '16_rosy_resonance', '19_classic_snow', '22_smooth_frost', '23_decent_tree', '28_kind_violet', '5_peach_sea', '6_crisp_morning', '6_dark_hill']\n",
    "\n",
    "print(len(pythia_models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder, cfg = load_encoder(\"101_gallant_night\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load 101_gallant_night\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee18c890b2db4a07a3b6f24194ffb730",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/134M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28023990bfe749289e0f2a647683b0a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/134M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7472a204d520432aa2924927bb8ec680",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/134M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9856dae12b1d40a3947deb7de7f5a1b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/134M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1db9f91d912476887077e82728b4ca3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/134M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc7bd0f3e1d44eadb96c6c266fac579f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/134M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cda1df2d5f764e97a49985c9eb3d3946",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/134M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee79256efcb04066924a3958ce2a2b97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/134M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39edd95a0f63446f806318f0952d9f88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/134M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "071a72a0f0f8419ba65b9c3a25f6e0e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/134M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ea348cf64ed41f0a2a029e4bbb1fcc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/134M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for model in pythia_models:\n",
    "    try:\n",
    "        encoder, cfg = load_encoder(model)\n",
    "        name = f'SAE-{cfg[\"model\"]}-L{cfg[\"layer\"]}-{cfg[\"wandb_id\"]}'\n",
    "        encoder.push_to_hub(name, config=cfg)\n",
    "    except:\n",
    "        print(f\"Failed to load {model}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3d460b74b2f4110a0dae4d345298776",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/537M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoder = SparseAutoEncoder.from_pretrained(\"lovish/SAE-tiny-stories-2L-33M-L1-291\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
