{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "import requests\n",
    "import logging\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from transformer_lens import HookedTransformer\n",
    "from tqdm.auto import tqdm\n",
    "import plotly.io as pio\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import wandb\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import torch.nn.init as init\n",
    "from pathlib import Path\n",
    "from jaxtyping import Int, Float\n",
    "from torch import Tensor\n",
    "import einops\n",
    "from collections import Counter\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from ipywidgets import interact, IntSlider\n",
    "from process_tiny_stories_data import load_tinystories_validation_prompts, load_tinystories_tokens\n",
    "\n",
    "pio.renderers.default = \"notebook_connected\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "torch.autograd.set_grad_enabled(False)\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "logging.basicConfig(format='(%(levelname)s) %(asctime)s: %(message)s', level=logging.INFO, datefmt='%I:%M:%S')\n",
    "sys.path.append('../')  # Add the parent directory to the system path\n",
    "\n",
    "import utils.haystack_utils as haystack_utils\n",
    "from sparse_coding.train_autoencoder import AutoEncoder\n",
    "from utils.autoencoder_utils import custom_forward, AutoEncoderConfig, evaluate_autoencoder_reconstruction, get_encoder_feature_frequencies\n",
    "import utils.haystack_utils as haystack_utils\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load interesting encoder, find token features, generate histogram of activations for that token. Park features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model tiny-stories-2L-33M into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "# Run overview\n",
    "model_name = \"tiny-stories-2L-33M\"\n",
    "layer_name = \"L0\"\n",
    "print_model_name = f\"{model_name}-{layer_name}\"\n",
    "\n",
    "model = HookedTransformer.from_pretrained(\n",
    "        model_name,\n",
    "        center_unembed=True,\n",
    "        center_writing_weights=True,\n",
    "        fold_ln=True,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "prompts = load_tinystories_validation_prompts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_encoder(save_name, model_name):\n",
    "    with open(f\"{model_name}/{save_name}.json\", \"r\") as f:\n",
    "        cfg = json.load(f)\n",
    "\n",
    "    cfg = AutoEncoderConfig(\n",
    "        cfg[\"layer\"], cfg[\"act\"], cfg[\"expansion_factor\"], cfg[\"l1_coeff\"]\n",
    "    )\n",
    "\n",
    "    if cfg.act_name == \"hook_mlp_out\":\n",
    "        d_in = model.cfg.d_model  # d_mlp\n",
    "    else:\n",
    "        d_in = model.cfg.d_mlp\n",
    "    d_hidden = d_in * cfg.expansion_factor\n",
    "\n",
    "    encoder = AutoEncoder(d_hidden, cfg.l1_coeff, d_in)\n",
    "    encoder.load_state_dict(torch.load(os.path.join(model_name, save_name + \".pt\")))\n",
    "    encoder.to(device)\n",
    "    return encoder, cfg\n",
    "\n",
    "save_names = [f.split(\".\")[0] for f in os.listdir(model_name) if f.endswith('.pt')]\n",
    "l0_encoder, l0_cfg = load_encoder('18_morning_sun', model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_acts(prompt: str, model: HookedTransformer, encoder: AutoEncoder, cfg: AutoEncoderConfig):\n",
    "    _, cache = model.run_with_cache(prompt, names_filter=cfg.encoder_hook_point)\n",
    "    acts = cache[cfg.encoder_hook_point].squeeze(0)\n",
    "    _, _, mid_acts, _, _ = encoder(acts)\n",
    "    return mid_acts\n",
    "\n",
    "\n",
    "def get_max_activations(prompts: list[str], model: HookedTransformer, encoder: AutoEncoder, cfg: AutoEncoderConfig):\n",
    "    activations = []\n",
    "    indices = []\n",
    "    for prompt in tqdm(prompts):\n",
    "        acts = get_acts(prompt, model, encoder, cfg)[0, :-1]\n",
    "        print(acts.shape)\n",
    "        value, index = acts.max(0)\n",
    "        print(value.shape)\n",
    "        break\n",
    "        activations.append(value)\n",
    "        indices.append(index)\n",
    "\n",
    "    max_activation_per_prompt = torch.stack(activations)  # n_prompt x d_enc\n",
    "    max_activation_token_index = torch.stack(indices)\n",
    "\n",
    "    total_activations = max_activation_per_prompt.sum(0)\n",
    "    print(f\"Active directions on validation data: {total_activations.nonzero().shape[0]} out of {total_activations.shape[0]}\")\n",
    "    return max_activation_per_prompt, max_activation_token_index\n",
    "\n",
    "def print_top_examples(prompts: list[str], activations: Float[Tensor, \"n_prompts d_enc\"], direction: int, cfg: AutoEncoderConfig, encoder: AutoEncoder, n=5):\n",
    "    top_idxs = activations[:, direction].argsort(descending=True)[:n].cpu().tolist()\n",
    "    for prompt_index in top_idxs:\n",
    "        prompt = prompts[prompt_index]\n",
    "        prompt_tokens = model.to_str_tokens(model.to_tokens(prompt))\n",
    "        acts = get_acts(prompt, model, encoder, cfg)\n",
    "        direction_act = acts[:, direction].cpu().tolist()\n",
    "        max_direction_act = max(direction_act)\n",
    "        if max_direction_act > 0:\n",
    "            haystack_utils.clean_print_strings_as_html(prompt_tokens, direction_act, max_value=max_direction_act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21990"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd58467b87d54b779398b20634b2f230",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21990 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "stack expects a non-empty TensorList",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/root/superposition/sparse_coding/check_monosemanticity.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B135.181.65.54/root/superposition/sparse_coding/check_monosemanticity.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m max_activations, max_activation_token_indices \u001b[39m=\u001b[39m get_max_activations(prompts, model, l0_encoder, l0_cfg)\n",
      "\u001b[1;32m/root/superposition/sparse_coding/check_monosemanticity.ipynb Cell 7\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B135.181.65.54/root/superposition/sparse_coding/check_monosemanticity.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m     activations\u001b[39m.\u001b[39mappend(value)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B135.181.65.54/root/superposition/sparse_coding/check_monosemanticity.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m     indices\u001b[39m.\u001b[39mappend(index)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B135.181.65.54/root/superposition/sparse_coding/check_monosemanticity.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m max_activation_per_prompt \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mstack(activations)  \u001b[39m# n_prompt x d_enc\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B135.181.65.54/root/superposition/sparse_coding/check_monosemanticity.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m max_activation_token_index \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack(indices)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B135.181.65.54/root/superposition/sparse_coding/check_monosemanticity.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m total_activations \u001b[39m=\u001b[39m max_activation_per_prompt\u001b[39m.\u001b[39msum(\u001b[39m0\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects a non-empty TensorList"
     ]
    }
   ],
   "source": [
    "max_activations, max_activation_token_indices = get_max_activations(prompts, model, l0_encoder, l0_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"One day, a little girl named Lily went for a walk in the park\"\n",
    "acts = get_acts(prompt, model, l0_encoder, l0_cfg)[-1] # d_enc\n",
    "print(f\"Active directions on last token: {acts.nonzero().shape[0]} out of {acts.shape[0]}\")\n",
    "active_directions = acts.nonzero().squeeze(1)\n",
    "highly_active_directions = torch.argwhere((acts > 0.5)).squeeze(1)\n",
    "for active_direction in highly_active_directions:\n",
    "    print(f\"Direction {active_direction}\")\n",
    "    print_top_examples(prompts, max_activations, active_direction, l0_cfg, l0_encoder, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = model.to_single_token(\" park\")\n",
    "token_prompts = []\n",
    "for prompt in prompts[:1000]:\n",
    "    tokens = model.to_tokens(prompt)\n",
    "    if token in tokens:\n",
    "        token_prompts.append(prompt)\n",
    "print(len(token_prompts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_direction_frequency(data: list[str], direction: int, cfg: AutoEncoderConfig, encoder: AutoEncoder):\n",
    "    activations = []\n",
    "    for prompt in tqdm(data):\n",
    "        tokens = model.to_tokens(prompt)\n",
    "        _, cache = model.run_with_cache(\n",
    "            tokens, names_filter=f\"blocks.{cfg.layer}.{cfg.act_name}\"\n",
    "            )\n",
    "        acts = cache[f\"blocks.{cfg.layer}.{cfg.act_name}\"].squeeze(0)\n",
    "        _, _, mid_acts, _, _ = encoder(acts)\n",
    "        activations.append(mid_acts[:, direction])\n",
    "    activations = torch.cat(activations)\n",
    "    print(activations.shape)\n",
    "\n",
    "    fig = px.histogram(activations.tolist(), \n",
    "                       title=f\"{print_model_name} L1={cfg.l1_coeff}: Activations for direction {direction}\", \n",
    "                       histnorm=\"probability\")\n",
    "    fig.update_layout(\n",
    "        xaxis_title=\"Activation\",\n",
    "        yaxis_title=\"Probability\",\n",
    "        width = 600,\n",
    "        showlegend=False\n",
    "    )\n",
    "    fig.update_yaxes(type='log')\n",
    "    fig.show()\n",
    "    \n",
    "for direction in active_directions[:10]:\n",
    "    plot_direction_frequency(prompts[:50], direction, l0_cfg, l0_encoder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
