{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from transformer_lens import HookedTransformer\n",
    "from tqdm.auto import tqdm\n",
    "import plotly.io as pio\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import wandb\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import torch.nn.init as init\n",
    "import pickle\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "pio.renderers.default = \"notebook_connected\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "#torch.autograd.set_grad_enabled(False)\n",
    "#torch.set_grad_enabled(False)\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')  # Add the parent directory to the system path\n",
    "import utils.haystack_utils as haystack_utils\n",
    "from sparse_coding.train_autoencoder import AutoEncoder\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle_pt(name: str, path: Path):\n",
    "    autoencoder = torch.load(os.path.join(path, name + '.pt'))\n",
    "    with open(os.path.join(path, name + '_2' + '.pkl'), 'wb') as f:\n",
    "        pickle.dump(autoencoder, f)\n",
    "\n",
    "pickle_pt(name='mlp.hook_post_l5', path=Path('pythia-70m'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/german_europarl.json: Loaded 2000 examples with 152 to 2000 characters each.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    }
   ],
   "source": [
    "german_data = haystack_utils.load_json_data(\"data/german_europarl.json\")\n",
    "\n",
    "model = HookedTransformer.from_pretrained(\"EleutherAI/pythia-70m\",\n",
    "    center_unembed=True,\n",
    "    center_writing_weights=True,\n",
    "    fold_ln=True,\n",
    "    device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f17e23221c9409e8ee5ea7bb878b04d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss increase after encoding: 0.8281\n"
     ]
    }
   ],
   "source": [
    "# Load 70m dict\n",
    "d_in = model.cfg.d_mlp\n",
    "expansion_factor = 4\n",
    "autoencoder_dim = d_in * expansion_factor\n",
    "l1_coeff = 0.01\n",
    "\n",
    "autoencoder_70m = AutoEncoder(autoencoder_dim, l1_coeff, d_in)\n",
    "autoencoder_70m_filename = \"pythia-70m/mlp.hook_post_l5_2.pkl\"\n",
    "with open(autoencoder_70m_filename, 'rb') as f:\n",
    "    autoencoder_70m_state_dict = pickle.load(f)\n",
    "autoencoder_70m.load_state_dict(autoencoder_70m_state_dict)\n",
    "autoencoder_70m.to(device)\n",
    "\n",
    "def evaluate_dict(autoencoder: AutoEncoder, encoded_hook_name: str, german_data: list):\n",
    "    with torch.no_grad():\n",
    "        def encode_activations_hook(value, hook):\n",
    "            value = value.squeeze(0)\n",
    "            _, x_reconstruct, _, _, _ = autoencoder(value)\n",
    "            return x_reconstruct.unsqueeze(0)\n",
    "\n",
    "        hooks = [(encoded_hook_name, encode_activations_hook)]\n",
    "\n",
    "        original_losses = []\n",
    "        reconstruct_losses = []\n",
    "        for prompt in tqdm(german_data[:200]):\n",
    "            original_loss = model(prompt, return_type=\"loss\")\n",
    "            with model.hooks(hooks):\n",
    "                reconstruct_loss = model(prompt, return_type=\"loss\")\n",
    "            original_losses.append(original_loss.item())\n",
    "            reconstruct_losses.append(reconstruct_loss.item())\n",
    "\n",
    "    print(f\"Average loss increase after encoding: {(np.mean(reconstruct_losses) - np.mean(original_losses)):.4f}\")\n",
    "\n",
    "evaluate_dict(autoencoder_70m, \"blocks.5.mlp.hook_post\", german_data=german_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_in = model.cfg.d_model\n",
    "expansion_factor = 4\n",
    "autoencoder_dim = d_in * expansion_factor\n",
    "l1_coeff = 0.01\n",
    "\n",
    "our_autoencoder = AutoEncoder(autoencoder_dim, l1_coeff, d_in)\n",
    "our_autoencoder_filename = \"pythia-160m/hook_mlp_out_l8.pt\"\n",
    "our_autoencoder.load_state_dict(torch.load(our_autoencoder_filename))\n",
    "our_autoencoder.to(device)\n",
    "\n",
    "with open(\"pythia-160m/hook_mlp_out_l8.pkl\", \"wb\") as f:\n",
    "    pickle.dump(our_autoencoder, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate our dict\n",
    "with torch.no_grad():\n",
    "    def encode_mlp_activations_hook(value, hook):\n",
    "        value = value.squeeze(0)\n",
    "        _, x_reconstruct, _, _, _ = our_autoencoder(value)\n",
    "        return x_reconstruct.unsqueeze(0)\n",
    "\n",
    "    hooks = [(\"blocks.8.hook_mlp_out\", encode_mlp_activations_hook)]\n",
    "\n",
    "    original_losses = []\n",
    "    reconstruct_losses = []\n",
    "    for prompt in tqdm(german_data[:200]):\n",
    "        original_loss = model(prompt, return_type=\"loss\")\n",
    "        with model.hooks(hooks):\n",
    "            reconstruct_loss = model(prompt, return_type=\"loss\")\n",
    "        original_losses.append(original_loss.item())\n",
    "        reconstruct_losses.append(reconstruct_loss.item())\n",
    "\n",
    "print(f\"Average loss increase after encoding: {(np.mean(reconstruct_losses) - np.mean(original_losses)):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Logan's one\n",
    "autoencoder2.to_device(device)\n",
    "model.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    def encode_mlp_activations_hook(value, hook):\n",
    "        value = value.squeeze(0)\n",
    "        acts = autoencoder2.encode(value)\n",
    "        out = autoencoder2.decode(acts)\n",
    "        return out.unsqueeze(0)\n",
    "\n",
    "    hooks = [(\"blocks.8.hook_mlp_out\", encode_mlp_activations_hook)]\n",
    "\n",
    "    original_losses = []\n",
    "    reconstruct_losses = []\n",
    "    for prompt in tqdm(german_data[:200]):\n",
    "        original_loss = model(prompt, return_type=\"loss\")\n",
    "        with model.hooks(hooks):\n",
    "            reconstruct_loss = model(prompt, return_type=\"loss\")\n",
    "        original_losses.append(original_loss.item())\n",
    "        reconstruct_losses.append(reconstruct_loss.item())\n",
    "\n",
    "print(f\"Average loss increase after encoding: {(np.mean(reconstruct_losses) - np.mean(original_losses)):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
