{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import einsum\n",
    "from tqdm.auto import tqdm\n",
    "import seaborn as sns\n",
    "from transformer_lens import HookedTransformer, ActivationCache, utils, patching\n",
    "from datasets import load_dataset\n",
    "from einops import einsum\n",
    "import pandas as pd\n",
    "from transformer_lens import utils\n",
    "from rich.table import Table, Column\n",
    "from rich import print as rprint\n",
    "from jaxtyping import Float, Int, Bool\n",
    "from typing import List, Tuple\n",
    "from torch import Tensor\n",
    "import einops\n",
    "import functools\n",
    "from transformer_lens.hook_points import HookPoint\n",
    "# import circuitsvis\n",
    "from IPython.display import HTML\n",
    "from plotly.express import line\n",
    "import plotly.express as px\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "import gc\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from plotly.subplots import make_subplots\n",
    "# Plotly needs a different renderer for VSCode/Notebooks vs Colab argh\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"notebook_connected\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.autograd.set_grad_enabled(False)\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "from haystack_utils import load_txt_data, get_mlp_activations, line\n",
    "import haystack_utils\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model EleutherAI/pythia-70m into HookedTransformer\n",
      "data/german_europarl.json: Loaded 2000 examples with 152 to 2000 characters each.\n",
      "data/english_europarl.json: Loaded 2000 examples with 165 to 2000 characters each.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b7b155c60ff4f61932380f8f39c8de5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0286c525517f4884a95bc8cd65d1774f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24a29d1072204d1aa33b83910ad181a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec2b47136640423694c9d11d133e1b27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64cee2125f4042939f21735795183b95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c40c71c471144a799f8c0a49f657b4eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = HookedTransformer.from_pretrained(\"EleutherAI/pythia-70m\",\n",
    "    center_unembed=True,\n",
    "    center_writing_weights=True,\n",
    "    fold_ln=True,\n",
    "    device=device)\n",
    "\n",
    "german_data = haystack_utils.load_json_data(\"data/german_europarl.json\")\n",
    "english_data = haystack_utils.load_json_data(\"data/english_europarl.json\")\n",
    "\n",
    "\n",
    "english_activations = {}\n",
    "german_activations = {}\n",
    "for layer in range(3, 6):\n",
    "    english_activations[layer] = get_mlp_activations(english_data[:200], layer, model, mean=False)\n",
    "    german_activations[layer] = get_mlp_activations(german_data[:200], layer, model, mean=False)\n",
    "\n",
    "\n",
    "LOG_PROB_THRESHOLD = -7\n",
    "LAYER_TO_ABLATE = 3\n",
    "NEURONS_TO_ABLATE = [669]\n",
    "MEAN_ACTIVATION_ACTIVE = german_activations[LAYER_TO_ABLATE][:, NEURONS_TO_ABLATE].mean()\n",
    "MEAN_ACTIVATION_INACTIVE = english_activations[LAYER_TO_ABLATE][:, NEURONS_TO_ABLATE].mean()\n",
    "\n",
    "def deactivate_neurons_hook(value, hook):\n",
    "    value[:, :, NEURONS_TO_ABLATE] = MEAN_ACTIVATION_INACTIVE\n",
    "    return value\n",
    "deactivate_neurons_fwd_hooks=[(f'blocks.{LAYER_TO_ABLATE}.mlp.hook_post', deactivate_neurons_hook)]\n",
    "\n",
    "def activate_neurons_hook(value, hook):\n",
    "    value[:, :, NEURONS_TO_ABLATE] = MEAN_ACTIVATION_ACTIVE\n",
    "    return value\n",
    "activate_neurons_fwd_hooks=[(f'blocks.{LAYER_TO_ABLATE}.mlp.hook_post', activate_neurons_hook)]\n",
    "\n",
    "all_ignore, not_ignore = haystack_utils.get_weird_tokens(model, plot_norms=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30f7fda8351e4661a3bf134d09a94ffc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "german_losses = []\n",
    "for prompt in tqdm(german_data):\n",
    "    original_loss, ablated_loss, context_and_activated_loss, only_activated_loss = haystack_utils.get_direct_effect(prompt, model, pos=None, context_ablation_hooks=deactivate_neurons_fwd_hooks, context_activation_hooks=activate_neurons_fwd_hooks)\n",
    "    german_losses.append((original_loss, ablated_loss, context_and_activated_loss, only_activated_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mlp5_decrease_measure(losses: list[tuple[Float[Tensor, \"pos\"], Float[Tensor, \"pos\"], Float[Tensor, \"pos\"], Float[Tensor, \"pos\"]]]):\n",
    "    measure = []\n",
    "    for original_loss, ablated_loss, context_and_activated_loss, only_activated_loss in losses:\n",
    "        pos_wise_diff = ablated_loss - only_activated_loss\n",
    "        measure.append(pos_wise_diff.max().item())\n",
    "    return measure\n",
    "\n",
    "measure = get_mlp5_decrease_measure(german_losses)\n",
    "index = [i for i in range(len(measure))]\n",
    "\n",
    "sorted_measure = list(zip(index, measure))\n",
    "sorted_measure.sort(key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_prompt(index: int, losses):\n",
    "    prompt = german_data[index]\n",
    "    str_token_prompt = model.to_str_tokens(model.to_tokens(prompt))\n",
    "    original_loss, ablated_loss, context_and_activated_loss, only_activated_loss = losses[index]\n",
    "\n",
    "    pos_wise_diff = (ablated_loss - only_activated_loss).flatten().cpu().tolist()\n",
    "    haystack_utils.clean_print_strings_as_html(str_token_prompt[1:], pos_wise_diff, max_value=5, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_token_loss(prompt: str, model: HookedTransformer, max_value = 5):\n",
    "    original_loss, ablated_loss, context_and_activated_loss, only_activated_loss = haystack_utils.get_direct_effect(prompt, model, pos=None, context_ablation_hooks=deactivate_neurons_fwd_hooks, context_activation_hooks=activate_neurons_fwd_hooks)\n",
    "    str_token_prompt = model.to_str_tokens(model.to_tokens(prompt))\n",
    "\n",
    "    # Look for high difference in ablated loss - \n",
    "    pos_wise_difference = (ablated_loss-only_activated_loss)\n",
    "    haystack_utils.print_strings_as_html(str_token_prompt[1:], pos_wise_difference.flatten().cpu().tolist(), max_value=max_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><span style=\"background-color: rgb(255, 250, 250); color: black; padding: 2px;\" title=\"0.0836\">Ab</span> <span style=\"background-color: rgb(255, 211, 211); color: black; padding: 2px;\" title=\"0.8600\">st</span> <span style=\"background-color: rgb(255, 228, 228); color: black; padding: 2px;\" title=\"0.5150\">immun</span> <span style=\"background-color: rgb(255, 220, 220); color: black; padding: 2px;\" title=\"0.6847\">gs</span> <span style=\"background-color: rgb(255, 215, 215); color: black; padding: 2px;\" title=\"0.7664\">st</span> <span style=\"background-color: rgb(255, 210, 210); color: black; padding: 2px;\" title=\"0.8780\">unde</span> <span style=\"background-color: rgb(248, 248, 255); color: black; padding: 2px;\" title=\"-0.1284\">_</span> <span style=\"background-color: rgb(255, 154, 154); color: black; padding: 2px;\" title=\"1.9667\">Die</span> <span style=\"background-color: rgb(255, 236, 236); color: black; padding: 2px;\" title=\"0.3645\">_Pr</span> <span style=\"background-color: rgb(252, 252, 255); color: black; padding: 2px;\" title=\"-0.0478\">äsident</span> <span style=\"background-color: rgb(216, 216, 255); color: black; padding: 2px;\" title=\"-0.7467\">in</span> <span style=\"background-color: rgb(255, 253, 253); color: black; padding: 2px;\" title=\"0.0234\">_</span> <span style=\"background-color: rgb(255, 200, 200); color: black; padding: 2px;\" title=\"1.0641\">Al</span> <span style=\"background-color: rgb(255, 129, 129); color: black; padding: 2px;\" title=\"2.4525\">s</span> <span style=\"background-color: rgb(207, 207, 255); color: black; padding: 2px;\" title=\"-0.9390\">_nä</span> <span style=\"background-color: rgb(255, 213, 213); color: black; padding: 2px;\" title=\"0.8108\">ch</span> <span style=\"background-color: rgb(255, 179, 179); color: black; padding: 2px;\" title=\"1.4792\">ster</span> <span style=\"background-color: rgb(255, 212, 212); color: black; padding: 2px;\" title=\"0.8392\">_P</span> <span style=\"background-color: rgb(255, 187, 187); color: black; padding: 2px;\" title=\"1.3171\">unk</span> <span style=\"background-color: rgb(255, 179, 179); color: black; padding: 2px;\" title=\"1.4723\">t</span> <span style=\"background-color: rgb(255, 234, 234); color: black; padding: 2px;\" title=\"0.3975\">_fol</span> <span style=\"background-color: rgb(201, 201, 255); color: black; padding: 2px;\" title=\"-1.0519\">gt</span> <span style=\"background-color: rgb(229, 229, 255); color: black; padding: 2px;\" title=\"-0.5068\">_die</span> <span style=\"background-color: rgb(253, 253, 255); color: black; padding: 2px;\" title=\"-0.0318\">_Ab</span> <span style=\"background-color: rgb(254, 254, 255); color: black; padding: 2px;\" title=\"-0.0013\">st</span> <span style=\"background-color: rgb(247, 247, 255); color: black; padding: 2px;\" title=\"-0.1556\">immun</span> <span style=\"background-color: rgb(255, 236, 236); color: black; padding: 2px;\" title=\"0.3538\">g</span> <span style=\"background-color: rgb(255, 198, 198); color: black; padding: 2px;\" title=\"1.1020\">.</span> <span style=\"background-color: rgb(255, 254, 254); color: black; padding: 2px;\" title=\"0.0173\">_</span> <span style=\"background-color: rgb(239, 239, 255); color: black; padding: 2px;\" title=\"-0.3032\">(</span> <span style=\"background-color: rgb(232, 232, 255); color: black; padding: 2px;\" title=\"-0.4441\">Ab</span> <span style=\"background-color: rgb(253, 253, 255); color: black; padding: 2px;\" title=\"-0.0203\">st</span> <span style=\"background-color: rgb(251, 251, 255); color: black; padding: 2px;\" title=\"-0.0679\">immun</span> <span style=\"background-color: rgb(255, 228, 228); color: black; padding: 2px;\" title=\"0.5196\">g</span> <span style=\"background-color: rgb(255, 208, 208); color: black; padding: 2px;\" title=\"0.9057\">ser</span> <span style=\"background-color: rgb(240, 240, 255); color: black; padding: 2px;\" title=\"-0.2778\">ge</span> <span style=\"background-color: rgb(205, 205, 255); color: black; padding: 2px;\" title=\"-0.9667\">bn</span> <span style=\"background-color: rgb(228, 228, 255); color: black; padding: 2px;\" title=\"-0.5191\">isse</span> <span style=\"background-color: rgb(225, 225, 255); color: black; padding: 2px;\" title=\"-0.5752\">_und</span> <span style=\"background-color: rgb(254, 254, 255); color: black; padding: 2px;\" title=\"-0.0101\">_son</span> <span style=\"background-color: rgb(250, 250, 255); color: black; padding: 2px;\" title=\"-0.0871\">st</span> <span style=\"background-color: rgb(244, 244, 255); color: black; padding: 2px;\" title=\"-0.2121\">ige</span> <span style=\"background-color: rgb(199, 199, 255); color: black; padding: 2px;\" title=\"-1.0958\">_Ein</span> <span style=\"background-color: rgb(255, 250, 250); color: black; padding: 2px;\" title=\"0.0825\">zel</span> <span style=\"background-color: rgb(180, 180, 255); color: black; padding: 2px;\" title=\"-1.4559\">heit</span> <span style=\"background-color: rgb(251, 251, 255); color: black; padding: 2px;\" title=\"-0.0623\">en</span> <span style=\"background-color: rgb(217, 217, 255); color: black; padding: 2px;\" title=\"-0.7362\">_der</span> <span style=\"background-color: rgb(244, 244, 255); color: black; padding: 2px;\" title=\"-0.2025\">_Ab</span> <span style=\"background-color: rgb(254, 254, 255); color: black; padding: 2px;\" title=\"-0.0069\">st</span> <span style=\"background-color: rgb(249, 249, 255); color: black; padding: 2px;\" title=\"-0.1024\">immun</span> <span style=\"background-color: rgb(255, 250, 250); color: black; padding: 2px;\" title=\"0.0863\">g</span> <span style=\"background-color: rgb(255, 250, 250); color: black; padding: 2px;\" title=\"0.0795\">:</span> <span style=\"background-color: rgb(255, 232, 232); color: black; padding: 2px;\" title=\"0.4374\">_sie</span> <span style=\"background-color: rgb(255, 238, 238); color: black; padding: 2px;\" title=\"0.3309\">he</span> <span style=\"background-color: rgb(255, 248, 248); color: black; padding: 2px;\" title=\"0.1348\">_Pro</span> <span style=\"background-color: rgb(255, 250, 250); color: black; padding: 2px;\" title=\"0.0785\">tok</span> <span style=\"background-color: rgb(250, 250, 255); color: black; padding: 2px;\" title=\"-0.0934\">oll</span> <span style=\"background-color: rgb(255, 241, 241); color: black; padding: 2px;\" title=\"0.2661\">)</span> <span style=\"background-color: rgb(254, 254, 255); color: black; padding: 2px;\" title=\"-0.0068\">_</span> </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_token_loss(german_data[0], model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Ich möchte nochmals meine Ansicht\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.7153401374816895, 12.92672348022461, 9.561723709106445, 8.331337928771973)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_loss, ablated_loss, context_and_activated_loss, only_activated_loss = haystack_utils.get_direct_effect(prompt, model, pos=-1, context_ablation_hooks=deactivate_neurons_fwd_hooks, context_activation_hooks=activate_neurons_fwd_hooks)\n",
    "original_loss, ablated_loss, context_and_activated_loss, only_activated_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.7153401374816895,\n",
       " 12.92672348022461,\n",
       " 7.974599838256836,\n",
       " 3.314662218093872,\n",
       " 6.4687347412109375,\n",
       " 8.842937469482422)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_losses, total_effect_losses, direct_mlp3_mlp5_losses, direct_mlp3_losses, frozen_losses, frozen_loss_without_MLP4 = haystack_utils.pos_wise_mlp_effect_on_single_prompt(prompt, model, k=2048, ablation_hooks=deactivate_neurons_fwd_hooks, log=False, answer_pos=-1, return_mlp4_less_mlp5=True)\n",
    "original_losses, total_effect_losses, direct_mlp3_mlp5_losses, direct_mlp3_losses, frozen_losses, frozen_loss_without_MLP4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
