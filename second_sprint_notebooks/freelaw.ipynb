{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from transformer_lens import HookedTransformer, ActivationCache, utils, patching\n",
    "from jaxtyping import Float, Int, Bool\n",
    "from torch import Tensor\n",
    "from tqdm.auto import tqdm\n",
    "import plotly.io as pio\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from datasets import load_dataset\n",
    "\n",
    "pio.renderers.default = \"notebook_connected\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.autograd.set_grad_enabled(False)\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "from haystack_utils import get_mlp_activations\n",
    "import haystack_utils\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/home/ubuntu/.cache/huggingface/datasets/NeelNanda___parquet/NeelNanda--pile-10k-72f566e9f7c464ab/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "dataset = load_dataset(\"NeelNanda/pile-10k\", split='train')\n",
    "\n",
    "freelaw_data = []\n",
    "non_freelaw_data = []\n",
    "for i, item in enumerate(dataset):\n",
    "    text = item['text']\n",
    "    if len(text) < 100:\n",
    "        continue\n",
    "    if len(freelaw_data) == 500 and len(non_freelaw_data) == 500:\n",
    "        break\n",
    "    \n",
    "    if item['meta']['pile_set_name'] == 'FreeLaw':\n",
    "        freelaw_data.append(text)\n",
    "    elif len(non_freelaw_data) < 500:\n",
    "        non_freelaw_data.append(text)\n",
    "\n",
    "with open('data/freelaw.json', 'w') as f:\n",
    "    json.dump(f, freelaw_data)\n",
    "with open('data/non_freelaw.json', 'w') as f:\n",
    "    json.dump(f, non_freelaw_data)\n",
    "\n",
    "print(len(freelaw_data))\n",
    "print(len(non_freelaw_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model EleutherAI/pythia-70m into HookedTransformer\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30c2a5e9fbbc41d0a7957ab7a763a6c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f886f099d7a84a3d9d50b87761aebfcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = HookedTransformer.from_pretrained(\"EleutherAI/pythia-70m\",\n",
    "    center_unembed=True,\n",
    "    center_writing_weights=True,\n",
    "    fold_ln=True,\n",
    "    device=device)\n",
    "\n",
    "uspto_neurons_l4 = [663]\n",
    "freelaw_neurons_l4 = [189, 896, 227]\n",
    "\n",
    "freelaw_activations = {}\n",
    "non_freelaw_activations = {}\n",
    "for layer in range(4, 5):\n",
    "    freelaw_activations[layer] = get_mlp_activations(freelaw_data[:200], layer, model, mean=False)\n",
    "    non_freelaw_activations[layer] = get_mlp_activations(non_freelaw_data[:200], layer, model, mean=False)\n",
    "\n",
    "LAYER_TO_ABLATE = 4\n",
    "NEURONS_TO_ABLATE = uspto_neurons_l4\n",
    "MEAN_ACTIVATION_ACTIVE = freelaw_activations[LAYER_TO_ABLATE][:, NEURONS_TO_ABLATE].mean(0)\n",
    "MEAN_ACTIVATION_INACTIVE = non_freelaw_activations[LAYER_TO_ABLATE][:, NEURONS_TO_ABLATE].mean(0)\n",
    "\n",
    "def deactivate_neurons_hook(value, hook):\n",
    "    value[:, :, NEURONS_TO_ABLATE] = MEAN_ACTIVATION_INACTIVE\n",
    "    return value\n",
    "deactivate_neurons_fwd_hooks=[(f'blocks.{LAYER_TO_ABLATE}.mlp.hook_post', deactivate_neurons_hook)]\n",
    "\n",
    "def activate_neurons_hook(value, hook):\n",
    "    value[:, :, NEURONS_TO_ABLATE] = MEAN_ACTIVATION_ACTIVE\n",
    "    return value\n",
    "activate_neurons_fwd_hooks=[(f'blocks.{LAYER_TO_ABLATE}.mlp.hook_post', activate_neurons_hook)]\n",
    "\n",
    "all_ignore, not_ignore = haystack_utils.get_weird_tokens(model, plot_norms=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.012581122159958\n",
      "3.0354947290420533\n"
     ]
    }
   ],
   "source": [
    "original_losses, ablated_losses = [], []\n",
    "for prompt in freelaw_data:\n",
    "    original_loss, ablated_loss, _, _ = haystack_utils.get_caches_single_prompt(prompt, model, deactivate_neurons_fwd_hooks)\n",
    "    original_losses.append(original_loss)\n",
    "    ablated_losses.append(ablated_loss)\n",
    "\n",
    "print(sum(original_losses) / len(original_losses))\n",
    "print(sum(ablated_losses) / len(ablated_losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.154054642379284\n",
      "3.170984795808792\n"
     ]
    }
   ],
   "source": [
    "original_losses, ablated_losses = [], []\n",
    "for prompt in non_freelaw_data:\n",
    "    original_loss, ablated_loss, _, _ = haystack_utils.get_caches_single_prompt(prompt, model, activate_neurons_fwd_hooks)\n",
    "    original_losses.append(original_loss)\n",
    "    ablated_losses.append(ablated_loss)\n",
    "\n",
    "print(sum(original_losses) / len(original_losses))\n",
    "print(sum(ablated_losses) / len(ablated_losses))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
