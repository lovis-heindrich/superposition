{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model EleutherAI/pythia-160m into HookedTransformer\n",
      "data/german_europarl.json: Loaded 2000 examples with 152 to 2000 characters each.\n",
      "data/english_europarl.json: Loaded 2000 examples with 165 to 2000 characters each.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from transformer_lens import HookedTransformer\n",
    "from tqdm.auto import tqdm\n",
    "import plotly.io as pio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px \n",
    "import pickle\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import haystack_utils\n",
    "import hook_utils\n",
    "import plotting_utils\n",
    "import probing_utils\n",
    "from probing_utils import get_and_score_new_word_probe\n",
    "from sklearn import preprocessing\n",
    "\n",
    "pio.renderers.default = \"notebook_connected+notebook\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.autograd.set_grad_enabled(False)\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "model = HookedTransformer.from_pretrained(\"EleutherAI/pythia-160m\",\n",
    "    center_unembed=True,\n",
    "    center_writing_weights=True,\n",
    "    fold_ln=True,\n",
    "    device=device)\n",
    "\n",
    "german_data = haystack_utils.load_json_data(\"data/german_europarl.json\")[:200]\n",
    "english_data = haystack_utils.load_json_data(\"data/english_europarl.json\")[:200]\n",
    "\n",
    "LAYER, NEURON = 8, 2994"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            f1       mcc\n",
      "1426  0.859275  0.742336\n",
      "149   0.795104  0.641232\n",
      "2994  0.817568  0.637815\n",
      "1815  0.803144  0.625381\n",
      "1080  0.821160  0.624540\n",
      "626   0.760399  0.622951\n",
      "2288  0.789410  0.621133\n",
      "2636  0.811525  0.614484\n",
      "1404  0.816850  0.613347\n",
      "2830  0.775984  0.608591\n",
      "            f1       mcc  neuron_1  neuron_2\n",
      "1506  0.896530  0.800370      1426      1507\n",
      "2074  0.889679  0.787044      1426      2075\n",
      "11    0.889597  0.785888      1426        11\n",
      "2443  0.889129  0.785524      1426      2444\n",
      "2029  0.887817  0.785415      1426      2030\n",
      "1154  0.887900  0.784629      1426      1154\n",
      "2741  0.886871  0.783621      1426      2742\n",
      "1921  0.887128  0.781480      1426      1922\n",
      "45    0.886047  0.781297      1426        45\n",
      "667   0.881716  0.779885      1426       667\n"
     ]
    }
   ],
   "source": [
    "with open(f'data/pythia_160m/layer_8/single_neurons_df.pkl', 'rb') as f:\n",
    "    one_sparse_probe_scores_df = pickle.load(f)\n",
    "\n",
    "top_one_scores = one_sparse_probe_scores_df.sort_values(by='mcc', ascending=False).head(10)\n",
    "print(top_one_scores)\n",
    "\n",
    "with open(f'data/pythia_160m/layer_8/probes_two_sparse_df_10_mcc.pkl', 'rb') as f:\n",
    "    two_sparse_probe_scores_df = pickle.load(f)\n",
    "\n",
    "top_two_scores = two_sparse_probe_scores_df.sort_values(by='mcc', ascending=False).head(10)\n",
    "print(top_two_scores)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
