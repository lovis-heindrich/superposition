{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformer_lens import HookedTransformer, ActivationCache\n",
    "from typing import List\n",
    "from tqdm.auto import tqdm\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Plotly needs a different renderer for VSCode/Notebooks vs Colab argh\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"notebook_connected\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.autograd.set_grad_enabled(False)\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "import circuitsvis as cv\n",
    "import haystack_utils\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model EleutherAI/pythia-70m into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "model = HookedTransformer.from_pretrained(\"EleutherAI/pythia-70m\", fold_ln=True, device=device)\n",
    "model.set_use_attn_result(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 tensor([ 0.0326,  0.0236, -0.0164,  0.0012,  0.0001, -0.0072, -0.0073, -0.0014],\n",
      "       device='cuda:0')\n",
      "4 tensor([-0.0277,  0.0260, -0.0124,  0.0549, -0.0376, -0.0457, -0.0861,  0.0018],\n",
      "       device='cuda:0')\n",
      "5 tensor([-0.0312,  0.0192,  0.0550, -0.1864,  0.0231,  0.0341,  0.0783, -0.0077],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Q weights say, what does each token want. If it attends to the German direction it probably wants German tokens (or wants to filter out German tokens)\n",
    "# K weights say, what does each token have. If it attends to the German direction it is supplying German-ness\n",
    "# I want to see how much each head queries for and highlights German tokens\n",
    "\n",
    "from einops import einsum\n",
    "\n",
    "def get_intermediate_tensor(residual, weights, biases):\n",
    "        intermediate_tensor = einsum(residual, weights,\n",
    "                                     \"d_model, n_heads d_model d_head -> n_heads d_head\")\n",
    "        return intermediate_tensor # + biases\n",
    "\n",
    "for layer in range(3, 6):\n",
    "        W_Q = model.state_dict()[f'blocks.{layer}.attn.W_Q']  # [8, 512, 64]\n",
    "        b_Q = model.state_dict()[f'blocks.{layer}.attn.b_K']\n",
    "        W_K = model.state_dict()[f'blocks.{layer}.attn.W_K']\n",
    "        b_K = model.state_dict()[f'blocks.{layer}.attn.b_K']\n",
    "\n",
    "        neuron_weight = model.W_out[3, 669]\n",
    "\n",
    "        # A large norm implies that the German neuron is important to the head\n",
    "        query = get_intermediate_tensor(neuron_weight, W_Q, b_Q) # n_heads d_head\n",
    "        key = get_intermediate_tensor(neuron_weight, W_K, b_K)\n",
    "        attention_pattern = einsum(query, key,\n",
    "                                \"n_heads d_head, n_heads d_head -> n_heads\")\n",
    "\n",
    "        # How much information each head wants to copy from a German token to another German token\n",
    "        print(layer, attention_pattern)\n",
    "\n",
    "# The only large-ish value is in the 3rd head of the 5th layer."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L5H3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SizeLimitedObject:\n",
    "    def __init__(self, obj, max_width='700px', max_height='700px'):\n",
    "        self.obj = obj\n",
    "        self.max_width = max_width\n",
    "        self.max_height = max_height\n",
    "\n",
    "    def _repr_html_(self):\n",
    "        return f\"\"\"\n",
    "        <div style='max-width: {self.max_width}; max-height: {self.max_height}; padding: 20px;'>\n",
    "            {self.obj._repr_html_()}\n",
    "        </div>\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"During my morning jog, or \\\"morgendlichen Lauf,\\\" I enjoy\"\n",
    "layer = 5\n",
    "head = 3\n",
    "tokens = model.to_tokens(prompt)\n",
    "str_tokens = model.to_str_tokens(tokens)\n",
    "\n",
    "def disable_german_hook(value, hook):\n",
    "    value[:, :, 669] = -0.1\n",
    "    return value\n",
    "fwd_hooks=[(f'blocks.{3}.mlp.hook_post', disable_german_hook)]\n",
    "\n",
    "original_loss, ablated_loss, original_cache, ablated_cache = haystack_utils.get_caches_single_prompt(prompt, model, fwd_hooks)\n",
    "\n",
    "block_name = f'blocks.{layer}.attn.hook_pattern'\n",
    "original_activations = original_cache[block_name]\n",
    "ablated_activations = ablated_cache[block_name]\n",
    "\n",
    "difference = original_activations - ablated_activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 5 Head 3 Attention Pattern:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style='max-width: 700px; max-height: 700px; padding: 20px;'>\n",
       "            <div id=\"circuits-vis-4542e95d-8a80\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, AttentionPattern } from \"https://unpkg.com/circuitsvis@1.40.0/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-4542e95d-8a80\",\n",
       "      AttentionPattern,\n",
       "      {\"tokens\": [\"<|endoftext|>\", \"During\", \" my\", \" morning\", \" jog\", \",\", \" or\", \" \\\"\", \"m\", \"org\", \"end\", \"lichen\", \" Lau\", \"f\", \",\\\"\", \" I\", \" enjoy\"], \"attention\": [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.06666667014360428, 0.06666667014360428, 0.06666667014360428, 0.06666667014360428, 0.06666667014360428, 0.06666667014360428, 0.06666667014360428, 0.06666667014360428, 0.06666667014360428, 0.06666667014360428, 0.06666667014360428, 0.06666667014360428, 0.06666667014360428, 0.06666667014360428, 0.06666667014360428], [1.0, 8.72747374369709e-10, 4.691164434689199e-08, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.07692307978868484, 0.07692307978868484, 0.07692307978868484, 0.07692307978868484, 0.07692307978868484, 0.07692307978868484, 0.07692307978868484, 0.07692307978868484, 0.07692307978868484, 0.07692307978868484, 0.07692307978868484, 0.07692307978868484, 0.07692307978868484], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0833333358168602, 0.0833333358168602, 0.0833333358168602, 0.0833333358168602, 0.0833333358168602, 0.0833333358168602, 0.0833333358168602, 0.0833333358168602, 0.0833333358168602, 0.0833333358168602, 0.0833333358168602, 0.0833333358168602], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09090909361839294, 0.09090909361839294, 0.09090909361839294, 0.09090909361839294, 0.09090909361839294, 0.09090909361839294, 0.09090909361839294, 0.09090909361839294, 0.09090909361839294, 0.09090909361839294, 0.09090909361839294], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612], [0.8760460019111633, 1.9308202886626094e-18, 6.953151188945192e-18, 1.05452011877939e-27, 1.0095527411177736e-18, 2.6726203715410346e-12, 0.027941307052969933, 0.09601275622844696, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 8.15709290233341e-31, 3.779739830888246e-29, 1.7935036876092971e-38, 1.8086499316918606e-34, 9.182226078624777e-23, 7.108195976268661e-11, 2.682605249049175e-10, 1.266416662428502e-14, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [6.83707663769219e-36, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.606683593389683e-16, 0.0, 2.802596928649634e-44, 1.9573336949689045e-41, 1.9085775081813013e-27, 1.2725418557703553e-34, 9.74224092184664e-32, 1.8343653996771092e-31, 1.5690157701414155e-31, 1.7330515902358457e-06, 0.9999982118606567, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [4.462939519084708e-15, 5.89946653480748e-42, 2.155587697722647e-36, 5.184804318001823e-44, 1.216462452644293e-35, 1.3635940604227895e-29, 1.0078682599585997e-26, 2.3063446825687067e-28, 6.609840778312303e-40, 5.8366505173368036e-36, 1.174074011192076e-24, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [4.42022178408219e-14, 0.0, 0.0, 0.0, 0.0, 7.2727390298458e-43, 1.2423217140665523e-38, 2.867718110344302e-34, 1.78275712968639e-39, 4.780945055908939e-38, 6.68566839412099e-29, 1.5057016753416974e-06, 0.9999984502792358, 0.0, 0.0, 0.0, 0.0], [6.279036942084468e-14, 0.0, 2.2644983183489044e-42, 0.0, 2.466285297211678e-43, 6.944124878939182e-33, 1.2056125777381747e-26, 6.294209933370817e-24, 2.138940981826155e-32, 6.588401921281126e-32, 3.369047432495267e-24, 0.023689471185207367, 0.9763104915618896, 1.0380367676532387e-08, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.5], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 4.5880834337970293e-26, 1.2702348660664816e-20, 1.0255963330546904e-40, 5.448484162360272e-26, 1.0587626608771217e-10, 2.2766974416832397e-10, 5.323793142442135e-11, 1.3432720962155907e-38, 0.0, 0.0, 1.7614416845150906e-28, 1.3955140970038318e-31, 5.357610754992723e-34, 1.7408985579205278e-15, 4.515547464889252e-15, 1.953234153566775e-16]]}\n",
       "    )\n",
       "    </script>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<__main__.SizeLimitedObject at 0x7ff43ffa1750>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Layer {layer} Head {head} Attention Pattern:\")\n",
    "head_attention = cv.attention.attention_pattern(tokens=str_tokens, attention=original_activations[0, 3, :, :])\n",
    "sized_viz = SizeLimitedObject(head_attention)\n",
    "sized_viz"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
