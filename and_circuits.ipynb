{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from transformer_lens import HookedTransformer, ActivationCache, utils, patching\n",
    "from jaxtyping import Float, Int, Bool\n",
    "from torch import Tensor\n",
    "from tqdm.auto import tqdm\n",
    "import plotly.io as pio\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import plotting_utils\n",
    "import hook_utils\n",
    "\n",
    "pio.renderers.default = \"notebook_connected\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.autograd.set_grad_enabled(False)\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "from haystack_utils import get_mlp_activations\n",
    "import haystack_utils\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model EleutherAI/pythia-70m into HookedTransformer\n",
      "data/german_europarl.json: Loaded 2000 examples with 152 to 2000 characters each.\n",
      "data/english_europarl.json: Loaded 2000 examples with 165 to 2000 characters each.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "292c50aed4844230ba69fbbbcdf049ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m ngram \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39morschlÃ¤gen\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m model \u001b[39m=\u001b[39m HookedTransformer\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m\"\u001b[39m\u001b[39mEleutherAI/pythia-70m\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     center_unembed\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m      4\u001b[0m     center_writing_weights\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m      5\u001b[0m     fold_ln\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m      6\u001b[0m     device\u001b[39m=\u001b[39mdevice)\n\u001b[0;32m----> 8\u001b[0m activate_neurons_fwd_hooks, deactivate_neurons_fwd_hooks \u001b[39m=\u001b[39m haystack_utils\u001b[39m.\u001b[39;49mget_context_ablation_hooks(\u001b[39m3\u001b[39;49m, [\u001b[39m669\u001b[39;49m], model)\n\u001b[1;32m      9\u001b[0m all_ignore, _ \u001b[39m=\u001b[39m haystack_utils\u001b[39m.\u001b[39mget_weird_tokens(model, plot_norms\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     11\u001b[0m german_data \u001b[39m=\u001b[39m haystack_utils\u001b[39m.\u001b[39mload_json_data(\u001b[39m\"\u001b[39m\u001b[39mdata/german_europarl.json\u001b[39m\u001b[39m\"\u001b[39m)[:\u001b[39m200\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/haystack_utils.py:1379\u001b[0m, in \u001b[0;36mget_context_ablation_hooks\u001b[0;34m(layer_to_ablate, neurons_to_ablate, model)\u001b[0m\n\u001b[1;32m   1376\u001b[0m english_activations \u001b[39m=\u001b[39m {}\n\u001b[1;32m   1377\u001b[0m german_activations \u001b[39m=\u001b[39m {}\n\u001b[0;32m-> 1379\u001b[0m english_activations[layer_to_ablate] \u001b[39m=\u001b[39m get_mlp_activations(english_data, layer_to_ablate, model, mean\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m   1380\u001b[0m german_activations[layer_to_ablate] \u001b[39m=\u001b[39m get_mlp_activations(german_data, layer_to_ablate, model, mean\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m   1382\u001b[0m MEAN_ACTIVATION_ACTIVE \u001b[39m=\u001b[39m german_activations[layer_to_ablate][:, neurons_to_ablate]\u001b[39m.\u001b[39mmean()\n",
      "File \u001b[0;32m~/Documents/haystack_utils.py:73\u001b[0m, in \u001b[0;36mget_mlp_activations\u001b[0;34m(prompts, layer, model, num_prompts, context_crop_start, context_crop_end, mean, hook_pre, pos)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(num_prompts)):\n\u001b[1;32m     72\u001b[0m     tokens \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mto_tokens(prompts[i])\n\u001b[0;32m---> 73\u001b[0m     _, cache \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mrun_with_cache(tokens)\n\u001b[1;32m     74\u001b[0m     act \u001b[39m=\u001b[39m cache[act_label][:, context_crop_start:context_crop_end, :]\n\u001b[1;32m     75\u001b[0m     \u001b[39mif\u001b[39;00m pos \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformer_lens/HookedTransformer.py:440\u001b[0m, in \u001b[0;36mHookedTransformer.run_with_cache\u001b[0;34m(self, return_cache_object, remove_batch_dim, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_with_cache\u001b[39m(\n\u001b[1;32m    425\u001b[0m     \u001b[39mself\u001b[39m, \u001b[39m*\u001b[39mmodel_args, return_cache_object\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, remove_batch_dim\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    426\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    433\u001b[0m     Union[ActivationCache, Dict[\u001b[39mstr\u001b[39m, torch\u001b[39m.\u001b[39mTensor]],\n\u001b[1;32m    434\u001b[0m ]:\n\u001b[1;32m    435\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    436\u001b[0m \u001b[39m    Wrapper around run_with_cache in HookedRootModule. If return_cache_object is True, this will return an\u001b[39;00m\n\u001b[1;32m    437\u001b[0m \u001b[39m    ActivationCache object, with a bunch of useful HookedTransformer specific methods, otherwise it will return a\u001b[39;00m\n\u001b[1;32m    438\u001b[0m \u001b[39m    dictionary of activations as in HookedRootModule.\u001b[39;00m\n\u001b[1;32m    439\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 440\u001b[0m     out, cache_dict \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mrun_with_cache(\n\u001b[1;32m    441\u001b[0m         \u001b[39m*\u001b[39;49mmodel_args, remove_batch_dim\u001b[39m=\u001b[39;49mremove_batch_dim, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    442\u001b[0m     )\n\u001b[1;32m    443\u001b[0m     \u001b[39mif\u001b[39;00m return_cache_object:\n\u001b[1;32m    444\u001b[0m         cache \u001b[39m=\u001b[39m ActivationCache(\n\u001b[1;32m    445\u001b[0m             cache_dict, \u001b[39mself\u001b[39m, has_batch_dim\u001b[39m=\u001b[39m\u001b[39mnot\u001b[39;00m remove_batch_dim\n\u001b[1;32m    446\u001b[0m         )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformer_lens/hook_points.py:459\u001b[0m, in \u001b[0;36mHookedRootModule.run_with_cache\u001b[0;34m(self, names_filter, device, remove_batch_dim, incl_bwd, reset_hooks_end, clear_contexts, *model_args, **model_kwargs)\u001b[0m\n\u001b[1;32m    449\u001b[0m cache_dict, fwd, bwd \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_caching_hooks(\n\u001b[1;32m    450\u001b[0m     names_filter, incl_bwd, device, remove_batch_dim\u001b[39m=\u001b[39mremove_batch_dim\n\u001b[1;32m    451\u001b[0m )\n\u001b[1;32m    453\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhooks(\n\u001b[1;32m    454\u001b[0m     fwd_hooks\u001b[39m=\u001b[39mfwd,\n\u001b[1;32m    455\u001b[0m     bwd_hooks\u001b[39m=\u001b[39mbwd,\n\u001b[1;32m    456\u001b[0m     reset_hooks_end\u001b[39m=\u001b[39mreset_hooks_end,\n\u001b[1;32m    457\u001b[0m     clear_contexts\u001b[39m=\u001b[39mclear_contexts,\n\u001b[1;32m    458\u001b[0m ):\n\u001b[0;32m--> 459\u001b[0m     model_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(\u001b[39m*\u001b[39;49mmodel_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_kwargs)\n\u001b[1;32m    460\u001b[0m     \u001b[39mif\u001b[39;00m incl_bwd:\n\u001b[1;32m    461\u001b[0m         model_out\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformer_lens/HookedTransformer.py:369\u001b[0m, in \u001b[0;36mHookedTransformer.forward\u001b[0;34m(self, input, return_type, loss_per_token, prepend_bos, stop_at_layer, past_kv_cache)\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[39mif\u001b[39;00m shortformer_pos_embed \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    365\u001b[0m         shortformer_pos_embed \u001b[39m=\u001b[39m shortformer_pos_embed\u001b[39m.\u001b[39mto(\n\u001b[1;32m    366\u001b[0m             devices\u001b[39m.\u001b[39mget_device_for_block_index(i, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcfg)\n\u001b[1;32m    367\u001b[0m         )\n\u001b[0;32m--> 369\u001b[0m     residual \u001b[39m=\u001b[39m block(\n\u001b[1;32m    370\u001b[0m         residual,\n\u001b[1;32m    371\u001b[0m         past_kv_cache_entry\u001b[39m=\u001b[39;49mpast_kv_cache[i]\n\u001b[1;32m    372\u001b[0m         \u001b[39mif\u001b[39;49;00m past_kv_cache \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m\n\u001b[1;32m    373\u001b[0m         \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,  \u001b[39m# Cache contains a list of HookedTransformerKeyValueCache objects, one for each block\u001b[39;49;00m\n\u001b[1;32m    374\u001b[0m         shortformer_pos_embed\u001b[39m=\u001b[39;49mshortformer_pos_embed,\n\u001b[1;32m    375\u001b[0m     )  \u001b[39m# [batch, pos, d_model]\u001b[39;00m\n\u001b[1;32m    377\u001b[0m \u001b[39mif\u001b[39;00m stop_at_layer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    378\u001b[0m     \u001b[39m# When we stop at an early layer, we end here rather than doing further computation\u001b[39;00m\n\u001b[1;32m    379\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformer_lens/components.py:973\u001b[0m, in \u001b[0;36mTransformerBlock.forward\u001b[0;34m(self, resid_pre, shortformer_pos_embed, past_kv_cache_entry)\u001b[0m\n\u001b[1;32m    966\u001b[0m     \u001b[39mif\u001b[39;00m shortformer_pos_embed \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    967\u001b[0m         shortformer_pos_embed \u001b[39m=\u001b[39m add_head_dimension(shortformer_pos_embed)\n\u001b[1;32m    969\u001b[0m attn_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhook_attn_out(\n\u001b[1;32m    970\u001b[0m     \u001b[39m# hook the residual stream states that are used to calculate the\u001b[39;00m\n\u001b[1;32m    971\u001b[0m     \u001b[39m# queries, keys and values, independently.\u001b[39;00m\n\u001b[1;32m    972\u001b[0m     \u001b[39m# Then take the layer norm of these inputs, and pass these to the attention module.\u001b[39;00m\n\u001b[0;32m--> 973\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattn(\n\u001b[1;32m    974\u001b[0m         query_input\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mln1(query_input)\n\u001b[1;32m    975\u001b[0m         \u001b[39m+\u001b[39;49m (\u001b[39m0.0\u001b[39;49m \u001b[39mif\u001b[39;49;00m shortformer_pos_embed \u001b[39mis\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m shortformer_pos_embed),\n\u001b[1;32m    976\u001b[0m         key_input\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mln1(key_input)\n\u001b[1;32m    977\u001b[0m         \u001b[39m+\u001b[39;49m (\u001b[39m0.0\u001b[39;49m \u001b[39mif\u001b[39;49;00m shortformer_pos_embed \u001b[39mis\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m shortformer_pos_embed),\n\u001b[1;32m    978\u001b[0m         value_input\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mln1(value_input),\n\u001b[1;32m    979\u001b[0m         past_kv_cache_entry\u001b[39m=\u001b[39;49mpast_kv_cache_entry,\n\u001b[1;32m    980\u001b[0m     )\n\u001b[1;32m    981\u001b[0m )  \u001b[39m# [batch, pos, d_model]\u001b[39;00m\n\u001b[1;32m    982\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcfg\u001b[39m.\u001b[39mattn_only \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcfg\u001b[39m.\u001b[39mparallel_attn_mlp:\n\u001b[1;32m    983\u001b[0m     resid_mid \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhook_resid_mid(\n\u001b[1;32m    984\u001b[0m         resid_pre \u001b[39m+\u001b[39m attn_out\n\u001b[1;32m    985\u001b[0m     )  \u001b[39m# [batch, pos, d_model]\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformer_lens/components.py:508\u001b[0m, in \u001b[0;36mAttention.forward\u001b[0;34m(self, query_input, key_input, value_input, past_kv_cache_entry, additive_attention_mask)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    505\u001b[0m     qkv_einops_string \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbatch pos d_model\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    507\u001b[0m q \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhook_q(\n\u001b[0;32m--> 508\u001b[0m     einsum(\n\u001b[1;32m    509\u001b[0m         \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mqkv_einops_string\u001b[39m}\u001b[39;49;00m\u001b[39m, head_index d_model d_head \u001b[39;49m\u001b[39m\\\u001b[39;49;00m\n\u001b[1;32m    510\u001b[0m \u001b[39m        -> batch pos head_index d_head\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    511\u001b[0m         query_input,\n\u001b[1;32m    512\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mW_Q,\n\u001b[1;32m    513\u001b[0m     )\n\u001b[1;32m    514\u001b[0m     \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mb_Q\n\u001b[1;32m    515\u001b[0m )  \u001b[39m# [batch, pos, head_index, d_head]\u001b[39;00m\n\u001b[1;32m    516\u001b[0m k \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhook_k(\n\u001b[1;32m    517\u001b[0m     einsum(\n\u001b[1;32m    518\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mqkv_einops_string\u001b[39m}\u001b[39;00m\u001b[39m, head_index d_model d_head \u001b[39m\u001b[39m\\\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m     \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mb_K\n\u001b[1;32m    524\u001b[0m )  \u001b[39m# [batch, pos, head_index, d_head]\u001b[39;00m\n\u001b[1;32m    525\u001b[0m v \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhook_v(\n\u001b[1;32m    526\u001b[0m     einsum(\n\u001b[1;32m    527\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mqkv_einops_string\u001b[39m}\u001b[39;00m\u001b[39m, head_index d_model d_head \u001b[39m\u001b[39m\\\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    532\u001b[0m     \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mb_V\n\u001b[1;32m    533\u001b[0m )  \u001b[39m# [batch, pos, head_index, d_head]\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/fancy_einsum/__init__.py:136\u001b[0m, in \u001b[0;36meinsum\u001b[0;34m(equation, *operands)\u001b[0m\n\u001b[1;32m    134\u001b[0m backend \u001b[39m=\u001b[39m get_backend(operands[\u001b[39m0\u001b[39m])\n\u001b[1;32m    135\u001b[0m new_equation \u001b[39m=\u001b[39m convert_equation(equation)\n\u001b[0;32m--> 136\u001b[0m \u001b[39mreturn\u001b[39;00m backend\u001b[39m.\u001b[39;49meinsum(new_equation, \u001b[39m*\u001b[39;49moperands)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/fancy_einsum/__init__.py:54\u001b[0m, in \u001b[0;36mTorchBackend.einsum\u001b[0;34m(self, equation, *operands)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39meinsum\u001b[39m(\u001b[39mself\u001b[39m, equation, \u001b[39m*\u001b[39moperands):\n\u001b[0;32m---> 54\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtorch\u001b[39m.\u001b[39;49meinsum(equation, \u001b[39m*\u001b[39;49moperands)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/functional.py:378\u001b[0m, in \u001b[0;36meinsum\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    373\u001b[0m     \u001b[39mreturn\u001b[39;00m einsum(equation, \u001b[39m*\u001b[39m_operands)\n\u001b[1;32m    375\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(operands) \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m2\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m opt_einsum\u001b[39m.\u001b[39menabled:\n\u001b[1;32m    376\u001b[0m     \u001b[39m# the path for contracting 0 or 1 time(s) is already optimized\u001b[39;00m\n\u001b[1;32m    377\u001b[0m     \u001b[39m# or the user has disabled using opt_einsum\u001b[39;00m\n\u001b[0;32m--> 378\u001b[0m     \u001b[39mreturn\u001b[39;00m _VF\u001b[39m.\u001b[39;49meinsum(equation, operands)  \u001b[39m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    380\u001b[0m path \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[39mif\u001b[39;00m opt_einsum\u001b[39m.\u001b[39mis_available():\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`"
     ]
    }
   ],
   "source": [
    "ngram = \"orschlÃ¤gen\"\n",
    "model = HookedTransformer.from_pretrained(\"EleutherAI/pythia-70m\",\n",
    "    center_unembed=True,\n",
    "    center_writing_weights=True,\n",
    "    fold_ln=True,\n",
    "    device=device)\n",
    "\n",
    "activate_neurons_fwd_hooks, deactivate_neurons_fwd_hooks = haystack_utils.get_context_ablation_hooks(3, [669], model)\n",
    "all_ignore, _ = haystack_utils.get_weird_tokens(model, plot_norms=False)\n",
    "\n",
    "german_data = haystack_utils.load_json_data(\"data/german_europarl.json\")[:200]\n",
    "common_tokens = haystack_utils.get_common_tokens(german_data, model, all_ignore, k=100)\n",
    "\n",
    "# Sort tokens into new word vs continuation\n",
    "new_word_tokens = []\n",
    "continuation_tokens = []\n",
    "for token in common_tokens:\n",
    "    str_token = model.to_single_str_token(token.item())\n",
    "    if str_token.startswith(\" \"):\n",
    "        new_word_tokens.append(token)\n",
    "    else:\n",
    "        continuation_tokens.append(token)\n",
    "new_word_tokens = torch.stack(new_word_tokens)\n",
    "continuation_tokens = torch.stack(continuation_tokens)\n",
    "\n",
    "context_direction = model.W_out[3, 669, :]\n",
    "\n",
    "def get_cosine_sim(direction: Float[Tensor, \"d_res\"], layer=5) -> Float[Tensor, \"d_mlp\"]:\n",
    "    cosine = torch.nn.CosineSimilarity(dim=1)\n",
    "    return cosine(model.W_in[layer].T, direction.unsqueeze(0))\n",
    "\n",
    "def plot_histogram(t1, t2, t3, name1, name2, name3):\n",
    "    t1 = t1.cpu().numpy()\n",
    "    t2 = t2.cpu().numpy()\n",
    "    t3 = t3.cpu().numpy()\n",
    "    fig = go.Figure()\n",
    "    bin_width= 0.01\n",
    "    fig.add_trace(go.Histogram(x=t1, name=name1, opacity=0.5, histnorm='probability density', xbins=dict(size=bin_width)))\n",
    "    fig.add_trace(go.Histogram(x=t2, name=name2, opacity=0.5 , histnorm='probability density', xbins=dict(size=bin_width)))\n",
    "    fig.add_trace(go.Histogram(x=t3, name=name3, opacity=0.5, histnorm='probability density', xbins=dict(size=bin_width)))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=\"Individual MLP5 similarities to direction vectors\",\n",
    "        xaxis_title=\"Cosine Similarity\",\n",
    "        yaxis_title=\"Probability Density\",\n",
    "        barmode=\"overlay\",\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "def compute_mlp_loss(prompts, df, neurons, ablate_mode=\"NNN\", layer=5, compute_original_loss=False, mean=True):\n",
    "\n",
    "    mean_activations = torch.Tensor(df[df.index.isin(neurons.tolist())][ablate_mode].tolist()).cuda()\n",
    "    def ablate_mlp_hook(value, hook):\n",
    "        value[:, :, neurons] = mean_activations\n",
    "        return value\n",
    "\n",
    "    with model.hooks(fwd_hooks=[(f\"blocks.{layer}.mlp.hook_pre\", ablate_mlp_hook)]):\n",
    "        if mean:\n",
    "            ablated_loss = model(prompts, return_type=\"loss\", loss_per_token=True)[:, -1].mean().item()\n",
    "        else:\n",
    "            ablated_loss = model(prompts, return_type=\"loss\", loss_per_token=True)[:, -1].tolist()\n",
    "\n",
    "    if compute_original_loss:\n",
    "        if mean:\n",
    "            loss = model(prompts, return_type=\"loss\", loss_per_token=True)[:, -1].mean().item()\n",
    "        else:\n",
    "            loss = model(prompts, return_type=\"loss\", loss_per_token=True)[:, -1].tolist()\n",
    "        return loss, ablated_loss\n",
    "    return ablated_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss change for different AND thresholds\n",
    "option = \"orschlÃ¤gen\"\n",
    "df = pd.read_pickle(f\"data/and_neurons/df_{option}.pkl\") \n",
    "\n",
    "with open(f\"data/and_neurons/set_losses.json\", \"r\") as f:\n",
    "    all_losses = json.load(f)\n",
    "\n",
    "prompts = haystack_utils.generate_random_prompts(option, model, common_tokens, 500, length=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_token = model.to_single_token(\"gen\")\n",
    "ge_token = model.to_single_token(\"ge\")\n",
    "gen_dir = model.tokens_to_residual_directions(gen_token)\n",
    "ge_dir = model.tokens_to_residual_directions(ge_token)\n",
    "\n",
    "cos = torch.nn.CosineSimilarity(dim=1)\n",
    "gen_sims = cos(model.W_out[5], gen_dir.unsqueeze(0)).cpu().numpy()\n",
    "ge_sims = cos(model.W_out[5], ge_dir.unsqueeze(0)).cpu().numpy()\n",
    "\n",
    "df[\"GenSim\"] = gen_sims\n",
    "df[\"GeSim\"] = ge_sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3292, device='cuda:0')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how similar gen and ge dirs are\n",
    "cos = torch.nn.CosineSimilarity(dim=0)\n",
    "cos(gen_dir, ge_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boosted tokens: uf (+4.21), gen (+1.78), Ã (+1.43), ger (+0.31), Ãen (+0.14)\n",
      "Deboosted tokens: ge (-0.49), gt (-0.15)\n"
     ]
    }
   ],
   "source": [
    "haystack_utils.get_boosted_tokens(prompts, model, deactivate_neurons_fwd_hooks, all_ignore, deboost=False)\n",
    "haystack_utils.get_boosted_tokens(prompts, model, deactivate_neurons_fwd_hooks, all_ignore, deboost=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prev/Curr/Context\n",
      "AblationDiff    0.434787\n",
      "GenSim          0.002992\n",
      "GeSim          -0.000410\n",
      "dtype: float64\n",
      "Prev/Curr/Context\n",
      "AblationDiff   -0.431541\n",
      "GenSim          0.000029\n",
      "GeSim           0.004855\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df[df[\"AblationDiff\"]>0.2][[\"AblationDiff\", \"GenSim\", \"GeSim\"]].mean())\n",
    "print(df[df[\"AblationDiff\"]<-0.2][[\"AblationDiff\", \"GenSim\", \"GeSim\"]].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'GenSim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3653\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/_libs/index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'GenSim'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[121], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m df_tmp \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m      2\u001b[0m ablation_mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mYYN\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m df_tmp[\u001b[39m\"\u001b[39m\u001b[39mCustom\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m (df[\u001b[39m\"\u001b[39m\u001b[39mYYY\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m>\u001b[39m\u001b[39m0\u001b[39m) \u001b[39m&\u001b[39m (df[\u001b[39m\"\u001b[39m\u001b[39mYYY\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m>\u001b[39mdf[\u001b[39m\"\u001b[39m\u001b[39mNNN\u001b[39m\u001b[39m\"\u001b[39m]) \u001b[39m&\u001b[39m (df[\u001b[39m\"\u001b[39;49m\u001b[39mGenSim\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m>\u001b[39mdf[\u001b[39m\"\u001b[39m\u001b[39mGeSim\u001b[39m\u001b[39m\"\u001b[39m]) \u001b[39m&\u001b[39m \\\n\u001b[1;32m      5\u001b[0m     (df[\u001b[39m\"\u001b[39m\u001b[39mYYY\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m>\u001b[39mdf[\u001b[39m\"\u001b[39m\u001b[39mYYN\u001b[39m\u001b[39m\"\u001b[39m]) \u001b[39m&\u001b[39m (df[\u001b[39m\"\u001b[39m\u001b[39mYYY\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m>\u001b[39mdf[\u001b[39m\"\u001b[39m\u001b[39mYNY\u001b[39m\u001b[39m\"\u001b[39m]) \u001b[39m&\u001b[39m (df[\u001b[39m\"\u001b[39m\u001b[39mYYY\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m>\u001b[39mdf[\u001b[39m\"\u001b[39m\u001b[39mNYY\u001b[39m\u001b[39m\"\u001b[39m]) \u001b[39m&\u001b[39m\\\n\u001b[1;32m      6\u001b[0m     (df[\u001b[39m\"\u001b[39m\u001b[39mYYY\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m>\u001b[39mdf[\u001b[39m\"\u001b[39m\u001b[39mNYN\u001b[39m\u001b[39m\"\u001b[39m]) \u001b[39m&\u001b[39m (df[\u001b[39m\"\u001b[39m\u001b[39mYYY\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m>\u001b[39mdf[\u001b[39m\"\u001b[39m\u001b[39mNNY\u001b[39m\u001b[39m\"\u001b[39m]) \u001b[39m&\u001b[39m (df[\u001b[39m\"\u001b[39m\u001b[39mYYY\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m>\u001b[39mdf[\u001b[39m\"\u001b[39m\u001b[39mYNN\u001b[39m\u001b[39m\"\u001b[39m])\u001b[39m# & df[\"PosSim\"]\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[39mprint\u001b[39m(df_tmp[\u001b[39m\"\u001b[39m\u001b[39mCustom\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39msum())\n\u001b[1;32m      9\u001b[0m pos_and_neurons \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mLongTensor(df_tmp[df_tmp[\u001b[39m\"\u001b[39m\u001b[39mCustom\u001b[39m\u001b[39m\"\u001b[39m]]\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39mtolist())\u001b[39m.\u001b[39mcuda()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3760\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3761\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3762\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3763\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3653\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3655\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3656\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3657\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3660\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'GenSim'"
     ]
    }
   ],
   "source": [
    "df_tmp = df.copy()\n",
    "ablation_mode = \"YYN\"\n",
    "\n",
    "df_tmp[\"Custom\"] = (df[\"YYY\"]>0) & (df[\"YYY\"]>df[\"NNN\"]) & (df[\"GenSim\"]>df[\"GeSim\"]) & \\\n",
    "    (df[\"YYY\"]>df[\"YYN\"]) & (df[\"YYY\"]>df[\"YNY\"]) & (df[\"YYY\"]>df[\"NYY\"]) &\\\n",
    "    (df[\"YYY\"]>df[\"NYN\"]) & (df[\"YYY\"]>df[\"NNY\"]) & (df[\"YYY\"]>df[\"YNN\"])# & df[\"PosSim\"]\n",
    "\n",
    "print(df_tmp[\"Custom\"].sum())\n",
    "pos_and_neurons = torch.LongTensor(df_tmp[df_tmp[\"Custom\"]].index.tolist()).cuda()\n",
    "\n",
    "#df_tmp[\"context_diff\"] = df_tmp[\"YYY\"] - df_tmp[\"YYN\"]\n",
    "#df_tmp = df_tmp.sort_values(by=[\"Custom\", \"context_diff\"], ascending=False)\n",
    "#pos_and_neurons = torch.LongTensor(df_tmp.index.tolist()[:30]).cuda()\n",
    "\n",
    "original_loss, ablated_loss = compute_mlp_loss(prompts, df, pos_and_neurons, ablate_mode=ablation_mode, compute_original_loss=True)\n",
    "print(original_loss, ablated_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>                            <div id=\"fa88d3f1-ac46-4e96-bb3a-add43f007235\" class=\"plotly-graph-div\" style=\"height:525px; width:1000px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"fa88d3f1-ac46-4e96-bb3a-add43f007235\")) {                    Plotly.newPlot(                        \"fa88d3f1-ac46-4e96-bb3a-add43f007235\",                        [{\"error_y\":{\"array\":[1.5670197602114506],\"type\":\"data\",\"visible\":true},\"name\":\"Original\",\"x\":[\"Original\"],\"y\":[1.4473304677340202],\"type\":\"bar\"},{\"error_y\":{\"array\":[1.6820884137563037],\"type\":\"data\",\"visible\":true},\"name\":\"YYY\",\"x\":[\"YYY\"],\"y\":[1.660820982522564],\"type\":\"bar\"},{\"error_y\":{\"array\":[3.552136734441763],\"type\":\"data\",\"visible\":true},\"name\":\"YNY\",\"x\":[\"YNY\"],\"y\":[13.521126428604125],\"type\":\"bar\"},{\"error_y\":{\"array\":[2.9759520230605063],\"type\":\"data\",\"visible\":true},\"name\":\"NYY\",\"x\":[\"NYY\"],\"y\":[7.459195897728205],\"type\":\"bar\"},{\"error_y\":{\"array\":[3.0854424924399915],\"type\":\"data\",\"visible\":true},\"name\":\"YYN\",\"x\":[\"YYN\"],\"y\":[7.959784854471684],\"type\":\"bar\"},{\"error_y\":{\"array\":[3.8592734283019805],\"type\":\"data\",\"visible\":true},\"name\":\"YNN\",\"x\":[\"YNN\"],\"y\":[17.71716115474701],\"type\":\"bar\"},{\"error_y\":{\"array\":[3.559754200633209],\"type\":\"data\",\"visible\":true},\"name\":\"NYN\",\"x\":[\"NYN\"],\"y\":[13.49374113893509],\"type\":\"bar\"},{\"error_y\":{\"array\":[3.655443661152595],\"type\":\"data\",\"visible\":true},\"name\":\"NNY\",\"x\":[\"NNY\"],\"y\":[15.357988551139831],\"type\":\"bar\"},{\"error_y\":{\"array\":[3.9186588648929708],\"type\":\"data\",\"visible\":true},\"name\":\"NNN\",\"x\":[\"NNN\"],\"y\":[18.918647171020506],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"Losses for patching 102 AND MLP5 neurons with different ablation modes\"},\"xaxis\":{\"title\":{\"text\":\"\"}},\"yaxis\":{\"range\":[0,24]},\"barmode\":\"group\",\"width\":1000,\"showlegend\":true},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('fa88d3f1-ac46-4e96-bb3a-add43f007235');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def compute_counterfactual_losses(prompts, df, neurons):\n",
    "    losses = [model(prompts, return_type=\"loss\", loss_per_token=True)[:, -1].tolist()]\n",
    "    ablations = [\"YYY\", \"YNY\", \"NYY\", \"YYN\", \"YNN\", \"NYN\", \"NNY\", \"NNN\"]\n",
    "    names = [\"Original\"] + ablations\n",
    "    for ablation_mode in ablations:\n",
    "        ablated_loss = compute_mlp_loss(prompts, df, neurons, ablate_mode=ablation_mode, mean=False)\n",
    "        losses.append(ablated_loss)\n",
    "    return losses, names\n",
    "\n",
    "losses, names = compute_counterfactual_losses(prompts, df, pos_and_neurons)#torch.LongTensor([i for i in range(100)]))\n",
    "plotting_utils.plot_barplot(losses, names, title=\"Losses for patching 102 AND MLP5 neurons with different ablation modes\", yrange=(0, 24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "haystack_utils.clean_cache()\n",
    "prompts = haystack_utils.generate_random_prompts(option, model, common_tokens, 500, length=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2064943313598633\n"
     ]
    }
   ],
   "source": [
    "with model.hooks(fwd_hooks=deactivate_neurons_fwd_hooks):\n",
    "    deactivated_loss, cache = model.run_with_cache(prompts, return_type=\"loss\", loss_per_token=True)\n",
    "\n",
    "#cache = cache[\"blocks.5.mlp.hook_pre\"][:, -2].mean(0)\n",
    "print(deactivated_loss[:, -1].mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 23, 2048])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cache[\"post\", 5].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.4382295608520508, 5.653645992279053)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_mlp_loss(prompts, df, torch.LongTensor([i for i in range(2048)]), \"YYN\", compute_original_loss=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_activations_df = torch.Tensor(df[df.index.isin([i for i in range(2048)])][\"YYN\"].tolist()).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2048]) torch.Size([2048])\n",
      "tensor([-1.3228, -1.1839, -0.7734, -2.4799, -0.9134, -0.9777, -1.1465, -1.8528,\n",
      "        -0.9403, -0.6645], device='cuda:0')\n",
      "tensor([-1.3351, -1.1835, -0.7855, -2.4714, -0.9022, -0.9851, -1.1769, -1.8635,\n",
      "        -0.9359, -0.6646], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(mean_activations_df.shape, cache.shape)\n",
    "print(mean_activations_df[:10])\n",
    "print(cache[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>                            <div id=\"b6962c43-1eae-4a74-beac-6ce60d91ec27\" class=\"plotly-graph-div\" style=\"height:525px; width:1000px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"b6962c43-1eae-4a74-beac-6ce60d91ec27\")) {                    Plotly.newPlot(                        \"b6962c43-1eae-4a74-beac-6ce60d91ec27\",                        [{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"Original\",\"x\":[\"Original\"],\"y\":[1.4382295608520508],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND -0.50 (22)\",\"x\":[\"AND -0.50 (22)\"],\"y\":[1.4031965732574463],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND -0.40 (14)\",\"x\":[\"AND -0.40 (14)\"],\"y\":[1.4982680082321167],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND -0.30 (14)\",\"x\":[\"AND -0.30 (14)\"],\"y\":[1.4405291080474854],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND -0.20 (20)\",\"x\":[\"AND -0.20 (20)\"],\"y\":[1.4521732330322266],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND -0.10 (17)\",\"x\":[\"AND -0.10 (17)\"],\"y\":[1.5765925645828247],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND -0.00 (21)\",\"x\":[\"AND -0.00 (21)\"],\"y\":[1.4966233968734741],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND 0.10 (12)\",\"x\":[\"AND 0.10 (12)\"],\"y\":[1.3823171854019165],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND 0.20 (21)\",\"x\":[\"AND 0.20 (21)\"],\"y\":[1.4386775493621826],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND 0.30 (21)\",\"x\":[\"AND 0.30 (21)\"],\"y\":[1.232452392578125],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND 0.40 (19)\",\"x\":[\"AND 0.40 (19)\"],\"y\":[1.3736011981964111],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND 0.50 (20)\",\"x\":[\"AND 0.50 (20)\"],\"y\":[1.422939419746399],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND 0.60 (21)\",\"x\":[\"AND 0.60 (21)\"],\"y\":[1.4341751337051392],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND 0.70 (21)\",\"x\":[\"AND 0.70 (21)\"],\"y\":[1.778494954109192],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND 0.80 (19)\",\"x\":[\"AND 0.80 (19)\"],\"y\":[1.6555122137069702],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND 0.90 (19)\",\"x\":[\"AND 0.90 (19)\"],\"y\":[1.272355318069458],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND 1.00 (16)\",\"x\":[\"AND 1.00 (16)\"],\"y\":[1.8343677520751953],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND 1.10 (16)\",\"x\":[\"AND 1.10 (16)\"],\"y\":[1.6646665334701538],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND 1.20 (16)\",\"x\":[\"AND 1.20 (16)\"],\"y\":[1.8627641201019287],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND 1.30 (14)\",\"x\":[\"AND 1.30 (14)\"],\"y\":[1.8179941177368164],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND 1.40 (8)\",\"x\":[\"AND 1.40 (8)\"],\"y\":[1.6051018238067627],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND 1.50 (4)\",\"x\":[\"AND 1.50 (4)\"],\"y\":[1.3911800384521484],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND 1.60 (5)\",\"x\":[\"AND 1.60 (5)\"],\"y\":[1.8147002458572388],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND 1.70 (5)\",\"x\":[\"AND 1.70 (5)\"],\"y\":[2.058548927307129],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND 1.80 (3)\",\"x\":[\"AND 1.80 (3)\"],\"y\":[1.6896328926086426],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND 1.90 (3)\",\"x\":[\"AND 1.90 (3)\"],\"y\":[1.506465196609497],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"AND neuron loss increase for different thresholds\"},\"xaxis\":{\"title\":{\"text\":\"\"}},\"yaxis\":{\"title\":{\"text\":\"\"}},\"barmode\":\"group\",\"width\":1000,\"showlegend\":true},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('b6962c43-1eae-4a74-beac-6ce60d91ec27');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# And thresholds without similarity constraint\n",
    "prompts = haystack_utils.generate_random_prompts(option, model, common_tokens, 2000, length=20)\n",
    "losses = []\n",
    "lens =  []\n",
    "thresholds = []\n",
    "for and_threshold in np.arange(-0.5, 2, 0.1):\n",
    "    df_tmp = df.copy()\n",
    "    ablation_mode = \"YYN\"\n",
    "    df_tmp[\"Custom\"] = (df[\"YYY\"]>and_threshold) & (df[\"YYN\"]<=and_threshold) & (df[\"YNY\"]<=and_threshold) & (df[\"NYY\"]<=and_threshold) & (df[\"YNN\"]<=and_threshold) & (df[\"NNY\"]<=and_threshold)& (df[\"NYN\"]<=and_threshold)\n",
    "    pos_and_neurons = torch.LongTensor(df_tmp[df_tmp[\"Custom\"]].index.tolist()).cuda()\n",
    "\n",
    "    original_loss, ablated_loss = compute_mlp_loss(prompts, df, pos_and_neurons, ablate_mode=ablation_mode, compute_original_loss=True)\n",
    "    if len(losses) == 0:\n",
    "        losses.append([original_loss])\n",
    "    losses.append([ablated_loss])\n",
    "    lens.append(len(pos_and_neurons))\n",
    "    thresholds.append(and_threshold)\n",
    "names = [\"Original\"] + [f\"AND {thr:.2f} ({length})\" for thr, length in zip(thresholds, lens)]\n",
    "haystack_utils.plot_barplot(losses, names, title=\"AND neuron loss increase for different thresholds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>                            <div id=\"99af98eb-a217-47c8-97dc-6d5ab64346ca\" class=\"plotly-graph-div\" style=\"height:525px; width:1000px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"99af98eb-a217-47c8-97dc-6d5ab64346ca\")) {                    Plotly.newPlot(                        \"99af98eb-a217-47c8-97dc-6d5ab64346ca\",                        [{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"Original\",\"x\":[\"Original\"],\"y\":[1.4382295608520508],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND -0.50 (10)\",\"x\":[\"AND -0.50 (10)\"],\"y\":[1.483715534210205],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND -0.40 (10)\",\"x\":[\"AND -0.40 (10)\"],\"y\":[1.5106624364852905],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND -0.30 (8)\",\"x\":[\"AND -0.30 (8)\"],\"y\":[1.5630098581314087],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND -0.20 (9)\",\"x\":[\"AND -0.20 (9)\"],\"y\":[1.666882872581482],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND -0.10 (11)\",\"x\":[\"AND -0.10 (11)\"],\"y\":[1.6793701648712158],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND -0.00 (12)\",\"x\":[\"AND -0.00 (12)\"],\"y\":[1.6704334020614624],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND 0.10 (7)\",\"x\":[\"AND 0.10 (7)\"],\"y\":[1.520676851272583],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND 0.20 (12)\",\"x\":[\"AND 0.20 (12)\"],\"y\":[1.7507907152175903],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND 0.30 (10)\",\"x\":[\"AND 0.30 (10)\"],\"y\":[1.7054075002670288],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND 0.40 (7)\",\"x\":[\"AND 0.40 (7)\"],\"y\":[1.718890905380249],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND 0.50 (9)\",\"x\":[\"AND 0.50 (9)\"],\"y\":[1.776005506515503],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND 0.60 (12)\",\"x\":[\"AND 0.60 (12)\"],\"y\":[1.8645012378692627],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND 0.70 (12)\",\"x\":[\"AND 0.70 (12)\"],\"y\":[2.0634610652923584],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND 0.80 (11)\",\"x\":[\"AND 0.80 (11)\"],\"y\":[2.008836507797241],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND 0.90 (9)\",\"x\":[\"AND 0.90 (9)\"],\"y\":[1.770878553390503],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND 1.00 (9)\",\"x\":[\"AND 1.00 (9)\"],\"y\":[2.3202476501464844],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND 1.10 (8)\",\"x\":[\"AND 1.10 (8)\"],\"y\":[2.1552975177764893],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND 1.20 (9)\",\"x\":[\"AND 1.20 (9)\"],\"y\":[2.265568971633911],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND 1.30 (10)\",\"x\":[\"AND 1.30 (10)\"],\"y\":[2.190293312072754],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND 1.40 (6)\",\"x\":[\"AND 1.40 (6)\"],\"y\":[1.7008997201919556],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND 1.50 (2)\",\"x\":[\"AND 1.50 (2)\"],\"y\":[1.5467665195465088],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND 1.60 (4)\",\"x\":[\"AND 1.60 (4)\"],\"y\":[1.9145389795303345],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND 1.70 (5)\",\"x\":[\"AND 1.70 (5)\"],\"y\":[2.058548927307129],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND 1.80 (3)\",\"x\":[\"AND 1.80 (3)\"],\"y\":[1.6896328926086426],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND 1.90 (2)\",\"x\":[\"AND 1.90 (2)\"],\"y\":[1.523792028427124],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"AND neuron loss increase with cosine sim constraint: gen \\u003e ge\"},\"xaxis\":{\"title\":{\"text\":\"\"}},\"yaxis\":{\"title\":{\"text\":\"\"}},\"barmode\":\"group\",\"width\":1000,\"showlegend\":true},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('99af98eb-a217-47c8-97dc-6d5ab64346ca');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# And thresholds with similarity constraint\n",
    "losses = []\n",
    "lens =  []\n",
    "thresholds = []\n",
    "for and_threshold in np.arange(-0.5, 2, 0.1):\n",
    "    df_tmp = df.copy()\n",
    "    ablation_mode = \"YYN\"\n",
    "    df_tmp[\"Custom\"] = (df[\"GenSim\"]>df[\"GeSim\"]) & \\\n",
    "        (df[\"YYY\"]>and_threshold) & (df[\"YYN\"]<=and_threshold) & (df[\"YNY\"]<=and_threshold) & (df[\"NYY\"]<=and_threshold) & (df[\"YNN\"]<=and_threshold) & (df[\"NNY\"]<=and_threshold)& (df[\"NYN\"]<=and_threshold)\n",
    "    pos_and_neurons = torch.LongTensor(df_tmp[df_tmp[\"Custom\"]].index.tolist()).cuda()\n",
    "\n",
    "    original_loss, ablated_loss = compute_mlp_loss(prompts, df, pos_and_neurons, ablate_mode=ablation_mode, compute_original_loss=True)\n",
    "    if len(losses) == 0:\n",
    "        losses.append([original_loss])\n",
    "    losses.append([ablated_loss])\n",
    "    lens.append(len(pos_and_neurons))\n",
    "    thresholds.append(and_threshold)\n",
    "names = [\"Original\"] + [f\"AND {thr:.2f} ({length})\" for thr, length in zip(thresholds, lens)]\n",
    "haystack_utils.plot_barplot(losses, names, title=\"AND neuron loss increase with cosine sim constraint: gen > ge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model.hooks(deactivate_neurons_fwd_hooks):\n",
    "    ablated_loss, ablated_cache = model.run_with_cache(prompts, return_type=\"loss\")\n",
    "\n",
    "def get_ablate_neurons_hook(neuron: int | list[int], ablated_cache, layer=5):\n",
    "    def ablate_neurons_hook(value, hook):\n",
    "        value[:, :, neuron] = ablated_cache[f'blocks.{layer}.mlp.hook_post'][:, :, neuron]\n",
    "        return value\n",
    "    return [(f'blocks.{layer}.mlp.hook_post', ablate_neurons_hook)]\n",
    "\n",
    "ablate_top_neurons_hook = get_ablate_neurons_hook([i for i in range(2048)], ablated_cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.5872, 1.4587, 0.8471, 0.3234, 0.0033, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000], device='cuda:0')\n",
      "['Ã', 'gen', 'Ãen', 'ger', 'gt', '-', '*', ',', '(', '&', ')', '+', \"'\", '!', '<|endoftext|>', '<|padding|>', '%', '$', '\"', '#']\n"
     ]
    }
   ],
   "source": [
    "original_logprobs, ablated_logprobs, _, all_MLP5_logprobs = haystack_utils.get_direct_effect(prompts, model, pos=-2, context_ablation_hooks=deactivate_neurons_fwd_hooks, context_activation_hooks=activate_neurons_fwd_hooks, return_type='logprobs')\n",
    "\n",
    "diffs = (original_logprobs - ablated_logprobs).mean(0)\n",
    "diffs[all_ignore] = 0\n",
    "diffs[original_logprobs.mean(0)<-7] = 0\n",
    "top_diff, top_token = torch.topk(diffs, 20)\n",
    "print(top_diff)\n",
    "print(model.to_str_tokens(top_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "\n",
    "option = \"orschlÃ¤gen\"\n",
    "ablation_mode = \"YYN\"\n",
    "prompts = haystack_utils.generate_random_prompts(option, model, common_tokens, 1000, length=20)\n",
    "\n",
    "names = list(all_losses[option][ablation_mode].keys())\n",
    "losses = [[all_losses[option][ablation_mode][name]] for name in names]\n",
    "\n",
    "print(len(names), len(losses))\n",
    "print([len(x) for x in losses])\n",
    "haystack_utils.plot_barplot(losses, names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "layer = 2\n",
    "ngram = \"orschlÃ¤gen\"\n",
    "prompts = haystack_utils.generate_random_prompts(ngram, model, common_tokens, 500, length=20)\n",
    "\n",
    "if ngram.startswith(\" \"):\n",
    "    prompt_tuple = haystack_utils.get_trigram_prompts(prompts, new_word_tokens, continuation_tokens)\n",
    "else:\n",
    "    prompt_tuple = haystack_utils.get_trigram_prompts(prompts, continuation_tokens, continuation_tokens)\n",
    "prev_token_direction, curr_token_direction = haystack_utils.get_residual_trigram_directions(prompt_tuple, model, layer-1)\n",
    "\n",
    "prev_token_sim = get_cosine_sim(prev_token_direction, layer)\n",
    "curr_token_sim = get_cosine_sim(curr_token_direction, layer)\n",
    "context_sim = get_cosine_sim(context_direction, layer)\n",
    "    \n",
    "plot_histogram(prev_token_sim, curr_token_sim, context_sim, \"Prev Token\", \"Curr Token\", \"Context\")\n",
    "# %%\n",
    "prev_sim_neurons = torch.argwhere(prev_token_sim>0.05)\n",
    "curr_sim_neurons = torch.argwhere(curr_token_sim>0.03)\n",
    "\n",
    "print(len(prev_sim_neurons), len(curr_sim_neurons))\n",
    "union = haystack_utils.union_where([prev_token_sim, curr_token_sim], 0.07)\n",
    "print(union)\n",
    "# %%\n",
    "\n",
    "# Get random mean cache\n",
    "random_prompts = haystack_utils.generate_random_prompts(ngram, model, common_tokens, 500, length=20)[:, :-3]\n",
    "_, random_cache = model.run_with_cache(random_prompts)\n",
    "\n",
    "\n",
    "# %%\n",
    "# Define ablate neuron hook\n",
    "\n",
    "# Layer 1\n",
    "# orschlÃ¤gen: tensor([  61,  188, 1011], device='cuda:0')\n",
    "# hÃ¤ufig: 268 (almost doubles loss)\n",
    "# beweglich: neurons decrease loss - maybe they boost alternative completion\n",
    "\n",
    "def get_ablate_neurons_hook(neurons, layer):\n",
    "    print(neurons)\n",
    "    def ablate_neurons_hook(value, hook):\n",
    "        value[:, :, neurons] = random_cache[f'blocks.{layer}.mlp.hook_post'][:, :, neurons].mean((0, 1))\n",
    "        return value\n",
    "    return [(f'blocks.{layer}.mlp.hook_post', ablate_neurons_hook)]\n",
    "\n",
    "# Check loss increase\n",
    "original_loss, original_ablated_loss = compute_mlp_loss(prompts, df, torch.LongTensor([i for i in range(model.cfg.d_mlp)]).cuda(), compute_original_loss=True)\n",
    "\n",
    "with model.hooks(fwd_hooks=get_ablate_neurons_hook([1789], layer)):\n",
    "    ablated_loss = model(prompts, return_type=\"loss\", loss_per_token=True)[:, -1].mean().item()\n",
    "\n",
    "print(original_loss, original_ablated_loss, ablated_loss)\n",
    "# %%\n",
    "\n",
    "# 1011 increases loss on both \"gen\" and \"ge\"\n",
    "# Either it boosts both completions (trigram table)\n",
    "# Or it combines \"orsch\" and \"lÃ¤\" into a single representation that later components use\n",
    "\n",
    "# Check if trigram table by looking at the direct effect\n",
    "# Total effect of L1N1011\n",
    "with model.hooks(fwd_hooks=get_ablate_neurons_hook([1406], layer)):\n",
    "    _, ablated_cache = model.run_with_cache(prompts)\n",
    "\n",
    "def ablate_component_hook(value, hook):\n",
    "    value = ablated_cache[hook.name]\n",
    "    return value\n",
    "\n",
    "components = [f\"blocks.{layer}.mlp.hook_post\" for layer in range(3, 6)] + [f\"blocks.{layer}.attn.hook_z\" for layer in range(3, 6)]\n",
    "hooks = [(component, ablate_component_hook) for component in components]\n",
    "\n",
    "with model.hooks(fwd_hooks=hooks):\n",
    "    ablated_logits = model(prompts, return_type=\"logits\", loss_per_token=True)[:, -2].log_softmax(-1).mean(0)\n",
    "\n",
    "original_logits = model(prompts, return_type=\"logits\", loss_per_token=True)[:, -2].log_softmax(-1).mean(0)\n",
    "\n",
    "print(ablated_logits.shape, original_logits.shape)\n",
    "\n",
    "prob_diff = original_logits - ablated_logits\n",
    "prob_diff[all_ignore] = 0\n",
    "prob_diff[original_logits < -7] = 0\n",
    "diffs, tokens = torch.topk(prob_diff, 20)\n",
    "print(diffs)\n",
    "print(tokens)\n",
    "print(model.to_str_tokens(tokens))\n",
    "\n",
    "# %% \n",
    "# Direct effect\n",
    "_, original_cache = model.run_with_cache(prompts)\n",
    "\n",
    "def activate_component_hook(value, hook):\n",
    "    value = original_cache[hook.name]\n",
    "    return value\n",
    "\n",
    "activate_hooks = [(component, activate_component_hook) for component in components]\n",
    "\n",
    "with model.hooks(fwd_hooks=activate_hooks + get_ablate_neurons_hook([1406], layer)):\n",
    "    activated_logits = model(prompts, return_type=\"logits\", loss_per_token=True)[:, -2].log_softmax(-1).mean(0)\n",
    "\n",
    "prob_diff = original_logits - activated_logits\n",
    "prob_diff[all_ignore] = 0\n",
    "prob_diff[original_logits < -7] = 0\n",
    "diffs, tokens = torch.topk(prob_diff, 20)\n",
    "print(diffs)\n",
    "print(tokens)\n",
    "print(model.to_str_tokens(tokens))\n",
    "\n",
    "# Check later components + context neuron effects of 1011\n",
    "# %%\n",
    "\n",
    "#output_direction = model.W_out[1, 1011]\n",
    "output_direction = model.W_out[2, 1406]\n",
    "context_direction = model.W_out[3, 669]\n",
    "\n",
    "output_sims = get_cosine_sim(output_direction, 5)\n",
    "context_sims = get_cosine_sim(context_direction, 5)\n",
    "\n",
    "plot_histogram(output_sims, context_sims, torch.zeros_like(output_sims), \"Output\", \"Context\", \"Zero\")\n",
    "# %%\n",
    "union = haystack_utils.union_where([output_sims, context_sims], 0.05)\n",
    "len(union)\n",
    "# %%\n",
    "ngram = \"orschlÃ¤gen\"\n",
    "prompts = haystack_utils.generate_random_prompts(ngram, model, common_tokens, 1000, length=20)\n",
    "\n",
    "original_loss, original_ablated_loss = compute_mlp_loss(prompts, df, torch.LongTensor([i for i in range(model.cfg.d_mlp)]).cuda(), compute_original_loss=True)\n",
    "\n",
    "with model.hooks(fwd_hooks=get_ablate_neurons_hook(union, 5)): #712, 394, 287\n",
    "    ablated_loss = model(prompts, return_type=\"loss\", loss_per_token=True)[:, -1].mean().item()\n",
    "\n",
    "print(original_loss, original_ablated_loss, ablated_loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3360338807106018 4.822600841522217\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[' de', 'inen', ' V', 'orsch', 'lÃ¤', 'ge']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "ngram = \" meine VorschlÃ¤ge\"\n",
    "prompts = haystack_utils.generate_random_prompts(ngram, model, common_tokens, 1000, length=20)\n",
    "original_loss, original_ablated_loss = compute_mlp_loss(prompts, df, torch.LongTensor([i for i in range(model.cfg.d_mlp)]).cuda(), compute_original_loss=True)\n",
    "print(original_loss, original_ablated_loss)\n",
    "# %%\n",
    "model.to_str_tokens(model.to_tokens(\" deinen VorschlÃ¤ge\", prepend_bos=False))\n",
    "# %%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_losses = []\n",
    "ablated_losses = []\n",
    "ngrams = [\" VorschlÃ¤gen\", \" VorschlÃ¤ge\", \" seine VorschlÃ¤ge\", \" seinen VorschlÃ¤ge\", \" seinen VorschlÃ¤gen\", \" seine VorschlÃ¤gen\"]\n",
    "\n",
    "for ngram in ngrams:\n",
    "    prompts = haystack_utils.generate_random_prompts(ngram, model, common_tokens, 1000, length=20)\n",
    "\n",
    "    with model.hooks(fwd_hooks=deactivate_neurons_fwd_hooks):\n",
    "        ablated_loss = model(prompts, return_type=\"loss\", loss_per_token=True)[:, -1].mean().item()\n",
    "        ablated_losses.append(ablated_loss)\n",
    "    \n",
    "    original_loss = model(prompts, return_type=\"loss\", loss_per_token=True)[:, -1].mean().item()\n",
    "    original_losses.append(original_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"ngram\": ngrams, \"original_loss\": original_losses, \"ablated_loss\": ablated_losses})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 ngram  original_loss  ablated_loss\n",
      "0          VorschlÃ¤gen       1.233227      3.584343\n",
      "1           VorschlÃ¤ge       1.227341      0.848729\n",
      "2     seine VorschlÃ¤ge       0.372710      0.360383\n",
      "3    seinen VorschlÃ¤ge       3.786774      3.005842\n",
      "4   seinen VorschlÃ¤gen       0.244110      2.554850\n",
      "5    seine VorschlÃ¤gen       2.594725      4.802067\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>                            <div id=\"8ee3b6dd-66b2-4d63-b5f0-0b7778599177\" class=\"plotly-graph-div\" style=\"height:525px; width:950px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"8ee3b6dd-66b2-4d63-b5f0-0b7778599177\")) {                    Plotly.newPlot(                        \"8ee3b6dd-66b2-4d63-b5f0-0b7778599177\",                        [{\"marker\":{\"color\":\"blue\"},\"name\":\"Original\",\"x\":[\" Vorschl\\u00e4gen\",\" Vorschl\\u00e4ge\",\" seine Vorschl\\u00e4ge\",\" seinen Vorschl\\u00e4ge\",\" seinen Vorschl\\u00e4gen\",\" seine Vorschl\\u00e4gen\"],\"y\":[1.2332274913787842,1.2273411750793457,0.3727096617221832,3.786773920059204,0.2441098988056183,2.594724655151367],\"type\":\"bar\"},{\"marker\":{\"color\":\"green\"},\"name\":\"Ablated\",\"x\":[\" Vorschl\\u00e4gen\",\" Vorschl\\u00e4ge\",\" seine Vorschl\\u00e4ge\",\" seinen Vorschl\\u00e4ge\",\" seinen Vorschl\\u00e4gen\",\" seine Vorschl\\u00e4gen\"],\"y\":[3.584343433380127,0.8487294316291809,0.36038345098495483,3.0058417320251465,2.554849863052368,4.802066802978516],\"type\":\"bar\"}],                        {\"annotations\":[{\"font\":{\"color\":\"red\",\"size\":12},\"showarrow\":false,\"text\":\" seinen Vorschl\\u00e4ge\",\"x\":3,\"xref\":\"x\",\"y\":-0.052,\"yref\":\"paper\"},{\"font\":{\"color\":\"red\",\"size\":12},\"showarrow\":false,\"text\":\" seine Vorschl\\u00e4gen\",\"x\":5,\"xref\":\"x\",\"y\":-0.052,\"yref\":\"paper\"}],\"barmode\":\"group\",\"title\":{\"text\":\"Original Loss vs Ablated Loss\"},\"width\":950,\"xaxis\":{\"tickmode\":\"array\",\"ticktext\":[\" Vorschl\\u00e4gen\",\" Vorschl\\u00e4ge\",\" seine Vorschl\\u00e4ge\",\"\",\" seinen Vorschl\\u00e4gen\",\"\"],\"tickvals\":[0,1,2,3,4,5]},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('8ee3b6dd-66b2-4d63-b5f0-0b7778599177');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create traces for 'original loss' and 'ablated loss'\n",
    "trace1 = go.Bar(\n",
    "    x=df['ngram'],\n",
    "    y=df['original_loss'],\n",
    "    name='Original',\n",
    "    marker_color='blue'\n",
    ")\n",
    "\n",
    "trace2 = go.Bar(\n",
    "    x=df['ngram'],\n",
    "    y=df['ablated_loss'],\n",
    "    name='Ablated',\n",
    "    marker_color='green'\n",
    ")\n",
    "\n",
    "correct_ngrams = [\" VorschlÃ¤gen\", \" VorschlÃ¤ge\", \" seine VorschlÃ¤ge\", \"\", \" seinen VorschlÃ¤gen\", \"\"]\n",
    "incorrect_ngrams = [\"\", \"\", \"\", \" seinen VorschlÃ¤ge\", \"\", \" seine VorschlÃ¤gen\"]\n",
    "\n",
    "\n",
    "annotations = []\n",
    "for i, ngram in enumerate(incorrect_ngrams):\n",
    "    if ngram:  # if ngram is not empty\n",
    "        annotations.append(dict(\n",
    "            x=i,  # position of the label\n",
    "            y=-0.052,  # adjust this value to move the label up or down\n",
    "            xref=\"x\",\n",
    "            yref=\"paper\",\n",
    "            text=ngram,  # the label\n",
    "            font=dict(\n",
    "                color=\"red\",\n",
    "                size=12\n",
    "            ),\n",
    "            showarrow=False\n",
    "        ))\n",
    "\n",
    "# Create the layout\n",
    "layout = go.Layout(\n",
    "    title='Original Loss vs Ablated Loss',\n",
    "    barmode='group',  # this is what makes the bars grouped instead of stacked\n",
    "    xaxis=dict(tickmode='array', tickvals=df.index, ticktext=correct_ngrams),  # hide original x-axis labels\n",
    "    annotations=annotations,  # add annotations for the red labels\n",
    "    width=950\n",
    ")\n",
    "\n",
    "# Create the Figure\n",
    "fig = go.Figure(data=[trace1, trace2], layout=layout)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suppression neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Prev/Curr/Context</th>\n",
       "      <th>NNN</th>\n",
       "      <th>NNY</th>\n",
       "      <th>NYN</th>\n",
       "      <th>NYY</th>\n",
       "      <th>YNN</th>\n",
       "      <th>YNY</th>\n",
       "      <th>YYN</th>\n",
       "      <th>YYY</th>\n",
       "      <th>PrevTokenSim</th>\n",
       "      <th>CurrTokenSim</th>\n",
       "      <th>ContextSim</th>\n",
       "      <th>PosSim</th>\n",
       "      <th>NegSim</th>\n",
       "      <th>AblationDiff</th>\n",
       "      <th>And</th>\n",
       "      <th>NegAnd</th>\n",
       "      <th>Boosted</th>\n",
       "      <th>Deboosted</th>\n",
       "      <th>FullAblationLossIncrease</th>\n",
       "      <th>ContextAblationLossIncrease</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neuron</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.452348</td>\n",
       "      <td>-1.865411</td>\n",
       "      <td>-1.206139</td>\n",
       "      <td>-1.716999</td>\n",
       "      <td>-1.967061</td>\n",
       "      <td>-2.380259</td>\n",
       "      <td>-1.322760</td>\n",
       "      <td>-1.855663</td>\n",
       "      <td>-0.092576</td>\n",
       "      <td>0.017535</td>\n",
       "      <td>-0.060797</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.532903</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.004094</td>\n",
       "      <td>-0.005820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.041662</td>\n",
       "      <td>-1.186130</td>\n",
       "      <td>-1.242793</td>\n",
       "      <td>-1.350295</td>\n",
       "      <td>-1.351736</td>\n",
       "      <td>-1.422180</td>\n",
       "      <td>-1.183853</td>\n",
       "      <td>-1.149874</td>\n",
       "      <td>-0.031552</td>\n",
       "      <td>-0.006965</td>\n",
       "      <td>-0.008395</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.033978</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.001441</td>\n",
       "      <td>-0.000631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.127363</td>\n",
       "      <td>-2.293197</td>\n",
       "      <td>-0.955758</td>\n",
       "      <td>-1.091026</td>\n",
       "      <td>-1.940194</td>\n",
       "      <td>-2.136701</td>\n",
       "      <td>-0.773450</td>\n",
       "      <td>-0.983497</td>\n",
       "      <td>0.034648</td>\n",
       "      <td>0.081715</td>\n",
       "      <td>-0.074554</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.210047</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.002052</td>\n",
       "      <td>-0.000335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.090268</td>\n",
       "      <td>-1.259026</td>\n",
       "      <td>-2.459712</td>\n",
       "      <td>-2.098881</td>\n",
       "      <td>-1.240608</td>\n",
       "      <td>-1.239972</td>\n",
       "      <td>-2.479871</td>\n",
       "      <td>-2.146816</td>\n",
       "      <td>0.015636</td>\n",
       "      <td>-0.060014</td>\n",
       "      <td>-0.009209</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.333055</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.020078</td>\n",
       "      <td>-0.003826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.533762</td>\n",
       "      <td>0.919390</td>\n",
       "      <td>-0.291044</td>\n",
       "      <td>0.052384</td>\n",
       "      <td>0.248903</td>\n",
       "      <td>0.697211</td>\n",
       "      <td>-0.913438</td>\n",
       "      <td>-0.483871</td>\n",
       "      <td>-0.039145</td>\n",
       "      <td>-0.049453</td>\n",
       "      <td>0.035190</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.429567</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.063059</td>\n",
       "      <td>0.003769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Prev/Curr/Context       NNN       NNY       NYN       NYY       YNN       YNY  \\\n",
       "Neuron                                                                          \n",
       "0                 -1.452348 -1.865411 -1.206139 -1.716999 -1.967061 -2.380259   \n",
       "1                 -1.041662 -1.186130 -1.242793 -1.350295 -1.351736 -1.422180   \n",
       "2                 -2.127363 -2.293197 -0.955758 -1.091026 -1.940194 -2.136701   \n",
       "3                 -1.090268 -1.259026 -2.459712 -2.098881 -1.240608 -1.239972   \n",
       "4                  0.533762  0.919390 -0.291044  0.052384  0.248903  0.697211   \n",
       "\n",
       "Prev/Curr/Context       YYN       YYY  PrevTokenSim  CurrTokenSim  ContextSim  \\\n",
       "Neuron                                                                          \n",
       "0                 -1.322760 -1.855663     -0.092576      0.017535   -0.060797   \n",
       "1                 -1.183853 -1.149874     -0.031552     -0.006965   -0.008395   \n",
       "2                 -0.773450 -0.983497      0.034648      0.081715   -0.074554   \n",
       "3                 -2.479871 -2.146816      0.015636     -0.060014   -0.009209   \n",
       "4                 -0.913438 -0.483871     -0.039145     -0.049453    0.035190   \n",
       "\n",
       "Prev/Curr/Context  PosSim  NegSim  AblationDiff    And  NegAnd  Boosted  \\\n",
       "Neuron                                                                    \n",
       "0                   False    True     -0.532903  False   False    False   \n",
       "1                   False    True      0.033978  False   False    False   \n",
       "2                   False   False     -0.210047  False   False    False   \n",
       "3                   False    True      0.333055  False   False    False   \n",
       "4                   False   False      0.429567  False   False    False   \n",
       "\n",
       "Prev/Curr/Context  Deboosted  FullAblationLossIncrease  \\\n",
       "Neuron                                                   \n",
       "0                      False                 -0.004094   \n",
       "1                      False                 -0.001441   \n",
       "2                      False                  0.002052   \n",
       "3                      False                  0.020078   \n",
       "4                      False                 -0.063059   \n",
       "\n",
       "Prev/Curr/Context  ContextAblationLossIncrease  \n",
       "Neuron                                          \n",
       "0                                    -0.005820  \n",
       "1                                    -0.000631  \n",
       "2                                    -0.000335  \n",
       "3                                    -0.003826  \n",
       "4                                     0.003769  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look for neurons that deboost \"gen\" if \"orsch\" is not present\n",
    "option = \"orschlÃ¤gen\"\n",
    "df = pd.read_pickle(f\"data/and_neurons/df_{option}.pkl\") \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tried to stack head results when they weren't cached. Computing head results now\n"
     ]
    }
   ],
   "source": [
    "prompts = haystack_utils.generate_random_prompts(\"lÃ¤\", model, common_tokens, 100, length=20)\n",
    "logits, cache = model.run_with_cache(prompts)\n",
    "unembed_dir = model.tokens_to_residual_directions(\"gen\")\n",
    "resid_stack, labels = cache.get_full_resid_decomposition(apply_ln=True, pos_slice=-1, return_labels=True)\n",
    "crop = -2050, -2\n",
    "\n",
    "resid_stack = resid_stack.mean(1)[crop[0]:crop[1]]\n",
    "dla = resid_stack @ unembed_dir\n",
    "dla_df = pd.DataFrame({\"Neuron\": labels[crop[0]:crop[1]], \"NOT A DLA\": dla.tolist()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tried to stack head results when they weren't cached. Computing head results now\n"
     ]
    }
   ],
   "source": [
    "prompts = haystack_utils.generate_random_prompts(\"orschlÃ¤\", model, common_tokens, 100, length=20)\n",
    "logits, cache = model.run_with_cache(prompts)\n",
    "unembed_dir = model.tokens_to_residual_directions(\"gen\")\n",
    "resid_stack, labels = cache.get_full_resid_decomposition(apply_ln=True, pos_slice=-1, return_labels=True)\n",
    "\n",
    "resid_stack = resid_stack.mean(1)[crop[0]:crop[1]]\n",
    "dla = resid_stack @ unembed_dir\n",
    "dla_df[\"A DLA\"] = dla.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 tensor([  67,   73,   95,  111,  169,  198,  231,  286,  420,  445,  522,  570,\n",
      "         594,  681,  705,  749,  770,  827,  997, 1064, 1099, 1123, 1205, 1216,\n",
      "        1304, 1360, 1386, 1586, 1738, 1744, 1786, 1864, 1867, 1901, 1905, 1909,\n",
      "        1949, 1964, 1969])\n"
     ]
    }
   ],
   "source": [
    "dla_df[\"TurnedOff\"] = (dla_df[\"NOT A DLA\"]<-0.001) & (df[\"NYY\"]>0) & (dla_df[\"A DLA\"]>0) & (df[\"YYY\"]<df[\"NYY\"])\n",
    "neurons = dla_df[dla_df[\"TurnedOff\"]][\"Neuron\"].tolist()\n",
    "neurons = torch.LongTensor([int(neuron.split(\"N\")[1]) for neuron in neurons])\n",
    "print(len(neurons), neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>                            <div id=\"2a96bfb6-bfd0-44fd-80a9-fa73600910d1\" class=\"plotly-graph-div\" style=\"height:525px; width:1000px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"2a96bfb6-bfd0-44fd-80a9-fa73600910d1\")) {                    Plotly.newPlot(                        \"2a96bfb6-bfd0-44fd-80a9-fa73600910d1\",                        [{\"error_y\":{\"array\":[1.5670197602114506],\"type\":\"data\",\"visible\":true},\"name\":\"Original\",\"x\":[\"Original\"],\"y\":[1.4473304677340202],\"type\":\"bar\"},{\"error_y\":{\"array\":[1.7628359373927742],\"type\":\"data\",\"visible\":true},\"name\":\"NYY\",\"x\":[\"NYY\"],\"y\":[2.086745020035654],\"type\":\"bar\"},{\"error_y\":{\"array\":[1.603205940000963],\"type\":\"data\",\"visible\":true},\"name\":\"YNY\",\"x\":[\"YNY\"],\"y\":[1.5822080762479453],\"type\":\"bar\"},{\"error_y\":{\"array\":[1.5478954161076388],\"type\":\"data\",\"visible\":true},\"name\":\"YYN\",\"x\":[\"YYN\"],\"y\":[1.3778459606869147],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"Losses for patching 39 NOT A neurons with different ablation modes\"},\"xaxis\":{\"title\":{\"text\":\"\"}},\"yaxis\":{},\"barmode\":\"group\",\"width\":1000,\"showlegend\":true},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('2a96bfb6-bfd0-44fd-80a9-fa73600910d1');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def compute_counterfactual_losses(prompts, df, neurons):\n",
    "    losses = [model(prompts, return_type=\"loss\", loss_per_token=True)[:, -1].tolist()]\n",
    "    ablations = [\"NYY\", \"YNY\", \"YYN\"]\n",
    "    names = [\"Original\"] + ablations\n",
    "    for ablation_mode in ablations:\n",
    "        ablated_loss = compute_mlp_loss(prompts, df, neurons, ablate_mode=ablation_mode, mean=False)\n",
    "        losses.append(ablated_loss)\n",
    "    return losses, names\n",
    "\n",
    "prompts = haystack_utils.generate_random_prompts(\"orschlÃ¤gen\", model, common_tokens, 1000, length=20)\n",
    "losses, names = compute_counterfactual_losses(prompts, df, neurons)#torch.LongTensor([i for i in range(100)]))\n",
    "plotting_utils.plot_barplot(losses, names, title=\"Losses for patching 39 NOT A neurons with different ablation modes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
