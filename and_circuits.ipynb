{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from transformer_lens import HookedTransformer, ActivationCache, utils, patching\n",
    "from jaxtyping import Float, Int, Bool\n",
    "from torch import Tensor\n",
    "from tqdm.auto import tqdm\n",
    "import plotly.io as pio\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "pio.renderers.default = \"notebook_connected\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.autograd.set_grad_enabled(False)\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "from haystack_utils import get_mlp_activations\n",
    "import haystack_utils\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model EleutherAI/pythia-70m into HookedTransformer\n",
      "data/german_europarl.json: Loaded 2000 examples with 152 to 2000 characters each.\n",
      "data/english_europarl.json: Loaded 2000 examples with 165 to 2000 characters each.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60fdc309cc704f2e9bf22ce7ee3ea187",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bec930de7a454e74928e18334870d356",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/german_europarl.json: Loaded 2000 examples with 152 to 2000 characters each.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0ac29d7546f40cd9eccf568052e0b87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ngram = \"orschlägen\"\n",
    "model = HookedTransformer.from_pretrained(\"EleutherAI/pythia-70m\",\n",
    "    center_unembed=True,\n",
    "    center_writing_weights=True,\n",
    "    fold_ln=True,\n",
    "    device=device)\n",
    "\n",
    "activate_neurons_fwd_hooks, deactivate_neurons_fwd_hooks = haystack_utils.get_context_ablation_hooks(3, [669], model)\n",
    "all_ignore, _ = haystack_utils.get_weird_tokens(model, plot_norms=False)\n",
    "\n",
    "german_data = haystack_utils.load_json_data(\"data/german_europarl.json\")[:200]\n",
    "common_tokens = haystack_utils.get_common_tokens(german_data, model, all_ignore, k=100)\n",
    "\n",
    "# Sort tokens into new word vs continuation\n",
    "new_word_tokens = []\n",
    "continuation_tokens = []\n",
    "for token in common_tokens:\n",
    "    str_token = model.to_single_str_token(token.item())\n",
    "    if str_token.startswith(\" \"):\n",
    "        new_word_tokens.append(token)\n",
    "    else:\n",
    "        continuation_tokens.append(token)\n",
    "new_word_tokens = torch.stack(new_word_tokens)\n",
    "continuation_tokens = torch.stack(continuation_tokens)\n",
    "\n",
    "context_direction = model.W_out[3, 669, :]\n",
    "\n",
    "def get_cosine_sim(direction: Float[Tensor, \"d_res\"], layer=5) -> Float[Tensor, \"d_mlp\"]:\n",
    "    cosine = torch.nn.CosineSimilarity(dim=1)\n",
    "    return cosine(model.W_in[layer].T, direction.unsqueeze(0))\n",
    "\n",
    "def plot_histogram(t1, t2, t3, name1, name2, name3):\n",
    "    t1 = t1.cpu().numpy()\n",
    "    t2 = t2.cpu().numpy()\n",
    "    t3 = t3.cpu().numpy()\n",
    "    fig = go.Figure()\n",
    "    bin_width= 0.01\n",
    "    fig.add_trace(go.Histogram(x=t1, name=name1, opacity=0.5, histnorm='probability density', xbins=dict(size=bin_width)))\n",
    "    fig.add_trace(go.Histogram(x=t2, name=name2, opacity=0.5 , histnorm='probability density', xbins=dict(size=bin_width)))\n",
    "    fig.add_trace(go.Histogram(x=t3, name=name3, opacity=0.5, histnorm='probability density', xbins=dict(size=bin_width)))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=\"Individual MLP5 similarities to direction vectors\",\n",
    "        xaxis_title=\"Cosine Similarity\",\n",
    "        yaxis_title=\"Probability Density\",\n",
    "        barmode=\"overlay\",\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "def compute_mlp_loss(prompts, df, neurons, ablate_mode=\"NNN\", layer=5, compute_original_loss=False):\n",
    "\n",
    "    mean_activations = torch.Tensor(df[df.index.isin(neurons.tolist())][ablate_mode].tolist()).cuda()\n",
    "    def ablate_mlp_hook(value, hook):\n",
    "        value[:, :, neurons] = mean_activations\n",
    "        return value\n",
    "\n",
    "    with model.hooks(fwd_hooks=[(f\"blocks.{layer}.mlp.hook_pre\", ablate_mlp_hook)]):\n",
    "        ablated_loss = model(prompts, return_type=\"loss\", loss_per_token=True)[:, -1].mean().item()\n",
    "\n",
    "    if compute_original_loss:\n",
    "        loss = model(prompts, return_type=\"loss\", loss_per_token=True)[:, -1].mean().item()\n",
    "        return loss, ablated_loss\n",
    "    return ablated_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss change for different AND thresholds\n",
    "option = \"orschlägen\"\n",
    "df = pd.read_pickle(f\"data/and_neurons/df_{option}.pkl\") \n",
    "\n",
    "with open(f\"data/and_neurons/set_losses.json\", \"r\") as f:\n",
    "    all_losses = json.load(f)\n",
    "\n",
    "prompts = haystack_utils.generate_random_prompts(option, model, common_tokens, 2000, length=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_token = model.to_single_token(\"gen\")\n",
    "ge_token = model.to_single_token(\"ge\")\n",
    "gen_dir = model.tokens_to_residual_directions(gen_token)\n",
    "ge_dir = model.tokens_to_residual_directions(ge_token)\n",
    "\n",
    "cos = torch.nn.CosineSimilarity(dim=1)\n",
    "gen_sims = cos(model.W_out[5], gen_dir.unsqueeze(0)).cpu().numpy()\n",
    "ge_sims = cos(model.W_out[5], ge_dir.unsqueeze(0)).cpu().numpy()\n",
    "\n",
    "df[\"GenSim\"] = gen_sims\n",
    "df[\"GeSim\"] = ge_sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prev/Curr/Context\n",
      "AblationDiff    0.434787\n",
      "GenSim          0.002992\n",
      "GeSim          -0.000410\n",
      "dtype: float64\n",
      "Prev/Curr/Context\n",
      "AblationDiff   -0.431541\n",
      "GenSim          0.000029\n",
      "GeSim           0.004855\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df[df[\"AblationDiff\"]>0.2][[\"AblationDiff\", \"GenSim\", \"GeSim\"]].mean())\n",
    "print(df[df[\"AblationDiff\"]<-0.2][[\"AblationDiff\", \"GenSim\", \"GeSim\"]].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102\n",
      "1.3597999811172485 7.807448387145996\n"
     ]
    }
   ],
   "source": [
    "df_tmp = df.copy()\n",
    "ablation_mode = \"YYN\"\n",
    "\n",
    "df_tmp[\"Custom\"] = (df[\"YYY\"]>0) & (df[\"YYY\"]>df[\"NNN\"]) & (df[\"GenSim\"]>df[\"GeSim\"]) &\\\n",
    "    (df[\"YYY\"]>df[\"YYN\"]) & (df[\"YYY\"]>df[\"YNY\"]) & (df[\"YYY\"]>df[\"NYY\"]) &\\\n",
    "    (df[\"YYY\"]>df[\"NYN\"]) & (df[\"YYY\"]>df[\"NNY\"]) & (df[\"YYY\"]>df[\"YNN\"])# & df[\"PosSim\"]\n",
    "\n",
    "print(df_tmp[\"Custom\"].sum())\n",
    "pos_and_neurons = torch.LongTensor(df_tmp[df_tmp[\"Custom\"]].index.tolist()).cuda()\n",
    "\n",
    "#df_tmp[\"context_diff\"] = df_tmp[\"YYY\"] - df_tmp[\"YYN\"]\n",
    "#df_tmp = df_tmp.sort_values(by=[\"Custom\", \"context_diff\"], ascending=False)\n",
    "#pos_and_neurons = torch.LongTensor(df_tmp.index.tolist()[:30]).cuda()\n",
    "\n",
    "original_loss, ablated_loss = compute_mlp_loss(prompts, df, pos_and_neurons, ablate_mode=ablation_mode, compute_original_loss=True)\n",
    "print(original_loss, ablated_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prev/Curr/Context       NNN       NNY       NYN       NYY       YNN       YNY  \\\n",
      "Neuron                                                                          \n",
      "1465              -1.277869 -1.019137 -0.905179 -0.300349 -1.394603 -1.053455   \n",
      "1358              -1.104955 -1.179201 -0.195454 -0.120755 -1.119429 -1.094314   \n",
      "1200              -0.829713 -0.470205 -0.556886 -0.056243 -0.733147 -0.353565   \n",
      "81                -0.310923 -0.104064 -0.721332 -0.287294 -0.251633 -0.030125   \n",
      "1941              -0.863015 -0.613759 -0.582438 -0.229563 -0.845546 -0.528548   \n",
      "\n",
      "Prev/Curr/Context       YYN       YYY  PrevTokenSim  CurrTokenSim  ...  \\\n",
      "Neuron                                                             ...   \n",
      "1465              -0.690183  0.016683     -0.003766      0.042618  ...   \n",
      "1358              -0.415016  0.054841      0.020853      0.061688  ...   \n",
      "1200              -0.296196  0.123117      0.025034      0.029998  ...   \n",
      "81                -0.360566  0.021360      0.016521     -0.013888  ...   \n",
      "1941              -0.155905  0.225665      0.012176      0.030613  ...   \n",
      "\n",
      "Prev/Curr/Context  NegSim  AblationDiff   And  NegAnd  Boosted  Deboosted  \\\n",
      "Neuron                                                                      \n",
      "1465                False      0.706866  True   False    False      False   \n",
      "1358                False      0.469857  True   False    False      False   \n",
      "1200                False      0.419313  True   False     True      False   \n",
      "81                  False      0.381926  True   False    False      False   \n",
      "1941                False      0.381570  True   False     True      False   \n",
      "\n",
      "Prev/Curr/Context  FullAblationLossIncrease  ContextAblationLossIncrease  \\\n",
      "Neuron                                                                     \n",
      "1465                              -0.032043                    -0.040317   \n",
      "1358                               0.019140                     0.018410   \n",
      "1200                               0.001772                     0.000891   \n",
      "81                                -0.009052                    -0.009581   \n",
      "1941                              -0.025031                    -0.016533   \n",
      "\n",
      "Prev/Curr/Context  Custom  context_diff  \n",
      "Neuron                                   \n",
      "1465                 True      0.706866  \n",
      "1358                 True      0.469857  \n",
      "1200                 True      0.419313  \n",
      "81                   True      0.381926  \n",
      "1941                 True      0.381570  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "20\n",
      "1.3597999811172485 1.3272414207458496\n"
     ]
    }
   ],
   "source": [
    "df_tmp = df.copy()\n",
    "and_threshold=0.8\n",
    "ablation_mode = \"YYN\"\n",
    "df_tmp[\"Custom\"] = (df[\"YYY\"]>0) & \\\n",
    "    (df[\"YYN\"]<df[\"YYY\"]) & (df[\"YNY\"]<df[\"YYY\"]) & \\\n",
    "    (df[\"NYY\"]<df[\"YYY\"]) & (df[\"YNN\"]<df[\"YYY\"]) & \\\n",
    "    (df[\"NNY\"]<df[\"YYY\"]) & (df[\"NYN\"]<df[\"YYY\"])\n",
    "\n",
    "df_tmp[\"context_diff\"] = df_tmp[\"YYY\"] - df_tmp[\"YYN\"]\n",
    "pos_and_neurons = torch.LongTensor(df_tmp[df_tmp[\"Custom\"]].index.tolist()).cuda()\n",
    "df_tmp = df_tmp.sort_values(by=[\"And\", \"context_diff\"], ascending=False)\n",
    "pos_and_neurons = torch.LongTensor(df_tmp.index.tolist()[:20]).cuda()\n",
    "print(df_tmp.head())\n",
    "print(len(pos_and_neurons))\n",
    "original_loss, ablated_loss = compute_mlp_loss(prompts, df, pos_and_neurons, ablate_mode=ablation_mode, compute_original_loss=True)\n",
    "print(original_loss, ablated_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "\n",
    "option = \"orschlägen\"\n",
    "ablation_mode = \"YYN\"\n",
    "prompts = haystack_utils.generate_random_prompts(option, model, common_tokens, 1000, length=20)\n",
    "\n",
    "names = list(all_losses[option][ablation_mode].keys())\n",
    "losses = [[all_losses[option][ablation_mode][name]] for name in names]\n",
    "\n",
    "print(len(names), len(losses))\n",
    "print([len(x) for x in losses])\n",
    "haystack_utils.plot_barplot(losses, names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "layer = 2\n",
    "ngram = \"orschlägen\"\n",
    "prompts = haystack_utils.generate_random_prompts(ngram, model, common_tokens, 500, length=20)\n",
    "\n",
    "if ngram.startswith(\" \"):\n",
    "    prompt_tuple = haystack_utils.get_trigram_prompts(prompts, new_word_tokens, continuation_tokens)\n",
    "else:\n",
    "    prompt_tuple = haystack_utils.get_trigram_prompts(prompts, continuation_tokens, continuation_tokens)\n",
    "prev_token_direction, curr_token_direction = haystack_utils.get_residual_trigram_directions(prompt_tuple, model, layer-1)\n",
    "\n",
    "prev_token_sim = get_cosine_sim(prev_token_direction, layer)\n",
    "curr_token_sim = get_cosine_sim(curr_token_direction, layer)\n",
    "context_sim = get_cosine_sim(context_direction, layer)\n",
    "\n",
    "plot_histogram(prev_token_sim, curr_token_sim, context_sim, \"Prev Token\", \"Curr Token\", \"Context\")\n",
    "# %%\n",
    "prev_sim_neurons = torch.argwhere(prev_token_sim>0.05)\n",
    "curr_sim_neurons = torch.argwhere(curr_token_sim>0.03)\n",
    "\n",
    "print(len(prev_sim_neurons), len(curr_sim_neurons))\n",
    "union = haystack_utils.union_where([prev_token_sim, curr_token_sim], 0.07)\n",
    "print(union)\n",
    "# %%\n",
    "\n",
    "# Get random mean cache\n",
    "random_prompts = haystack_utils.generate_random_prompts(ngram, model, common_tokens, 500, length=20)[:, :-3]\n",
    "_, random_cache = model.run_with_cache(random_prompts)\n",
    "\n",
    "\n",
    "# %%\n",
    "# Define ablate neuron hook\n",
    "\n",
    "# Layer 1\n",
    "# orschlägen: tensor([  61,  188, 1011], device='cuda:0')\n",
    "# häufig: 268 (almost doubles loss)\n",
    "# beweglich: neurons decrease loss - maybe they boost alternative completion\n",
    "\n",
    "def get_ablate_neurons_hook(neurons, layer):\n",
    "    print(neurons)\n",
    "    def ablate_neurons_hook(value, hook):\n",
    "        value[:, :, neurons] = random_cache[f'blocks.{layer}.mlp.hook_post'][:, :, neurons].mean((0, 1))\n",
    "        return value\n",
    "    return [(f'blocks.{layer}.mlp.hook_post', ablate_neurons_hook)]\n",
    "\n",
    "# Check loss increase\n",
    "original_loss, original_ablated_loss = compute_mlp_loss(prompts, df, torch.LongTensor([i for i in range(model.cfg.d_mlp)]).cuda(), compute_original_loss=True)\n",
    "\n",
    "with model.hooks(fwd_hooks=get_ablate_neurons_hook([1789], layer)):\n",
    "    ablated_loss = model(prompts, return_type=\"loss\", loss_per_token=True)[:, -1].mean().item()\n",
    "\n",
    "print(original_loss, original_ablated_loss, ablated_loss)\n",
    "# %%\n",
    "\n",
    "# 1011 increases loss on both \"gen\" and \"ge\"\n",
    "# Either it boosts both completions (trigram table)\n",
    "# Or it combines \"orsch\" and \"lä\" into a single representation that later components use\n",
    "\n",
    "# Check if trigram table by looking at the direct effect\n",
    "# Total effect of L1N1011\n",
    "with model.hooks(fwd_hooks=get_ablate_neurons_hook([1406], layer)):\n",
    "    _, ablated_cache = model.run_with_cache(prompts)\n",
    "\n",
    "def ablate_component_hook(value, hook):\n",
    "    value = ablated_cache[hook.name]\n",
    "    return value\n",
    "\n",
    "components = [f\"blocks.{layer}.mlp.hook_post\" for layer in range(3, 6)] + [f\"blocks.{layer}.attn.hook_z\" for layer in range(3, 6)]\n",
    "hooks = [(component, ablate_component_hook) for component in components]\n",
    "\n",
    "with model.hooks(fwd_hooks=hooks):\n",
    "    ablated_logits = model(prompts, return_type=\"logits\", loss_per_token=True)[:, -2].log_softmax(-1).mean(0)\n",
    "\n",
    "original_logits = model(prompts, return_type=\"logits\", loss_per_token=True)[:, -2].log_softmax(-1).mean(0)\n",
    "\n",
    "print(ablated_logits.shape, original_logits.shape)\n",
    "\n",
    "prob_diff = original_logits - ablated_logits\n",
    "prob_diff[all_ignore] = 0\n",
    "prob_diff[original_logits < -7] = 0\n",
    "diffs, tokens = torch.topk(prob_diff, 20)\n",
    "print(diffs)\n",
    "print(tokens)\n",
    "print(model.to_str_tokens(tokens))\n",
    "\n",
    "# %% \n",
    "# Direct effect\n",
    "_, original_cache = model.run_with_cache(prompts)\n",
    "\n",
    "def activate_component_hook(value, hook):\n",
    "    value = original_cache[hook.name]\n",
    "    return value\n",
    "\n",
    "activate_hooks = [(component, activate_component_hook) for component in components]\n",
    "\n",
    "with model.hooks(fwd_hooks=activate_hooks + get_ablate_neurons_hook([1406], layer)):\n",
    "    activated_logits = model(prompts, return_type=\"logits\", loss_per_token=True)[:, -2].log_softmax(-1).mean(0)\n",
    "\n",
    "prob_diff = original_logits - activated_logits\n",
    "prob_diff[all_ignore] = 0\n",
    "prob_diff[original_logits < -7] = 0\n",
    "diffs, tokens = torch.topk(prob_diff, 20)\n",
    "print(diffs)\n",
    "print(tokens)\n",
    "print(model.to_str_tokens(tokens))\n",
    "\n",
    "# Check later components + context neuron effects of 1011\n",
    "# %%\n",
    "\n",
    "#output_direction = model.W_out[1, 1011]\n",
    "output_direction = model.W_out[2, 1406]\n",
    "context_direction = model.W_out[3, 669]\n",
    "\n",
    "output_sims = get_cosine_sim(output_direction, 5)\n",
    "context_sims = get_cosine_sim(context_direction, 5)\n",
    "\n",
    "plot_histogram(output_sims, context_sims, torch.zeros_like(output_sims), \"Output\", \"Context\", \"Zero\")\n",
    "# %%\n",
    "union = haystack_utils.union_where([output_sims, context_sims], 0.05)\n",
    "len(union)\n",
    "# %%\n",
    "ngram = \"orschlägen\"\n",
    "prompts = haystack_utils.generate_random_prompts(ngram, model, common_tokens, 1000, length=20)\n",
    "\n",
    "original_loss, original_ablated_loss = compute_mlp_loss(prompts, df, torch.LongTensor([i for i in range(model.cfg.d_mlp)]).cuda(), compute_original_loss=True)\n",
    "\n",
    "with model.hooks(fwd_hooks=get_ablate_neurons_hook(union, 5)): #712, 394, 287\n",
    "    ablated_loss = model(prompts, return_type=\"loss\", loss_per_token=True)[:, -1].mean().item()\n",
    "\n",
    "print(original_loss, original_ablated_loss, ablated_loss)\n",
    "# %%\n",
    "ngram = \" meine Vorschläge\"\n",
    "prompts = haystack_utils.generate_random_prompts(ngram, model, common_tokens, 1000, length=20)\n",
    "original_loss, original_ablated_loss = compute_mlp_loss(prompts, df, torch.LongTensor([i for i in range(model.cfg.d_mlp)]).cuda(), compute_original_loss=True)\n",
    "print(original_loss, original_ablated_loss)\n",
    "# %%\n",
    "model.to_str_tokens(model.to_tokens(\" deinen Vorschläge\", prepend_bos=False))\n",
    "# %%\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
