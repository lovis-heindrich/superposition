{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from transformer_lens import HookedTransformer, ActivationCache, utils, patching\n",
    "from jaxtyping import Float, Int, Bool\n",
    "from torch import Tensor\n",
    "from tqdm.auto import tqdm\n",
    "import plotly.io as pio\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "pio.renderers.default = \"notebook_connected\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.autograd.set_grad_enabled(False)\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "from haystack_utils import get_mlp_activations\n",
    "import haystack_utils\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "217b5ce247104eb99db0802675147f9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/567 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f38d92d9161490c99de0380d7bd0f3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/166M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60aadf9adfdb42b3a40ebe8957b8a3ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/396 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0afd911d46544489c590cad5e05e54d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a57cf5c5b77402d806535b19e3c8b25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model EleutherAI/pythia-70m into HookedTransformer\n",
      "data/german_europarl.json: Loaded 2000 examples with 152 to 2000 characters each.\n",
      "data/english_europarl.json: Loaded 2000 examples with 165 to 2000 characters each.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bcf23335f2e457cbe1ee2f93c3827d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e584e286818e4a7aa1ba82c436c9721f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/german_europarl.json: Loaded 2000 examples with 152 to 2000 characters each.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "918702307f1b4ae98b3611076eb64cd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ngram = \"orschlägen\"\n",
    "model = HookedTransformer.from_pretrained(\"EleutherAI/pythia-70m\",\n",
    "    center_unembed=True,\n",
    "    center_writing_weights=True,\n",
    "    fold_ln=True,\n",
    "    device=device)\n",
    "\n",
    "activate_neurons_fwd_hooks, deactivate_neurons_fwd_hooks = haystack_utils.get_context_ablation_hooks(3, [669], model)\n",
    "all_ignore, _ = haystack_utils.get_weird_tokens(model, plot_norms=False)\n",
    "\n",
    "german_data = haystack_utils.load_json_data(\"data/german_europarl.json\")[:200]\n",
    "common_tokens = haystack_utils.get_common_tokens(german_data, model, all_ignore, k=100)\n",
    "\n",
    "# Sort tokens into new word vs continuation\n",
    "new_word_tokens = []\n",
    "continuation_tokens = []\n",
    "for token in common_tokens:\n",
    "    str_token = model.to_single_str_token(token.item())\n",
    "    if str_token.startswith(\" \"):\n",
    "        new_word_tokens.append(token)\n",
    "    else:\n",
    "        continuation_tokens.append(token)\n",
    "new_word_tokens = torch.stack(new_word_tokens)\n",
    "continuation_tokens = torch.stack(continuation_tokens)\n",
    "\n",
    "context_direction = model.W_out[3, 669, :]\n",
    "\n",
    "def get_cosine_sim(direction: Float[Tensor, \"d_res\"], layer=5) -> Float[Tensor, \"d_mlp\"]:\n",
    "    cosine = torch.nn.CosineSimilarity(dim=1)\n",
    "    return cosine(model.W_in[layer].T, direction.unsqueeze(0))\n",
    "\n",
    "def plot_histogram(t1, t2, t3, name1, name2, name3):\n",
    "    t1 = t1.cpu().numpy()\n",
    "    t2 = t2.cpu().numpy()\n",
    "    t3 = t3.cpu().numpy()\n",
    "    fig = go.Figure()\n",
    "    bin_width= 0.01\n",
    "    fig.add_trace(go.Histogram(x=t1, name=name1, opacity=0.5, histnorm='probability density', xbins=dict(size=bin_width)))\n",
    "    fig.add_trace(go.Histogram(x=t2, name=name2, opacity=0.5 , histnorm='probability density', xbins=dict(size=bin_width)))\n",
    "    fig.add_trace(go.Histogram(x=t3, name=name3, opacity=0.5, histnorm='probability density', xbins=dict(size=bin_width)))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=\"Individual MLP5 similarities to direction vectors\",\n",
    "        xaxis_title=\"Cosine Similarity\",\n",
    "        yaxis_title=\"Probability Density\",\n",
    "        barmode=\"overlay\",\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "def compute_mlp_loss(prompts, df, neurons, ablate_mode=\"NNN\", layer=5, compute_original_loss=False):\n",
    "\n",
    "    mean_activations = torch.Tensor(df[df.index.isin(neurons.tolist())][ablate_mode].tolist()).cuda()\n",
    "    def ablate_mlp_hook(value, hook):\n",
    "        value[:, :, neurons] = mean_activations\n",
    "        return value\n",
    "\n",
    "    with model.hooks(fwd_hooks=[(f\"blocks.{layer}.mlp.hook_pre\", ablate_mlp_hook)]):\n",
    "        ablated_loss = model(prompts, return_type=\"loss\", loss_per_token=True)[:, -1].mean().item()\n",
    "\n",
    "    if compute_original_loss:\n",
    "        loss = model(prompts, return_type=\"loss\", loss_per_token=True)[:, -1].mean().item()\n",
    "        return loss, ablated_loss\n",
    "    return ablated_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss change for different AND thresholds\n",
    "option = \"orschlägen\"\n",
    "df = pd.read_pickle(f\"data/and_neurons/df_{option}.pkl\") \n",
    "\n",
    "with open(f\"data/and_neurons/set_losses.json\", \"r\") as f:\n",
    "    all_losses = json.load(f)\n",
    "\n",
    "prompts = haystack_utils.generate_random_prompts(option, model, common_tokens, 500, length=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_token = model.to_single_token(\"gen\")\n",
    "ge_token = model.to_single_token(\"ge\")\n",
    "gen_dir = model.tokens_to_residual_directions(gen_token)\n",
    "ge_dir = model.tokens_to_residual_directions(ge_token)\n",
    "\n",
    "cos = torch.nn.CosineSimilarity(dim=1)\n",
    "gen_sims = cos(model.W_out[5], gen_dir.unsqueeze(0)).cpu().numpy()\n",
    "ge_sims = cos(model.W_out[5], ge_dir.unsqueeze(0)).cpu().numpy()\n",
    "\n",
    "df[\"GenSim\"] = gen_sims\n",
    "df[\"GeSim\"] = ge_sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3292, device='cuda:0')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how similar gen and ge dirs are\n",
    "cos = torch.nn.CosineSimilarity(dim=0)\n",
    "cos(gen_dir, ge_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global logprob effect from context neuron\n",
    "\n",
    "original_logprobs = model(prompts, return_type=\"logprob\", loss_per_token=True)[:, -1].cpu().numpy()\n",
    "with model.hooks(fwd_hooks=deactivate_neurons_fwd_hooks):\n",
    "    deactivated_logprobs = model(prompts, return_type=\"logprob\", loss_per_token=True)[:, -1].cpu().numpy()\n",
    "\n",
    "logprob_diffs = deactivated_logprobs - original_logprobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prev/Curr/Context\n",
      "AblationDiff    0.434787\n",
      "GenSim          0.002992\n",
      "GeSim          -0.000410\n",
      "dtype: float64\n",
      "Prev/Curr/Context\n",
      "AblationDiff   -0.431541\n",
      "GenSim          0.000029\n",
      "GeSim           0.004855\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df[df[\"AblationDiff\"]>0.2][[\"AblationDiff\", \"GenSim\", \"GeSim\"]].mean())\n",
    "print(df[df[\"AblationDiff\"]<-0.2][[\"AblationDiff\", \"GenSim\", \"GeSim\"]].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102\n",
      "1.4382295608520508 7.869058609008789\n"
     ]
    }
   ],
   "source": [
    "df_tmp = df.copy()\n",
    "ablation_mode = \"YYN\"\n",
    "\n",
    "df_tmp[\"Custom\"] = (df[\"YYY\"]>0) & (df[\"YYY\"]>df[\"NNN\"]) & (df[\"GenSim\"]>df[\"GeSim\"]) &\\\n",
    "    (df[\"YYY\"]>df[\"YYN\"]) & (df[\"YYY\"]>df[\"YNY\"]) & (df[\"YYY\"]>df[\"NYY\"]) &\\\n",
    "    (df[\"YYY\"]>df[\"NYN\"]) & (df[\"YYY\"]>df[\"NNY\"]) & (df[\"YYY\"]>df[\"YNN\"])# & df[\"PosSim\"]\n",
    "\n",
    "print(df_tmp[\"Custom\"].sum())\n",
    "pos_and_neurons = torch.LongTensor(df_tmp[df_tmp[\"Custom\"]].index.tolist()).cuda()\n",
    "\n",
    "#df_tmp[\"context_diff\"] = df_tmp[\"YYY\"] - df_tmp[\"YYN\"]\n",
    "#df_tmp = df_tmp.sort_values(by=[\"Custom\", \"context_diff\"], ascending=False)\n",
    "#pos_and_neurons = torch.LongTensor(df_tmp.index.tolist()[:30]).cuda()\n",
    "\n",
    "original_loss, ablated_loss = compute_mlp_loss(prompts, df, pos_and_neurons, ablate_mode=ablation_mode, compute_original_loss=True)\n",
    "print(original_loss, ablated_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "haystack_utils.clean_cache()\n",
    "prompts = haystack_utils.generate_random_prompts(option, model, common_tokens, 500, length=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2064943313598633\n"
     ]
    }
   ],
   "source": [
    "with model.hooks(fwd_hooks=deactivate_neurons_fwd_hooks):\n",
    "    deactivated_loss, cache = model.run_with_cache(prompts, return_type=\"loss\", loss_per_token=True)\n",
    "\n",
    "#cache = cache[\"blocks.5.mlp.hook_pre\"][:, -2].mean(0)\n",
    "print(deactivated_loss[:, -1].mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 23, 2048])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cache[\"post\", 5].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.4382295608520508, 5.653645992279053)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_mlp_loss(prompts, df, torch.LongTensor([i for i in range(2048)]), \"YYN\", compute_original_loss=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_activations_df = torch.Tensor(df[df.index.isin([i for i in range(2048)])][\"YYN\"].tolist()).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2048]) torch.Size([2048])\n",
      "tensor([-1.3228, -1.1839, -0.7734, -2.4799, -0.9134, -0.9777, -1.1465, -1.8528,\n",
      "        -0.9403, -0.6645], device='cuda:0')\n",
      "tensor([-1.3351, -1.1835, -0.7855, -2.4714, -0.9022, -0.9851, -1.1769, -1.8635,\n",
      "        -0.9359, -0.6646], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(mean_activations_df.shape, cache.shape)\n",
    "print(mean_activations_df[:10])\n",
    "print(cache[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>                            <div id=\"b6962c43-1eae-4a74-beac-6ce60d91ec27\" class=\"plotly-graph-div\" style=\"height:525px; width:1000px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"b6962c43-1eae-4a74-beac-6ce60d91ec27\")) {                    Plotly.newPlot(                        \"b6962c43-1eae-4a74-beac-6ce60d91ec27\",                        [{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"Original\",\"x\":[\"Original\"],\"y\":[1.4382295608520508],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND -0.50 (22)\",\"x\":[\"AND -0.50 (22)\"],\"y\":[1.4031965732574463],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND -0.40 (14)\",\"x\":[\"AND -0.40 (14)\"],\"y\":[1.4982680082321167],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND -0.30 (14)\",\"x\":[\"AND -0.30 (14)\"],\"y\":[1.4405291080474854],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND -0.20 (20)\",\"x\":[\"AND -0.20 (20)\"],\"y\":[1.4521732330322266],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND -0.10 (17)\",\"x\":[\"AND -0.10 (17)\"],\"y\":[1.5765925645828247],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND -0.00 (21)\",\"x\":[\"AND -0.00 (21)\"],\"y\":[1.4966233968734741],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND 0.10 (12)\",\"x\":[\"AND 0.10 (12)\"],\"y\":[1.3823171854019165],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND 0.20 (21)\",\"x\":[\"AND 0.20 (21)\"],\"y\":[1.4386775493621826],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND 0.30 (21)\",\"x\":[\"AND 0.30 (21)\"],\"y\":[1.232452392578125],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND 0.40 (19)\",\"x\":[\"AND 0.40 (19)\"],\"y\":[1.3736011981964111],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND 0.50 (20)\",\"x\":[\"AND 0.50 (20)\"],\"y\":[1.422939419746399],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND 0.60 (21)\",\"x\":[\"AND 0.60 (21)\"],\"y\":[1.4341751337051392],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND 0.70 (21)\",\"x\":[\"AND 0.70 (21)\"],\"y\":[1.778494954109192],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND 0.80 (19)\",\"x\":[\"AND 0.80 (19)\"],\"y\":[1.6555122137069702],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND 0.90 (19)\",\"x\":[\"AND 0.90 (19)\"],\"y\":[1.272355318069458],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND 1.00 (16)\",\"x\":[\"AND 1.00 (16)\"],\"y\":[1.8343677520751953],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND 1.10 (16)\",\"x\":[\"AND 1.10 (16)\"],\"y\":[1.6646665334701538],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND 1.20 (16)\",\"x\":[\"AND 1.20 (16)\"],\"y\":[1.8627641201019287],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND 1.30 (14)\",\"x\":[\"AND 1.30 (14)\"],\"y\":[1.8179941177368164],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND 1.40 (8)\",\"x\":[\"AND 1.40 (8)\"],\"y\":[1.6051018238067627],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND 1.50 (4)\",\"x\":[\"AND 1.50 (4)\"],\"y\":[1.3911800384521484],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND 1.60 (5)\",\"x\":[\"AND 1.60 (5)\"],\"y\":[1.8147002458572388],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND 1.70 (5)\",\"x\":[\"AND 1.70 (5)\"],\"y\":[2.058548927307129],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND 1.80 (3)\",\"x\":[\"AND 1.80 (3)\"],\"y\":[1.6896328926086426],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND 1.90 (3)\",\"x\":[\"AND 1.90 (3)\"],\"y\":[1.506465196609497],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"AND neuron loss increase for different thresholds\"},\"xaxis\":{\"title\":{\"text\":\"\"}},\"yaxis\":{\"title\":{\"text\":\"\"}},\"barmode\":\"group\",\"width\":1000,\"showlegend\":true},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('b6962c43-1eae-4a74-beac-6ce60d91ec27');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# And thresholds without similarity constraint\n",
    "prompts = haystack_utils.generate_random_prompts(option, model, common_tokens, 2000, length=20)\n",
    "losses = []\n",
    "lens =  []\n",
    "thresholds = []\n",
    "for and_threshold in np.arange(-0.5, 2, 0.1):\n",
    "    df_tmp = df.copy()\n",
    "    ablation_mode = \"YYN\"\n",
    "    df_tmp[\"Custom\"] = (df[\"YYY\"]>and_threshold) & (df[\"YYN\"]<=and_threshold) & (df[\"YNY\"]<=and_threshold) & (df[\"NYY\"]<=and_threshold) & (df[\"YNN\"]<=and_threshold) & (df[\"NNY\"]<=and_threshold)& (df[\"NYN\"]<=and_threshold)\n",
    "    pos_and_neurons = torch.LongTensor(df_tmp[df_tmp[\"Custom\"]].index.tolist()).cuda()\n",
    "\n",
    "    original_loss, ablated_loss = compute_mlp_loss(prompts, df, pos_and_neurons, ablate_mode=ablation_mode, compute_original_loss=True)\n",
    "    if len(losses) == 0:\n",
    "        losses.append([original_loss])\n",
    "    losses.append([ablated_loss])\n",
    "    lens.append(len(pos_and_neurons))\n",
    "    thresholds.append(and_threshold)\n",
    "names = [\"Original\"] + [f\"AND {thr:.2f} ({length})\" for thr, length in zip(thresholds, lens)]\n",
    "haystack_utils.plot_barplot(losses, names, title=\"AND neuron loss increase for different thresholds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>                            <div id=\"99af98eb-a217-47c8-97dc-6d5ab64346ca\" class=\"plotly-graph-div\" style=\"height:525px; width:1000px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"99af98eb-a217-47c8-97dc-6d5ab64346ca\")) {                    Plotly.newPlot(                        \"99af98eb-a217-47c8-97dc-6d5ab64346ca\",                        [{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"Original\",\"x\":[\"Original\"],\"y\":[1.4382295608520508],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND -0.50 (10)\",\"x\":[\"AND -0.50 (10)\"],\"y\":[1.483715534210205],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND -0.40 (10)\",\"x\":[\"AND -0.40 (10)\"],\"y\":[1.5106624364852905],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND -0.30 (8)\",\"x\":[\"AND -0.30 (8)\"],\"y\":[1.5630098581314087],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND -0.20 (9)\",\"x\":[\"AND -0.20 (9)\"],\"y\":[1.666882872581482],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND -0.10 (11)\",\"x\":[\"AND -0.10 (11)\"],\"y\":[1.6793701648712158],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND -0.00 (12)\",\"x\":[\"AND -0.00 (12)\"],\"y\":[1.6704334020614624],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND 0.10 (7)\",\"x\":[\"AND 0.10 (7)\"],\"y\":[1.520676851272583],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND 0.20 (12)\",\"x\":[\"AND 0.20 (12)\"],\"y\":[1.7507907152175903],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND 0.30 (10)\",\"x\":[\"AND 0.30 (10)\"],\"y\":[1.7054075002670288],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND 0.40 (7)\",\"x\":[\"AND 0.40 (7)\"],\"y\":[1.718890905380249],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND 0.50 (9)\",\"x\":[\"AND 0.50 (9)\"],\"y\":[1.776005506515503],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND 0.60 (12)\",\"x\":[\"AND 0.60 (12)\"],\"y\":[1.8645012378692627],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND 0.70 (12)\",\"x\":[\"AND 0.70 (12)\"],\"y\":[2.0634610652923584],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND 0.80 (11)\",\"x\":[\"AND 0.80 (11)\"],\"y\":[2.008836507797241],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND 0.90 (9)\",\"x\":[\"AND 0.90 (9)\"],\"y\":[1.770878553390503],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND 1.00 (9)\",\"x\":[\"AND 1.00 (9)\"],\"y\":[2.3202476501464844],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND 1.10 (8)\",\"x\":[\"AND 1.10 (8)\"],\"y\":[2.1552975177764893],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND 1.20 (9)\",\"x\":[\"AND 1.20 (9)\"],\"y\":[2.265568971633911],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND 1.30 (10)\",\"x\":[\"AND 1.30 (10)\"],\"y\":[2.190293312072754],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND 1.40 (6)\",\"x\":[\"AND 1.40 (6)\"],\"y\":[1.7008997201919556],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND 1.50 (2)\",\"x\":[\"AND 1.50 (2)\"],\"y\":[1.5467665195465088],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND 1.60 (4)\",\"x\":[\"AND 1.60 (4)\"],\"y\":[1.9145389795303345],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND 1.70 (5)\",\"x\":[\"AND 1.70 (5)\"],\"y\":[2.058548927307129],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND 1.80 (3)\",\"x\":[\"AND 1.80 (3)\"],\"y\":[1.6896328926086426],\"type\":\"bar\"},{\"error_y\":{\"array\":[0.0],\"type\":\"data\",\"visible\":true},\"name\":\"AND 1.90 (2)\",\"x\":[\"AND 1.90 (2)\"],\"y\":[1.523792028427124],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"AND neuron loss increase with cosine sim constraint: gen \\u003e ge\"},\"xaxis\":{\"title\":{\"text\":\"\"}},\"yaxis\":{\"title\":{\"text\":\"\"}},\"barmode\":\"group\",\"width\":1000,\"showlegend\":true},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('99af98eb-a217-47c8-97dc-6d5ab64346ca');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# And thresholds with similarity constraint\n",
    "losses = []\n",
    "lens =  []\n",
    "thresholds = []\n",
    "for and_threshold in np.arange(-0.5, 2, 0.1):\n",
    "    df_tmp = df.copy()\n",
    "    ablation_mode = \"YYN\"\n",
    "    df_tmp[\"Custom\"] = (df[\"GenSim\"]>df[\"GeSim\"]) & \\\n",
    "        (df[\"YYY\"]>and_threshold) & (df[\"YYN\"]<=and_threshold) & (df[\"YNY\"]<=and_threshold) & (df[\"NYY\"]<=and_threshold) & (df[\"YNN\"]<=and_threshold) & (df[\"NNY\"]<=and_threshold)& (df[\"NYN\"]<=and_threshold)\n",
    "    pos_and_neurons = torch.LongTensor(df_tmp[df_tmp[\"Custom\"]].index.tolist()).cuda()\n",
    "\n",
    "    original_loss, ablated_loss = compute_mlp_loss(prompts, df, pos_and_neurons, ablate_mode=ablation_mode, compute_original_loss=True)\n",
    "    if len(losses) == 0:\n",
    "        losses.append([original_loss])\n",
    "    losses.append([ablated_loss])\n",
    "    lens.append(len(pos_and_neurons))\n",
    "    thresholds.append(and_threshold)\n",
    "names = [\"Original\"] + [f\"AND {thr:.2f} ({length})\" for thr, length in zip(thresholds, lens)]\n",
    "haystack_utils.plot_barplot(losses, names, title=\"AND neuron loss increase with cosine sim constraint: gen > ge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model.hooks(deactivate_neurons_fwd_hooks):\n",
    "    ablated_loss, ablated_cache = model.run_with_cache(prompts, return_type=\"loss\")\n",
    "\n",
    "def get_ablate_neurons_hook(neuron: int | list[int], ablated_cache, layer=5):\n",
    "    def ablate_neurons_hook(value, hook):\n",
    "        value[:, :, neuron] = ablated_cache[f'blocks.{layer}.mlp.hook_post'][:, :, neuron]\n",
    "        return value\n",
    "    return [(f'blocks.{layer}.mlp.hook_post', ablate_neurons_hook)]\n",
    "\n",
    "ablate_top_neurons_hook = get_ablate_neurons_hook([i for i in range(2048)], ablated_cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.5872, 1.4587, 0.8471, 0.3234, 0.0033, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000], device='cuda:0')\n",
      "['ß', 'gen', 'ßen', 'ger', 'gt', '-', '*', ',', '(', '&', ')', '+', \"'\", '!', '<|endoftext|>', '<|padding|>', '%', '$', '\"', '#']\n"
     ]
    }
   ],
   "source": [
    "original_logprobs, ablated_logprobs, _, all_MLP5_logprobs = haystack_utils.get_direct_effect(prompts, model, pos=-2, context_ablation_hooks=deactivate_neurons_fwd_hooks, context_activation_hooks=activate_neurons_fwd_hooks, return_type='logprobs')\n",
    "\n",
    "diffs = (original_logprobs - ablated_logprobs).mean(0)\n",
    "diffs[all_ignore] = 0\n",
    "diffs[original_logprobs.mean(0)<-7] = 0\n",
    "top_diff, top_token = torch.topk(diffs, 20)\n",
    "print(top_diff)\n",
    "print(model.to_str_tokens(top_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "\n",
    "option = \"orschlägen\"\n",
    "ablation_mode = \"YYN\"\n",
    "prompts = haystack_utils.generate_random_prompts(option, model, common_tokens, 1000, length=20)\n",
    "\n",
    "names = list(all_losses[option][ablation_mode].keys())\n",
    "losses = [[all_losses[option][ablation_mode][name]] for name in names]\n",
    "\n",
    "print(len(names), len(losses))\n",
    "print([len(x) for x in losses])\n",
    "haystack_utils.plot_barplot(losses, names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "layer = 2\n",
    "ngram = \"orschlägen\"\n",
    "prompts = haystack_utils.generate_random_prompts(ngram, model, common_tokens, 500, length=20)\n",
    "\n",
    "if ngram.startswith(\" \"):\n",
    "    prompt_tuple = haystack_utils.get_trigram_prompts(prompts, new_word_tokens, continuation_tokens)\n",
    "else:\n",
    "    prompt_tuple = haystack_utils.get_trigram_prompts(prompts, continuation_tokens, continuation_tokens)\n",
    "prev_token_direction, curr_token_direction = haystack_utils.get_residual_trigram_directions(prompt_tuple, model, layer-1)\n",
    "\n",
    "prev_token_sim = get_cosine_sim(prev_token_direction, layer)\n",
    "curr_token_sim = get_cosine_sim(curr_token_direction, layer)\n",
    "context_sim = get_cosine_sim(context_direction, layer)\n",
    "\n",
    "plot_histogram(prev_token_sim, curr_token_sim, context_sim, \"Prev Token\", \"Curr Token\", \"Context\")\n",
    "# %%\n",
    "prev_sim_neurons = torch.argwhere(prev_token_sim>0.05)\n",
    "curr_sim_neurons = torch.argwhere(curr_token_sim>0.03)\n",
    "\n",
    "print(len(prev_sim_neurons), len(curr_sim_neurons))\n",
    "union = haystack_utils.union_where([prev_token_sim, curr_token_sim], 0.07)\n",
    "print(union)\n",
    "# %%\n",
    "\n",
    "# Get random mean cache\n",
    "random_prompts = haystack_utils.generate_random_prompts(ngram, model, common_tokens, 500, length=20)[:, :-3]\n",
    "_, random_cache = model.run_with_cache(random_prompts)\n",
    "\n",
    "\n",
    "# %%\n",
    "# Define ablate neuron hook\n",
    "\n",
    "# Layer 1\n",
    "# orschlägen: tensor([  61,  188, 1011], device='cuda:0')\n",
    "# häufig: 268 (almost doubles loss)\n",
    "# beweglich: neurons decrease loss - maybe they boost alternative completion\n",
    "\n",
    "def get_ablate_neurons_hook(neurons, layer):\n",
    "    print(neurons)\n",
    "    def ablate_neurons_hook(value, hook):\n",
    "        value[:, :, neurons] = random_cache[f'blocks.{layer}.mlp.hook_post'][:, :, neurons].mean((0, 1))\n",
    "        return value\n",
    "    return [(f'blocks.{layer}.mlp.hook_post', ablate_neurons_hook)]\n",
    "\n",
    "# Check loss increase\n",
    "original_loss, original_ablated_loss = compute_mlp_loss(prompts, df, torch.LongTensor([i for i in range(model.cfg.d_mlp)]).cuda(), compute_original_loss=True)\n",
    "\n",
    "with model.hooks(fwd_hooks=get_ablate_neurons_hook([1789], layer)):\n",
    "    ablated_loss = model(prompts, return_type=\"loss\", loss_per_token=True)[:, -1].mean().item()\n",
    "\n",
    "print(original_loss, original_ablated_loss, ablated_loss)\n",
    "# %%\n",
    "\n",
    "# 1011 increases loss on both \"gen\" and \"ge\"\n",
    "# Either it boosts both completions (trigram table)\n",
    "# Or it combines \"orsch\" and \"lä\" into a single representation that later components use\n",
    "\n",
    "# Check if trigram table by looking at the direct effect\n",
    "# Total effect of L1N1011\n",
    "with model.hooks(fwd_hooks=get_ablate_neurons_hook([1406], layer)):\n",
    "    _, ablated_cache = model.run_with_cache(prompts)\n",
    "\n",
    "def ablate_component_hook(value, hook):\n",
    "    value = ablated_cache[hook.name]\n",
    "    return value\n",
    "\n",
    "components = [f\"blocks.{layer}.mlp.hook_post\" for layer in range(3, 6)] + [f\"blocks.{layer}.attn.hook_z\" for layer in range(3, 6)]\n",
    "hooks = [(component, ablate_component_hook) for component in components]\n",
    "\n",
    "with model.hooks(fwd_hooks=hooks):\n",
    "    ablated_logits = model(prompts, return_type=\"logits\", loss_per_token=True)[:, -2].log_softmax(-1).mean(0)\n",
    "\n",
    "original_logits = model(prompts, return_type=\"logits\", loss_per_token=True)[:, -2].log_softmax(-1).mean(0)\n",
    "\n",
    "print(ablated_logits.shape, original_logits.shape)\n",
    "\n",
    "prob_diff = original_logits - ablated_logits\n",
    "prob_diff[all_ignore] = 0\n",
    "prob_diff[original_logits < -7] = 0\n",
    "diffs, tokens = torch.topk(prob_diff, 20)\n",
    "print(diffs)\n",
    "print(tokens)\n",
    "print(model.to_str_tokens(tokens))\n",
    "\n",
    "# %% \n",
    "# Direct effect\n",
    "_, original_cache = model.run_with_cache(prompts)\n",
    "\n",
    "def activate_component_hook(value, hook):\n",
    "    value = original_cache[hook.name]\n",
    "    return value\n",
    "\n",
    "activate_hooks = [(component, activate_component_hook) for component in components]\n",
    "\n",
    "with model.hooks(fwd_hooks=activate_hooks + get_ablate_neurons_hook([1406], layer)):\n",
    "    activated_logits = model(prompts, return_type=\"logits\", loss_per_token=True)[:, -2].log_softmax(-1).mean(0)\n",
    "\n",
    "prob_diff = original_logits - activated_logits\n",
    "prob_diff[all_ignore] = 0\n",
    "prob_diff[original_logits < -7] = 0\n",
    "diffs, tokens = torch.topk(prob_diff, 20)\n",
    "print(diffs)\n",
    "print(tokens)\n",
    "print(model.to_str_tokens(tokens))\n",
    "\n",
    "# Check later components + context neuron effects of 1011\n",
    "# %%\n",
    "\n",
    "#output_direction = model.W_out[1, 1011]\n",
    "output_direction = model.W_out[2, 1406]\n",
    "context_direction = model.W_out[3, 669]\n",
    "\n",
    "output_sims = get_cosine_sim(output_direction, 5)\n",
    "context_sims = get_cosine_sim(context_direction, 5)\n",
    "\n",
    "plot_histogram(output_sims, context_sims, torch.zeros_like(output_sims), \"Output\", \"Context\", \"Zero\")\n",
    "# %%\n",
    "union = haystack_utils.union_where([output_sims, context_sims], 0.05)\n",
    "len(union)\n",
    "# %%\n",
    "ngram = \"orschlägen\"\n",
    "prompts = haystack_utils.generate_random_prompts(ngram, model, common_tokens, 1000, length=20)\n",
    "\n",
    "original_loss, original_ablated_loss = compute_mlp_loss(prompts, df, torch.LongTensor([i for i in range(model.cfg.d_mlp)]).cuda(), compute_original_loss=True)\n",
    "\n",
    "with model.hooks(fwd_hooks=get_ablate_neurons_hook(union, 5)): #712, 394, 287\n",
    "    ablated_loss = model(prompts, return_type=\"loss\", loss_per_token=True)[:, -1].mean().item()\n",
    "\n",
    "print(original_loss, original_ablated_loss, ablated_loss)\n",
    "# %%\n",
    "ngram = \" meine Vorschläge\"\n",
    "prompts = haystack_utils.generate_random_prompts(ngram, model, common_tokens, 1000, length=20)\n",
    "original_loss, original_ablated_loss = compute_mlp_loss(prompts, df, torch.LongTensor([i for i in range(model.cfg.d_mlp)]).cuda(), compute_original_loss=True)\n",
    "print(original_loss, original_ablated_loss)\n",
    "# %%\n",
    "model.to_str_tokens(model.to_tokens(\" deinen Vorschläge\", prepend_bos=False))\n",
    "# %%\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
