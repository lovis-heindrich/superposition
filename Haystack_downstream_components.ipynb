{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import einsum\n",
    "from tqdm.auto import tqdm\n",
    "import seaborn as sns\n",
    "from transformer_lens import HookedTransformer, ActivationCache, utils\n",
    "from datasets import load_dataset\n",
    "from einops import einsum\n",
    "import pandas as pd\n",
    "from transformer_lens import utils\n",
    "from rich.table import Table, Column\n",
    "from rich import print as rprint\n",
    "from jaxtyping import Float, Int, Bool\n",
    "from typing import List, Tuple\n",
    "from torch import Tensor\n",
    "import einops\n",
    "import functools\n",
    "from transformer_lens.hook_points import HookPoint\n",
    "# import circuitsvis\n",
    "from IPython.display import HTML\n",
    "from plotly.express import line\n",
    "import plotly.express as px\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "import gc\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from plotly.subplots import make_subplots\n",
    "# Plotly needs a different renderer for VSCode/Notebooks vs Colab argh\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"notebook_connected\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.autograd.set_grad_enabled(False)\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "from haystack_utils import load_txt_data, get_mlp_activations, line\n",
    "import haystack_utils\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model pythia-70m-v0 into HookedTransformer\n",
      "kde4_french.txt: Loaded 1007 examples with 505 to 5345 characters each.\n",
      "kde4_english.txt: Loaded 1007 examples with 501 to 5295 characters each.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa30637f30e24d3ebd305ed3d77f9592",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c350b46d3f74eecafc51ccaba05e311",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = HookedTransformer.from_pretrained(\"pythia-70m-v0\", fold_ln=True, device=device)\n",
    "\n",
    "kde_french = load_txt_data(\"kde4_french.txt\")\n",
    "kde_english = load_txt_data(\"kde4_english.txt\")\n",
    "\n",
    "french_activations = get_mlp_activations(kde_french, 3, model, num_prompts=100, mean=True)\n",
    "english_activations = get_mlp_activations(kde_english, 3, model, num_prompts=100, mean=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Absolute activation difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.4020, device='cuda:0')\n",
      "tensor(3.6891, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Average loss of the first 20 examples\n",
    "\n",
    "examples = kde_french[:20]\n",
    "print(haystack_utils.get_average_loss(examples, model))\n",
    "print(haystack_utils.get_average_loss(examples, model, crop_context=150))\n",
    "# print(\"Context lengths:\", [model.to_tokens(example).shape[1] for example in examples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ablated_mlp_difference(\n",
    "    prompts: list[str], \n",
    "    model: HookedTransformer, \n",
    "    layer_to_cache: int, \n",
    "    fwd_hooks: List[Tuple]=[], \n",
    "    print_mean_loss=False\n",
    "):\n",
    "    \"\"\"Get mean differences between original and ablated MLP activations at a specified model layer. Mean ablations are applied to the given layer and set of neurons.\"\"\"        \n",
    "    block_name = f'blocks.{layer_to_cache}.mlp.hook_post'\n",
    "    original_losses = []\n",
    "    ablated_losses = []\n",
    "    mean_differences = []\n",
    "    for prompt in tqdm(prompts):\n",
    "        original_loss, ablated_loss, original_cache, ablated_cache = haystack_utils.get_caches_single_prompt(\n",
    "            prompt, model, fwd_hooks=fwd_hooks, return_type=\"loss\")\n",
    "\n",
    "        original_losses.append(original_loss)\n",
    "        ablated_losses.append(ablated_loss)\n",
    "\n",
    "        original_activations = original_cache[block_name][:, 1:] # batch, pos, d_mlp\n",
    "        ablated_activations = ablated_cache[block_name][:, 1:]\n",
    "\n",
    "        mean_difference = original_activations.mean((0, 1)) - ablated_activations.mean((0, 1))\n",
    "        mean_differences.append(mean_difference)\n",
    "        \n",
    "    if print_mean_loss:\n",
    "        print(f\"Original loss: {np.mean(original_losses):.2f}, ablated loss: {np.mean(ablated_losses):.2f} (+{((np.mean(ablated_losses) - np.mean(original_losses)) / np.mean(original_losses))*100:.2f}%)\")\n",
    "    return torch.stack(mean_differences).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae0a6f897bbb4539a336a65122f0d65b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1007 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original loss: 3.58, ablated loss: 3.81 (+6.23%)\n"
     ]
    }
   ],
   "source": [
    "layer_to_cache = 5\n",
    "neurons = torch.LongTensor([609])\n",
    "def ablate_neuron_hook(value, hook):\n",
    "    value[:, :, neurons] = english_activations[neurons] # english_activations: Float[Tensor, \"d_mlp\"]\n",
    "    return value\n",
    "fwd_hooks = [(f'blocks.{3}.mlp.hook_post', ablate_neuron_hook)]\n",
    "\n",
    "difference = get_ablated_mlp_difference(kde_french, model, fwd_hooks=fwd_hooks, layer_to_cache=layer_to_cache, print_mean_loss=True)\n",
    "sorted_differences, sorted_neurons = torch.topk(difference.abs(), len(difference), largest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.24.1.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>                            <div id=\"6cdd3c18-ebbb-4ba6-ba85-2e4132bc85a6\" class=\"plotly-graph-div\" style=\"height:525px; width:800px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"6cdd3c18-ebbb-4ba6-ba85-2e4132bc85a6\")) {                    Plotly.newPlot(                        \"6cdd3c18-ebbb-4ba6-ba85-2e4132bc85a6\",                        [{\"alignmentgroup\":\"True\",\"bingroup\":\"x\",\"hovertemplate\":\"variable=0\\u003cbr\\u003evalue=%{x}\\u003cbr\\u003ecount=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"0\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"0\",\"offsetgroup\":\"0\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[-0.004645213019102812,-0.0006136452429927886,0.006211047992110252,-0.002322225132957101,0.23277893662452698,0.09119828045368195,-0.025653963908553123,-0.005280723795294762,0.475567102432251,-0.034190017729997635,-0.05423297733068466,0.004980783443897963,-0.019466059282422066,0.03750162944197655,-0.004625317640602589,-0.05223976820707321,-0.006628438830375671,-0.0011433938052505255,0.0035071875900030136,-0.0006513202679343522,-0.03129849210381508,0.0024591388646513224,0.02765336073935032,0.001678431872278452,-0.006818615831434727,-0.0013570740120485425,0.12331552803516388,0.006186533719301224,-0.004329089540988207,-0.0005642889882437885,0.13134504854679108,0.1344047486782074,0.04212997853755951,-8.100828563328832e-05,0.01962145045399666,0.13554984331130981,-0.018795782700181007,-0.012909294106066227,-0.0064403279684484005,0.01084035262465477,-0.002423809841275215,0.024102481082081795,0.002338384510949254,-0.02377157285809517,0.1279948502779007,-0.010644313879311085,-0.019269390031695366,-0.07665669173002243,-0.030872242525219917,0.02692301571369171,0.07366594672203064,0.0031236805953085423,-0.04073566570878029,-0.006546888034790754,0.013087010011076927,-0.0006539325695484877,0.08187743276357651,-0.004644104745239019,0.006800767965614796,-0.031160205602645874,0.0017054971540346742,-0.026584019884467125,0.0006125188083387911,0.001900800270959735,-0.003380256239324808,-0.09584038704633713,-0.02766544558107853,0.05313342809677124,0.20201140642166138,-0.00021283567184582353,-0.005416809115558863,-0.004874279722571373,-0.0017170438077300787,-0.013062398880720139,-0.0001338957081316039,0.05430465564131737,0.024049565196037292,0.014560566283762455,0.26702335476875305,-0.018329361453652382,0.026148570701479912,-0.03559798374772072,-0.023088259622454643,-0.029311740770936012,0.03448234125971794,-0.036625463515520096,-0.021770842373371124,0.012280743569135666,0.006972406059503555,-0.0019983553793281317,0.007716454565525055,0.07439247518777847,-0.002367510925978422,-0.012216290459036827,0.04376036673784256,0.01786503754556179,0.03230438008904457,-4.886157694272697e-05,-0.015596008859574795,0.0022216658107936382,0.019405612722039223,-0.009608658030629158,-0.008382480591535568,-0.003082943381741643,-0.027551429346203804,-0.0049604508094489574,0.004959183279424906,-0.013233243487775326,0.07829063385725021,0.005535818170756102,-0.009854353033006191,0.01903490722179413,0.0781283751130104,0.017044471576809883,-0.0026784376241266727,-0.007833919487893581,0.0008231133688241243,-0.004492197185754776,-0.02919813245534897,-0.012031170539557934,-0.038675401359796524,-0.00406522024422884,0.007983917370438576,0.013701402582228184,-0.006909344345331192,0.006315927486866713,0.03573119640350342,-0.04256713017821312,-0.03846440836787224,0.05503939092159271,-0.007610925007611513,0.04226303473114967,-0.003542704973369837,0.07739277184009552,-0.03821789100766182,0.19483855366706848,0.08405905216932297,-0.026929214596748352,0.13730397820472717,-0.002836344763636589,-0.0024231462739408016,-0.06524313986301422,0.09647706896066666,-0.004153795540332794,0.03496702387928963,-0.0014769633999094367,0.0007161868270486593,-0.015922294929623604,-0.00859666895121336,0.186822772026062,0.01773834601044655,0.004994567483663559,-0.0056625609286129475,-0.004876898135989904,-0.005144287366420031,0.12575224041938782,-0.036264076828956604,-0.0012376487720757723,0.08352196216583252,-0.03464856371283531,0.16168303787708282,-0.006481883581727743,0.015120992437005043,-0.011759885586798191,0.4662923812866211,-0.0001256964314961806,0.05538472160696983,0.003395344829186797,-0.018749697133898735,0.013441191986203194,-0.0011844080872833729,-0.04351048916578293,-0.011930001899600029,-0.020333215594291687,0.0021447099279612303,0.010741347447037697,0.035986825823783875,0.01863458752632141,-0.013434931635856628,0.004832758102566004,-0.006559897214174271,0.06058422476053238,0.004469030071049929,-0.04413075000047684,0.002259110566228628,0.029072843492031097,-0.027805449441075325,-0.009250297211110592,-0.09631276875734329,0.002394384006038308,0.02843928337097168,0.0013212455669417977,-0.00038139455136843026,-0.005320688243955374,-0.0008561631548218429,-0.0021416256204247475,0.008763321675360203,-0.0036705078091472387,-0.047679513692855835,0.011330514214932919,-0.008641764521598816,-0.0077081043273210526,-0.07201337814331055,-0.024211516603827477,0.07249527424573898,-0.009465648792684078,-0.008552877232432365,2.036022488027811e-05,-0.023946158587932587,0.06188356503844261,-0.013288441114127636,-0.007933609187602997,-0.0067152585834264755,-0.0034554039593786,0.014431487768888474,0.01636660471558571,-0.045327119529247284,0.00871239136904478,-0.009479147382080555,-0.0014034465420991182,0.13572482764720917,-0.0023995577357709408,0.07260772585868835,0.0454045794904232,0.021093666553497314,0.00023902632528916,0.0024472391232848167,0.008172246627509594,0.002755027497187257,0.022070016711950302,0.01828949898481369,0.013978918083012104,0.00029939666274003685,-0.023739326745271683,0.018198275938630104,-0.006178799085319042,-0.0040857489220798016,0.0006665545515716076,-0.008144197054207325,-0.005497039761394262,0.08197489380836487,0.01602174900472164,0.013483285903930664,-0.026553485542535782,-0.038671813905239105,0.36461877822875977,-0.02884887345135212,0.008880972862243652,0.007274139206856489,-0.15119875967502594,0.005923358257859945,-0.016512835398316383,0.055295322090387344,0.006336695980280638,0.08251775056123734,-0.016786737367510796,-0.011971984058618546,-0.000948500819504261,-0.008206156082451344,0.003746926784515381,0.005254030227661133,-0.0036727702245116234,-0.019498148933053017,-0.011908279731869698,0.02448648400604725,-0.03408602252602577,0.001742583466693759,-0.008616166189312935,-0.0023475668858736753,-0.00716042285785079,0.059091366827487946,-0.0020026646088808775,-0.0028563763480633497,0.7151039838790894,-0.0006852278602309525,-0.00243889051489532,0.08357306569814682,0.08594661951065063,-0.012701064348220825,-0.0068289246410131454,0.0038386269006878138,0.010203057900071144,-0.04113083332777023,-0.004039045423269272,-0.007627981249243021,0.005857041571289301,-0.02986447513103485,0.08259967714548111,-0.024698661640286446,-0.0009670574218034744,0.0032953971531242132,-0.07398638129234314,0.14083242416381836,0.03286191448569298,-0.021708419546484947,0.04532970115542412,0.02075500786304474,0.18267779052257538,0.043853435665369034,0.004376429598778486,-0.0027334385085850954,0.007169910706579685,0.022340571507811546,0.004969383589923382,-0.005891677923500538,-0.06657474488019943,9.280235826736316e-05,0.005743340123444796,-0.04793081805109978,-0.023715930059552193,0.01767909526824951,0.0030600843019783497,0.032750148326158524,0.05318917706608772,-0.10728482156991959,0.2242056131362915,-0.07610709965229034,0.0009231063304468989,0.011235164478421211,0.01210837997496128,-0.0010622316040098667,-0.05312838405370712,0.0037232860922813416,0.05737198516726494,-0.03457816317677498,0.012936770915985107,-0.005463580135256052,-0.009469049982726574,0.008881386369466782,0.019744638353586197,0.018708670511841774,-0.002232686150819063,0.1211957111954689,0.040669552981853485,0.025166762992739677,0.0017070710891857743,0.028708431869745255,0.006022741552442312,0.2614167034626007,0.0014208020875230432,-0.06447631120681763,0.016764473170042038,0.11732622236013412,0.004105744417756796,-0.004814587067812681,0.012246789410710335,0.10192490369081497,0.17693571746349335,-0.0007356274873018265,-0.03347818925976753,-0.01460955385118723,-0.0061266073025763035,0.0027084138710051775,-0.0054666814394295216,0.0300554521381855,-0.03432834893465042,0.007611540611833334,0.005371890030801296,-0.02243451587855816,0.004771157633513212,0.16913700103759766,0.02193443477153778,0.0390433631837368,0.07397397607564926,-0.005108758807182312,-0.005905346479266882,-0.024828793480992317,0.004662474617362022,-0.002770010381937027,-0.017945047467947006,0.043566860258579254,-0.00487237423658371,0.05656665563583374,0.024963503703475,-0.058777011930942535,0.018058782443404198,-0.037189044058322906,0.11925259977579117,0.016575541347265244,-0.02109733410179615,0.25930845737457275,0.009392132982611656,0.015815215185284615,0.04103565588593483,0.019390499219298363,0.05333097651600838,0.029388073831796646,0.1564011573791504,-0.005791984032839537,0.433454692363739,-0.024507302790880203,-0.0013034753501415253,-0.0030447840690612793,0.10689831525087357,0.33250898122787476,0.6447740197181702,-0.005973809398710728,0.0079468609765172,-0.004644939675927162,-0.04483107849955559,-0.0028580771759152412,0.05176464468240738,-0.0006939696031622589,0.02337528020143509,0.12098231911659241,0.16007079184055328,-0.008880999870598316,0.08727112412452698,0.011360261589288712,-0.0034169543068856,-0.0052482970058918,0.2624962329864502,0.004252597223967314,-0.002640691353008151,0.16106033325195312,0.04277379438281059,-0.0038910796865820885,-0.07597172260284424,-0.01157904602587223,0.15368898212909698,0.00022672685736324638,0.10313466191291809,-0.009468426927924156,0.1962376981973648,-0.0016221634577959776,0.0002954721567220986,-0.025559306144714355,0.0021601510234177113,-0.010314279235899448,0.0024137983564287424,0.025079475715756416,-0.02590538188815117,-0.04780182987451553,-0.0519254170358181,0.005343396682292223,-0.015992367640137672,0.07725358754396439,-0.005795253906399012,-0.00723810400813818,0.010940434411168098,0.0028690712060779333,-0.008423377759754658,0.010094577446579933,0.005537400953471661,0.00791088305413723,0.004955637268722057,-0.006595000624656677,0.19218173623085022,0.00789677631109953,0.024150919169187546,-0.008427183143794537,-0.09604676067829132,0.0780588909983635,0.25326481461524963,0.04742222651839256,0.17436707019805908,-0.03446580097079277,-0.015459700487554073,-0.018376491963863373,-0.02600482851266861,0.00284431385807693,-0.02230951562523842,0.004753673914819956,0.010539771988987923,-0.0014892617473378778,-0.01602712646126747,0.027816468849778175,-0.0076279896311461926,-0.008352648466825485,0.1096518412232399,-0.010711866430938244,-0.039188358932733536,0.10321192443370819,-0.02477787621319294,-0.014221061021089554,-0.00023779696493875235,-0.000562500674277544,-0.003789984155446291,0.002650890266522765,0.005614610854536295,0.002112150425091386,-0.0014538327232003212,-0.017902400344610214,-0.008921150118112564,-0.01060411799699068,-0.01430119201540947,0.06111973896622658,-0.012830793857574463,-0.04581665247678757,-0.03418072313070297,-0.003537859534844756,-0.003915900830179453,-0.02235945127904415,0.18568946421146393,-0.0028291677590459585,-0.016676053404808044,-0.06898068636655807,0.041533030569553375,-0.030074963346123695,0.20476014912128448,-0.012250873260200024,0.025306761264801025,0.07820350676774979,-0.0027490605134516954,-0.019432980567216873,0.21428820490837097,0.016151713207364082,0.02630760706961155,0.016709832474589348,-0.004726942162960768,-0.0039007579907774925,-0.007685123011469841,0.018467744812369347,-0.0063987066969275475,0.03138565644621849,-0.051885586231946945,-0.03129017725586891,-0.00015451233775820583,-0.006551456172019243,0.047724369913339615,-0.005057531408965588,-0.015551531687378883,0.0183008573949337,-0.0018397823441773653,-0.0022385658230632544,-0.014439664781093597,0.021579544991254807,0.013950170017778873,0.008760461583733559,-0.01041736826300621,-0.012676212005317211,-0.033112626522779465,-0.04405989870429039,0.0002095125091727823,-0.006116317585110664,-0.034703001379966736,-0.02199949510395527,0.04073537513613701,0.025159144774079323,-0.029106806963682175,-0.058247994631528854,-0.034595660865306854,-0.04319586977362633,-0.00424548052251339,0.002218489767983556,-0.03242040053009987,0.017039654776453972,-0.048445191234350204,0.18472564220428467,0.05882515385746956,-0.06909164786338806,-0.010895276442170143,0.06825368106365204,0.010713526047766209,0.15993934869766235,-0.00032454918255098164,0.18790467083454132,-0.015733754262328148,-0.0038563215639442205,-0.07407152652740479,-0.01134100928902626,0.014287200756371021,-0.016506247222423553,-0.002446400932967663,0.004075178876519203,0.05573681369423866,-0.005277138203382492,-0.029919516295194626,0.06295528262853622,0.02961098961532116,-0.024952968582510948,0.0002470949839334935,-0.012903451919555664,0.006526879034936428,0.004548890981823206,0.022486120462417603,0.0007031977293081582,-0.011098173446953297,0.0005036378279328346,0.0032105010468512774,0.06272909045219421,-0.06844544410705566,-0.01033997256308794,0.02556978538632393,0.3316364884376526,0.02378668636083603,0.16603899002075195,0.1012192890048027,-0.0017560970736667514,0.07259687036275864,-0.016242265701293945,-0.04860980436205864,-8.334604353876784e-05,-0.003397071035578847,-0.017157837748527527,-0.004535210318863392,0.034173384308815,-0.03125791624188423,-0.003416928928345442,0.11330373585224152,0.015504170209169388,0.0007054139277897775,0.002143880119547248,0.005326631013303995,0.004203251097351313,0.010523378849029541,0.10482998937368393,-0.0021694002207368612,0.26951536536216736,-0.017837485298514366,-0.0033166292123496532,0.005073225125670433,0.0040822867304086685,0.09451388567686081,0.034647081047296524,0.033915914595127106,-0.005228984169661999,-0.0048005892895162106,0.018097806721925735,-0.014803271740674973,-0.004989855922758579,-0.0017300022300332785,0.004007785581052303,0.018346888944506645,0.005145843606442213,-0.00258070370182395,-0.010825126431882381,0.012089180760085583,-0.0058935899287462234,0.007837159559130669,0.016619116067886353,-0.11683517694473267,-0.030878394842147827,0.03874924033880234,0.01964624598622322,-0.00232789758592844,0.1399078518152237,0.007210484705865383,-0.004307447466999292,0.2699168920516968,-0.001386851305142045,-0.16956572234630585,-0.014497377909719944,0.14366766810417175,-0.0014249390223994851,-0.00795831996947527,-0.029906118288636208,-0.015408267267048359,0.16690252721309662,0.004093184135854244,0.011372233740985394,0.25740572810173035,-0.037239089608192444,-0.005313648842275143,0.11750657856464386,0.007029336411505938,0.018345076590776443,-0.04573101922869682,0.012454302981495857,0.07771646976470947,-0.009636851027607918,-0.012712768279016018,0.02075181156396866,-0.02213127911090851,0.010591201484203339,0.167741060256958,-0.002430352382361889,-0.0009518603910692036,-0.0028939705807715654,-0.008413197472691536,0.7021030783653259,-0.004593890160322189,-0.05697477236390114,0.03189952298998833,-0.005647123791277409,-0.012817027047276497,-0.01100547518581152,0.030290234833955765,-0.00799307506531477,-0.019384438171982765,-0.006633146665990353,-0.03597930818796158,0.019736655056476593,0.0033234376460313797,-0.05308498814702034,0.0004869652329944074,-0.006691085174679756,0.0040728445164859295,0.00017417187336832285,0.011532073840498924,0.12515859305858612,-0.0024855483788996935,0.00162292190361768,0.02707214467227459,-0.01545510534197092,-0.01008776668459177,-0.0009216934558935463,0.06798722594976425,-0.007839385420084,-3.060316885239445e-05,-0.009295620024204254,-0.0793241411447525,-0.0068739322014153,0.14318665862083435,-0.000457126327091828,-0.03998026251792908,-0.0031201341189444065,0.11930659413337708,0.004745628219097853,-0.09319791197776794,-0.0013601392274722457,0.012938321568071842,-0.0164520051330328,-0.033740345388650894,0.000602422805968672,-0.0544000081717968,-0.0020822198130190372,-0.01591150462627411,-0.013667628169059753,0.009617476724088192,0.002743704244494438,0.0019029849208891392,-0.013422761112451553,0.005748941097408533,-0.037115808576345444,0.0012604250805452466,-0.016096362844109535,-0.1501796692609787,-0.07030007243156433,-0.04598483070731163,-0.054097045212984085,0.13845369219779968,-0.034750375896692276,-0.021337369456887245,0.006293851416558027,-0.0015634669689461589,0.0017558896215632558,0.002428871812298894,-0.020300526171922684,-0.007384138181805611,-0.004491092637181282,-0.016195230185985565,-0.0016314112581312656,-0.005505576264113188,-0.001161353662610054,-0.004724513739347458,0.005980781279504299,0.0312948040664196,-0.017268994823098183,-0.029777254909276962,0.018768658861517906,0.44961270689964294,0.008118866011500359,-0.006278596818447113,-0.02874174527823925,0.1418476402759552,-0.018276436254382133,-0.004730530083179474,0.022858452051877975,-0.03905598074197769,-0.003774165641516447,0.022160721942782402,-0.006822068244218826,-0.0222198236733675,-0.0031062159687280655,0.015547585673630238,0.0012053446844220161,0.24697662889957428,0.01726004108786583,0.03361538425087929,-0.020579148083925247,0.0005952324136160314,0.059178225696086884,-0.0113602289929986,-0.0010688401525840163,-0.0073845782317221165,0.02034432627260685,0.018285218626260757,0.015984006226062775,0.0032236650586128235,-0.023425253108143806,0.032531652599573135,-0.019351154565811157,0.15788491070270538,-0.0015374587383121252,0.0438021644949913,0.03899456188082695,0.005289331544190645,0.04402501881122589,-0.010196664370596409,0.045799873769283295,-0.020681068301200867,-0.02181635983288288,-0.013764968141913414,0.018948892131447792,0.02005469612777233,-0.04877547547221184,-0.010378377512097359,-0.08346281945705414,-0.019546763971447945,-0.0061738514341413975,-0.005458686966449022,-0.0019041136838495731,-0.0038813783321529627,0.0281821321696043,-0.022431975230574608,0.001682924572378397,0.08426415920257568,-0.020807703956961632,0.0016358838183805346,0.03728383779525757,-0.029339265078306198,0.007681053131818771,0.11926102638244629,-0.0010841373587027192,-0.006671900395303965,-0.003899335628375411,0.12526938319206238,-0.009594770148396492,0.007146656513214111,0.2980741262435913,0.0034718168899416924,0.019651737064123154,-0.004924190696328878,-0.043529342859983444,-0.006110643036663532,-0.0034849392250180244,-0.00737681845203042,-0.0033208588138222694,-0.01167556457221508,0.00030056684045121074,0.20641785860061646,0.08183722198009491,0.028174269944429398,-0.006698673125356436,0.0010332403471693397,-0.002291383920237422,-0.0033757551573216915,-0.00753322197124362,-0.0018931458471342921,0.019904419779777527,-0.013701768592000008,-0.015497997403144836,0.0176352821290493,0.06595146656036377,0.11633270978927612,-0.013472565449774265,0.24593667685985565,0.011428366415202618,0.07246765494346619,-0.013047810643911362,0.018081676214933395,-0.014121259562671185,0.0075004808604717255,-0.013510839082300663,-0.015663672238588333,0.010975268669426441,-0.013771751895546913,0.01579905115067959,0.009510263800621033,-0.1245226189494133,-0.11089810729026794,0.011421085335314274,-0.007148204371333122,-0.015153283253312111,0.010475683026015759,-0.009670669212937355,-0.02466120757162571,-0.0019146676640957594,-0.07029943913221359,0.006173625588417053,0.0012999781174585223,-0.06499486416578293,0.00581437349319458,-0.024107711389660835,0.06720402091741562,-0.0071667395532131195,0.027964098379015923,-0.004705394152551889,-0.0112041300162673,-0.011495262384414673,0.03670451045036316,-0.04268771782517433,0.021465154364705086,0.02688484638929367,-0.005603729281574488,0.00590489199385047,0.014251607470214367,-0.004824754316359758,-0.008417175151407719,-0.030222926288843155,0.055705223232507706,0.15783314406871796,-0.002907812362536788,-0.013279760256409645,0.006261605303734541,-0.003430156037211418,-0.008986220695078373,-0.004338465165346861,-0.0027498058043420315,0.004587468691170216,-0.03217482194304466,0.01990473084151745,0.05330314859747887,0.11668094247579575,0.07740889489650726,-0.01696637272834778,0.0011429855367168784,-0.0030606871005147696,-0.03000987134873867,0.06922116875648499,-0.0028920506592839956,-0.005907099228352308,0.03855491429567337,-0.0026816027238965034,0.0007276231772266328,-0.012625506147742271,0.1419343203306198,-0.011388977989554405,0.0024175760336220264,0.0024989466182887554,-0.06170206889510155,-0.004142296500504017,0.005300722550600767,-0.01143167819827795,0.053042445331811905,0.03914249688386917,0.160530224442482,-0.02241348661482334,0.3769306540489197,0.1330377161502838,0.0036284641828387976,-0.0023240745067596436,-0.0035106840077787638,-0.0008417719509452581,0.052458256483078,0.06342276930809021,-0.05779692530632019,0.0009666014811955392,0.011660631746053696,-0.0016172985779121518,0.011291365139186382,-0.0076523288153111935,-0.007639871444553137,0.0039843302220106125,-0.0088134640827775,-0.01414224598556757,-0.006614453159272671,0.001986844465136528,0.0011204401962459087,-0.008894763886928558,0.01378717739135027,0.006797072011977434,0.00443745544180274,0.11156454682350159,0.07290377467870712,0.011270458810031414,-0.006055859383195639,-0.006146946921944618,-0.007420094683766365,0.10880280286073685,-8.84074397617951e-05,0.16606496274471283,0.03330808877944946,-0.005711507052183151,0.015811162069439888,-0.07801683992147446,-0.006777368485927582,0.092556431889534,-0.01714608445763588,0.009059448726475239,0.019067853689193726,-0.007663468364626169,-0.043095387518405914,0.03398478403687477,0.029127486050128937,-0.008028143085539341,0.0073546189814805984,0.1828276813030243,0.019436893984675407,0.04073994979262352,0.001902354066260159,0.004665250889956951,-0.025351041927933693,-0.07044246047735214,0.018658651039004326,0.009803983382880688,-0.00977142434567213,0.0750952884554863,0.15327590703964233,0.01896848902106285,-0.00761126633733511,-0.010631305165588856,-0.0017967040184885263,-0.037685636430978775,0.2375953495502472,0.024706043303012848,-0.06615694612264633,-0.006485410965979099,-0.0017880332889035344,0.0015232511796057224,-0.024319974705576897,-0.02332351729273796,-0.005580633878707886,0.023989224806427956,0.0034704813733696938,-0.0003337182861287147,0.03359571844339371,-0.0007085782126523554,-0.04302370920777321,-0.007052919827401638,-0.001104839495383203,-0.0015286824200302362,0.0025068954564630985,-0.03358331322669983,-0.003511553630232811,0.06422897428274155,0.04000869393348694,-0.007797854486852884,-0.0023035570047795773,0.29567965865135193,-0.002570685464888811,-0.002939834725111723,0.0076227509416639805,-0.006286390125751495,0.06972228735685349,0.009650676511228085,-0.09512551873922348,-0.08068141341209412,-0.005132943391799927,0.03617839142680168,-0.0039693391881883144,-0.0025103723164647818,-0.009762079454958439,-0.008541015908122063,-0.008257094770669937,0.030181679874658585,-0.0037664619740098715,0.10617286711931229,0.051624514162540436,0.0034024694468826056,-0.00259377621114254,0.3230321705341339,-0.06642479449510574,0.06410222500562668,-0.017422232776880264,0.0433245450258255,-0.002114349976181984,-0.010414163582026958,0.019602864980697632,0.018185583874583244,-0.05249035358428955,-0.03578391671180725,-0.0036094910465180874,-0.000678405980579555,-0.0076088570058345795,0.025984464213252068,0.03707066550850868,-0.018633155152201653,0.19237466156482697,-0.0037924458738416433,0.01789741963148117,0.013406962156295776,0.08204109966754913,-0.0022507484536617994,-0.019943153485655785,-0.009909553453326225,-0.0017817873740568757,-0.024083683267235756,-0.0111572640016675,-0.002352713607251644,0.010085896588861942,-0.0017198289278894663,-0.03498097136616707,-0.014404943212866783,-0.004392402712255716,0.049131959676742554,0.011584492400288582,-0.014011221937835217,-0.024410312995314598,-0.011385711841285229,-0.03652048110961914,0.03036557510495186,-0.005891698878258467,-0.0015782585833221674,-0.015826530754566193,-0.003998700529336929,-0.04266894981265068,-0.008434169925749302,0.03635666146874428,0.006451057735830545,-0.018399618566036224,-0.009809603914618492,0.01833895593881607,-0.006078475620597601,0.22527770698070526,-0.01168537512421608,0.005056797526776791,-0.002161506563425064,0.09650868922472,0.0011392743326723576,-0.005252891220152378,0.06451069563627243,-0.03725253790616989,0.1676637977361679,-0.09150703251361847,0.008580648340284824,-0.001435623737052083,-0.011402866803109646,-0.003917403053492308,0.0075574712827801704,-0.002388652879744768,-0.08813897520303726,-0.01076489593833685,0.032735977321863174,0.009191588498651981,-0.00800092238932848,-0.0180086437612772,-0.11261468380689621,0.037919316440820694,0.0009748057345859706,-0.04047664254903793,0.005821756552904844,-0.0004936035256832838,0.25573912262916565,-0.007076680194586515,-0.007721832953393459,-0.008724418468773365,0.004357947036623955,0.006793621461838484,0.10502239316701889,0.0016076405299827456,-0.0061688353307545185,-0.009314843453466892,0.04424986615777016,0.0034328263718634844,0.0011769274715334177,-0.003238472854718566,0.3681802451610565,0.005782471038401127,-0.02593410573899746,0.008220376446843147,0.01277749240398407,0.004134156741201878,-0.00012138535385020077,0.024717874825000763,-0.010410076007246971,-0.0023796046152710915,-0.0011412969324737787,-0.008064273744821548,0.003630375489592552,0.004866226576268673,-0.009563964791595936,-0.021202633157372475,0.0003320029645692557,-0.0002730156120378524,0.006500359624624252,-0.005530693102627993,-0.011651569046080112,0.008563892915844917,0.00023510196479037404,-0.00602139625698328,-0.008357232436537743,-0.004468056373298168,0.006194030400365591,0.03319437429308891,-0.0030667639803141356,0.002814425388351083,0.035355035215616226,-0.028481077402830124,0.05490719899535179,0.010853728279471397,0.11014627665281296,-0.029138820245862007,-0.014762120321393013,0.00031282109557650983,0.00087525270646438,0.13134299218654633,0.0033766028936952353,-0.0004918617196381092,-0.0029558404348790646,-0.022689932957291603,0.009330738335847855,-0.0054794177412986755,0.009236037731170654,0.007872565649449825,-0.024570567533373833,0.0014873010804876685,0.004937858320772648,0.03555239737033844,-0.02141241915524006,-0.007951817475259304,0.03462611511349678,0.010282238945364952,-0.03979173302650452,-0.005732805468142033,-0.01711372844874859,0.0012824798468500376,-0.007210528012365103,0.031061207875609398,-0.0019005981739610434,-0.039388373494148254,0.0140683613717556,-0.0033107756171375513,-0.0055655864998698235,0.015286808833479881,0.016343267634510994,0.1081511452794075,-0.0016034077852964401,0.46433600783348083,0.01766033284366131,-0.005684328731149435,-0.008740889839828014,-0.01706239953637123,-0.004077380523085594,0.00048207445070147514,-0.006619768217206001,0.0007684135343879461,-0.06095748394727707,-0.010779956355690956,5.505003719008528e-05,-0.003819103818386793,-0.010616413317620754,0.02705393359065056,-0.04979003593325615,0.14397843182086945,0.0011796575272455812,0.02072046883404255,-0.011525535956025124,0.003121545072644949,0.0025810261722654104,-0.01766209304332733,0.1952013373374939,0.0024459809064865112,-0.012508227489888668,-0.01442317757755518,-0.008623972535133362,0.007272740360349417,0.02260281704366207,0.009376315400004387,-0.0358230359852314,-0.02093653567135334,-0.002304522320628166,-0.016963467001914978,-0.0049538929015398026,-0.007205733563750982,-0.031994376331567764,-0.0026386042591184378,0.0356132835149765,0.007091015111654997,0.10718517005443573,-0.035119980573654175,-0.010877256281673908,-0.023249130696058273,-0.07879941910505295,-0.0011116963578388095,-0.04503946378827095,0.17086076736450195,-0.002129456726834178,0.08004669845104218,0.00475337915122509,0.14789140224456787,0.12220489233732224,-0.020711509510874748,-0.01318239513784647,-0.0009795891819521785,-0.02741638757288456,0.023379411548376083,0.0010440037585794926,-0.0028736635576933622,0.0008303320500999689,0.004096638411283493,-0.008826647885143757,-0.019314268603920937,-0.04237856715917587,-0.012535655871033669,0.001890754560008645,0.11748742312192917,0.03559604659676552,-0.002285158960148692,0.004185312893241644,0.022144082933664322,-0.0014040893875062466,-0.001897743670269847,0.04944509267807007,0.01776268146932125,0.011356507427990437,-0.04441734030842781,-0.009513605386018753,0.027786262333393097,-0.025412552058696747,0.022508664056658745,-0.015743231400847435,0.2729165256023407,-0.009756569750607014,-0.02571229264140129,0.02034592069685459,-0.008710525929927826,-0.004963724408298731,-0.00929989106953144,0.02016943320631981,-0.010220210999250412,0.03769482299685478,-0.00754699157550931,0.05218498781323433,0.0008872825419530272,0.08541427552700043,0.02456856705248356,0.08538840711116791,-0.05951105058193207,0.012458553537726402,-0.015515519306063652,0.010159734636545181,0.0689728856086731,-0.034479156136512756,0.16399624943733215,-0.049982063472270966,0.00020231390953995287,-0.004125971347093582,-0.06825835257768631,0.06558854132890701,0.013802263885736465,0.0008310135453939438,0.017802471294999123,0.09520474076271057,-0.04871523007750511,-0.021026020869612694,0.0061122397892177105,0.1222129613161087,0.0029381385538727045,0.04998905211687088,-0.003611804684624076,-0.0631658136844635,-0.0058439080603420734,-0.03773866221308708,0.0006563400384038687,0.10272485017776489,-0.010360436514019966,0.08872393518686295,0.0635119378566742,-0.001708125346340239,0.04725271090865135,0.022460073232650757,-0.0024894645903259516,0.0048418547958135605,0.0062646409496665,0.0008174501708708704,0.013216438703238964,0.006000896450132132,-0.005013995338231325,-0.022229226306080818,-0.015498078428208828,-0.042715441435575485,0.36803004145622253,-0.07112967222929001,-0.041652947664260864,-0.00030510351643897593,-0.015243200585246086,-0.002942809369415045,-0.05135973542928696,-0.03044879250228405,0.022483015432953835,0.0911000594496727,0.012549537234008312,-0.011926837265491486,-0.002193296793848276,0.13494278490543365,-0.0012723043328151107,0.008968256413936615,0.005450306925922632,-0.004720342345535755,-0.02085121162235737,-0.01964847929775715,-0.005046359729021788,0.00980594102293253,-0.039496004581451416,-0.008213968947529793,-0.008124150335788727,-0.0027419542893767357,0.02412932924926281,0.014900320209562778,-0.03876253962516785,0.13825230300426483,0.008772013708949089,-0.002713114721700549,0.012623093090951443,0.0023085512220859528,0.012435686774551868,-0.018935177475214005,0.19905485212802887,-0.0047802492044866085,-0.004849446937441826,0.05828786641359329,0.008615112863481045,0.028957339003682137,-0.008389518596231937,-0.000234790044487454,0.03394897282123566,-0.00039802282117307186,0.009999164380133152,0.0005598191055469215,-0.001690863398835063,0.0031947586685419083,-0.003161469241604209,-0.0059798527508974075,-0.006496512331068516,0.0012028454802930355,-0.005960582289844751,-0.005062402691692114,-0.0016604416305199265,0.008943780325353146,0.0061205592937767506,-0.01354395691305399,0.004063543397933245,0.0656934380531311,0.10855761170387268,0.002766466001048684,0.015515872277319431,0.0919347032904625,-0.0033125746995210648,-0.003478697035461664,0.0011752303689718246,0.003606051905080676,-0.0038120143581181765,0.031398482620716095,-0.004691349342465401,0.008881003595888615,0.023500362411141396,0.003138356376439333,0.02686181478202343,0.004147127270698547,0.00021757105423603207,-0.008492061868309975,-0.0010400093160569668,0.0011780103668570518,-0.07982251048088074,0.010167448781430721,5.554383824346587e-05,0.02143412083387375,0.004075644072145224,0.008399573154747486,0.050826650112867355,-0.05633855611085892,-0.03339773043990135,0.28793519735336304,-0.028594497591257095,0.12135067582130432,0.0013808244839310646,-0.008517961017787457,0.025457527488470078,-0.008553283289074898,-0.004316060338169336,-0.0020054320339113474,0.008603936992585659,0.06479892134666443,0.004998333752155304,-0.028956051915884018,-0.0077174329198896885,0.02420121245086193,0.0039058742113411427,-0.013592272996902466,-0.03428148478269577,-0.014637303538620472,0.14905105531215668,-0.00034011504612863064,-0.006364346016198397,-0.01728605479001999,0.018105005845427513,-0.009558763355016708,-0.01113666407763958,-0.010058940388262272,-0.0014264472993090749,-0.013765932060778141,-0.0171009860932827,0.04905436560511589,-0.10371659696102142,-0.0073236762546002865,-0.08865631371736526,-0.00706460140645504,0.3285045623779297,0.006808524485677481,-0.003716197097674012,-0.004848439712077379,-0.00849424209445715,-0.032225146889686584,0.01975606381893158,-0.006351508665829897,0.1807904988527298,0.002604822628200054,0.031516749411821365,-0.008392172865569592,0.014482589438557625,-0.030743345618247986,-0.0029952791519463062,-0.012704668566584587,-0.00953291729092598,-0.006173840258270502,-0.05312345549464226,0.003179988358169794,0.014878222718834877,0.046956371515989304,-0.0005900162504985929,-0.0008827131823636591,0.012729627080261707,0.05626939982175827,0.010052453726530075,0.02024155668914318,-0.00042419866076670587,0.006481311749666929,0.02463172748684883,-0.07359142601490021,0.005615576636046171,-0.00599196320399642,-0.0036325587425380945,-0.004744841251522303,-0.00643210019916296,-0.03376389294862747,0.0007068978156894445,-0.048427484929561615,-0.020728519186377525,-0.004445121623575687,0.014776741154491901,0.05915725603699684,0.08184799551963806,0.04562787339091301,0.03124392405152321,-0.024494489654898643,-0.029142150655388832,0.06907393038272858,0.004327760543674231,0.15357568860054016,-0.00029522605473175645,-0.0004049324197694659,0.03668036311864853,0.017053475603461266,-0.003721818095073104,0.25457844138145447,-0.0022196092177182436,-0.013193887658417225,-0.00974801741540432,0.11705756932497025,-0.0021530683152377605,0.003734542988240719,0.01837191730737686,-0.014920006506145,0.11165928095579147,0.087893545627594,0.08338312804698944,-0.010616310872137547,-0.0007391658728010952,0.1255163550376892,-0.002622986678034067,-0.010789536871016026,-0.005751191172748804,-0.0024054080713540316,0.016988372430205345,-0.035737115889787674,0.0035568717867136,0.007158106658607721,0.05468430742621422,-0.0006034895195625722,-0.000842469627968967,0.010537071153521538,-0.01229765359312296,0.009177710860967636,-0.00536999711766839,0.04751163348555565,0.0005898430827073753,0.004800737835466862,-0.002531446050852537,0.009670207276940346,0.030652372166514397,-0.061398062855005264,-0.0021500701550394297,-0.003778071841225028,-0.0014558351831510663,0.013892286457121372,0.0021874886006116867,0.053764842450618744,0.0595344640314579,0.017411671578884125,0.009198994375765324,0.0017600590363144875,-0.010746670886874199,0.04664795100688934,-0.001364925759844482,-0.1127227321267128,0.0007056238246150315,-0.0239674374461174,-0.0039194729179143906,0.022042449563741684,0.003003404475748539,-0.06318534165620804,0.0027487874031066895,0.1561419665813446,0.024798531085252762,0.05312056466937065,-0.018069377169013023,0.01921282336115837,-0.015287330374121666,0.009897316806018353,-0.0044362847693264484,-0.10346078872680664,0.0006315418286249042,0.004240548238158226,0.0445525236427784,-0.002899657702073455,0.003096260828897357,0.007907029241323471,2.7386839065002277e-05,0.06029539927840233,0.004758127965033054,0.00568819185718894,0.006763231009244919,-0.01838696375489235,0.014819796197116375,0.0066917575895786285,-0.006849256809800863,0.0005701584741473198,-0.029365645721554756,-0.0010684097651392221,-0.005470482166856527,-0.10448210686445236,-0.0762324258685112,0.012111281976103783,-0.22258837521076202,0.12987020611763,-0.005190607625991106,0.05476167052984238,0.014025910757482052,0.008572500199079514,-0.06545866280794144,0.006106723099946976,-0.01822522096335888,-0.014307270757853985,0.0003083988558501005,-0.014754902571439743,-0.006976380944252014,-0.02323862351477146,-0.017937256023287773,0.03877364471554756,-0.005412340629845858,0.019320063292980194,-0.0034332440700381994,0.13801899552345276,0.0014400611398741603,-0.009429450146853924,-0.0033151486422866583,-0.02926529198884964,-0.0010916596511378884,-0.03375314176082611,0.05348825454711914,0.010852135717868805,-0.04562240093946457,-0.0188930444419384,-0.006555868778377771,-0.006273028906434774,0.011761968955397606,0.00818447582423687,-0.025232423096895218,0.13410355150699615,0.40544581413269043,0.0015166890807449818,-0.04204104095697403,-0.013966957107186317,-0.015834558755159378,0.10679709911346436,0.042914874851703644,0.011779439635574818,-0.0014300155453383923,-0.04952358081936836,0.12945157289505005,0.13354723155498505,0.01982251927256584,-0.0003536157018970698,-0.007534627337008715,-0.0041167838498950005,0.09163407236337662,0.07744055986404419,0.004003276117146015,-0.020266707986593246,0.03342479467391968,-0.04354453086853027,-0.0015622678911313415,-0.021864978596568108,-0.030464377254247665,-0.036580998450517654,-0.010070298798382282,0.0022992005106061697,-0.0012453473173081875,-0.005830475129187107,0.0058205933310091496,0.025784194469451904,-0.004663365893065929,0.1373412013053894,0.0014365898678079247,0.0433829165995121,-0.09178519248962402,-0.022411728277802467,-0.007879635319113731,0.06809081137180328,-0.004058210179209709,0.11829428374767303,-0.0037158008199185133,-0.006518807262182236,0.009547492489218712,0.2818148136138916,-0.03575613722205162,0.14461606740951538,-0.0022815472912043333,0.00289138057269156,0.015687689185142517,0.20241865515708923,-0.0031396597623825073,-0.0008519265102222562,0.003254897892475128,-0.07853236794471741,-0.018154209479689598,0.015280451625585556,0.17916572093963623,-0.003714451566338539,-0.004161568358540535,-0.030891548842191696,0.005945430602878332,0.00713732372969389,-0.0005478303646668792,0.003536897012963891,-0.008505872450768948,-0.006446393206715584,0.0002773639280349016,-0.04193270206451416,0.3338053226470947,0.03181032836437225,0.10544312000274658,0.23975154757499695,0.0005587908090092242,-0.02301384136080742,-0.010718466714024544,0.007370648439973593,0.09768371284008026,0.019710425287485123,0.0016882997006177902,-0.009175579994916916,-0.003696276107802987,0.04650665447115898,0.011317362077534199,-0.0023338852915912867,0.013348739594221115,0.05155555531382561,-0.030291246250271797,-0.008993218652904034,-0.021145178005099297,0.08556245267391205,-0.05768382176756859,5.252821938483976e-05,0.0019291759235784411,0.009595506824553013,-0.02401660569012165,0.004501008428633213,0.02150658331811428,0.024229926988482475,-0.021921832114458084,-0.005051030777394772,0.08100704103708267,-0.0029933506157249212,0.036992281675338745,0.0022449896205216646,0.1002068743109703,0.010631559416651726,0.020464176312088966,-0.006552437786012888,-0.01883787289261818,-0.03805805742740631,0.10634124279022217,-0.0074209533631801605,-0.004866227973252535,0.04474516212940216,-0.04774320498108864,0.06545193493366241,0.008351842872798443,0.017093604430556297,-0.0060453652404248714,-0.004144648555666208,0.001485321088694036,0.005009221378713846,0.00192946195602417,-0.21230275928974152,-0.004228701815009117,0.1862856149673462,-0.03997163102030754,-0.0037422061432152987,0.010015050880610943,-0.0016807513311505318,0.021686241030693054,-0.003122221678495407,0.0012819248950108886,0.011147791519761086,-0.00714831380173564,-0.008835084736347198,0.0018975242273882031,0.008169448934495449,0.001971631310880184,-0.0051550595089793205,-0.00036220907350070775,-0.03765670582652092,-0.006588938646018505,0.020841248333454132,-0.009780178777873516,0.008780751377344131,0.02521262876689434,0.0169252697378397,-0.0030746422708034515,-0.01445965189486742,0.06636557728052139,0.014686920680105686,-0.02781290002167225,-0.005658993497490883,0.018415391445159912,-0.009795183315873146,0.0027202123310416937,-0.0032817053142935038,-0.02750137262046337,0.07384857535362244,0.2536703050136566,-0.012635293416678905,0.14308364689350128,-0.004755283240228891,-0.04626382142305374,-0.0005541902501136065,0.0006256647757254541,-0.003167911432683468,0.0018583649070933461,0.0072668432258069515,0.0007195991347543895,0.005628250539302826,0.0026532108895480633,-0.004811965394765139,-0.01557934284210205,-0.0024410078767687082,-0.1008034497499466,0.004706820473074913,-0.03128548711538315,-0.002760942094027996,0.00581957446411252,-0.06505484133958817,-0.01237938180565834,-0.018037596717476845,-0.002816735068336129,-0.04295036569237709,0.013854628428816795,-0.04767755791544914,0.26138344407081604,-0.008875303901731968,0.010986866429448128,-0.004627389833331108,0.004568960051983595,-0.017383718863129616,-0.04610523581504822,-0.004826495889574289,0.1934332549571991,0.0007422718335874379,0.010442640632390976,-0.002851002151146531,0.01650136150419712,-0.0010042879730463028,-0.0018556338036432862,-0.009705770760774612,0.031213819980621338,0.001913527143187821,-0.002130413195118308,0.008327181451022625,-0.0036737408954650164,0.007053916342556477,-0.011295674368739128,0.30656278133392334,0.001087905839085579,0.08579953014850616,0.043320171535015106,0.007784849964082241,0.03600400686264038,0.24051909148693085,0.06903831660747528,0.054072700440883636,-0.0035297139547765255,0.09624241292476654,0.006554565392434597,-0.06552927196025848,-0.004928814712911844,-0.0812147930264473,-0.012662244029343128,-0.028308019042015076,0.02936592884361744,-0.03655901923775673,0.047396428883075714,0.016367997974157333,-0.009927383624017239,0.027291426435112953,-0.03237568214535713,-0.060187723487615585,0.0031988252885639668,-0.007139367517083883,0.010953938588500023,0.00010564559488557279,-0.00013482138456311077,0.02656184695661068,0.02055242285132408,0.0232087429612875,-0.01769379712641239,0.007691127248108387,0.047476161271333694,-0.007190796080976725,0.006552289705723524,-0.06908343732357025,0.01470065489411354,0.03726710006594658,0.16564355790615082,-0.02258165553212166,0.044827625155448914,-0.02068674936890602,-0.011316600255668163,-0.006370794493705034,-0.016762182116508484,-0.019496796652674675,0.015307726338505745,0.02765672467648983,0.0035060103982686996,0.061095889657735825,-0.01706652343273163,-0.01998012140393257,0.012795539572834969,-0.012051145546138287,0.01335712056607008,0.008845968171954155,-0.03372344747185707,0.21133802831172943,-0.013723386451601982,0.17360679805278778,-0.015013995580375195,0.012557853013277054,-0.02442352846264839,0.003009383799508214,-0.004966295324265957,-0.009103823453187943,-0.0062670656479895115,-0.0014553555520251393,0.014199594035744667,-0.03332758694887161,-0.0035018092021346092,0.0670798048377037,-0.05746004357933998,-0.05579923093318939,0.008252207189798355,0.005237840581685305,-0.04761620983481407,0.003509764326736331,-0.04927784949541092,0.027307054027915,-0.004781183321028948,-0.09593003988265991,-0.0027698474004864693,0.00824057962745428,0.031100427731871605,0.005466194357722998,-0.017591286450624466,-0.05205025151371956,0.06866943091154099,-0.006722265854477882,-0.002029918832704425,0.1767091006040573,-7.772091521474067e-06,-0.000574007339309901,0.0002072049246635288,0.23863309621810913,0.009297879412770271,-0.006725148297846317,0.025133676826953888,-0.043715763837099075,0.004475896246731281,0.09412455558776855,-0.02059442549943924,-0.07767908275127411,-0.0009654538007453084,0.010739658959209919,0.0051940674893558025,0.006434588227421045,-0.02490590140223503,0.07631773501634598,-0.0275731161236763,0.0022677003871649504,0.011715210042893887,-0.09409359097480774,0.08068477362394333,-0.0014431012095883489,0.02602120116353035,0.001353069907054305,0.03953405097126961,0.013417043723165989,-0.0008672505500726402,-0.006039141211658716,-0.008484303951263428,-0.020787252113223076,-0.00848315004259348,-0.004864308051764965,0.021094337105751038,-0.005285970866680145,0.001262808102183044,-0.011076305992901325,0.007044656202197075,-0.04987737536430359,0.003070257604122162,-0.005625477991998196,-0.02665749005973339,0.00039721131906844676,0.10205652564764023,-0.007883262820541859,-0.012041810899972916,-0.00800673570483923,-0.026232311502099037,0.022309746593236923,0.0006800732226110995,-0.04813557118177414,-0.02813149057328701,-0.005847478285431862,0.3122236132621765,-0.0019217211520299315,-0.019425438717007637,0.03049270249903202,-0.015554460696876049,0.032692935317754745,-0.03236410394310951,0.01152295246720314,0.001169516472145915,-0.006874178536236286,0.01480881217867136,-0.008516300469636917,-0.034259263426065445,0.010230878368020058,0.0039682211354374886,-0.01632762886583805,0.10799974203109741,0.0073707993142306805,-0.004085790365934372,0.024297188967466354,-0.005330395884811878,-0.004501835908740759,-0.010111144743859768,-0.057622186839580536,-0.013808263465762138],\"xaxis\":\"x\",\"yaxis\":\"y\",\"type\":\"histogram\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"value\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"count\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Difference in layer 5 neuron activations between original and ablated context neuron\"},\"barmode\":\"relative\",\"width\":800},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('6cdd3c18-ebbb-4ba6-ba85-2e4132bc85a6');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "px.histogram(difference.cpu().numpy(), title=f\"Difference in layer {layer_to_cache} neuron activations between original and ablated context neuron\", width=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>                            <div id=\"f1b30628-3965-4db8-ad20-db70bfafbdaf\" class=\"plotly-graph-div\" style=\"height:525px; width:800px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"f1b30628-3965-4db8-ad20-db70bfafbdaf\")) {                    Plotly.newPlot(                        \"f1b30628-3965-4db8-ad20-db70bfafbdaf\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"z\":[[-0.004645213019102812,-0.0006136452429927886,0.006211047992110252,-0.002322225132957101,0.23277893662452698,0.09119828045368195,-0.025653963908553123,-0.005280723795294762,0.475567102432251,-0.034190017729997635,-0.05423297733068466,0.004980783443897963,-0.019466059282422066,0.03750162944197655,-0.004625317640602589,-0.05223976820707321,-0.006628438830375671,-0.0011433938052505255,0.0035071875900030136,-0.0006513202679343522,-0.03129849210381508,0.0024591388646513224,0.02765336073935032,0.001678431872278452,-0.006818615831434727,-0.0013570740120485425,0.12331552803516388,0.006186533719301224,-0.004329089540988207,-0.0005642889882437885,0.13134504854679108,0.1344047486782074,0.04212997853755951,-8.100828563328832e-05,0.01962145045399666,0.13554984331130981,-0.018795782700181007,-0.012909294106066227,-0.0064403279684484005,0.01084035262465477,-0.002423809841275215,0.024102481082081795,0.002338384510949254,-0.02377157285809517,0.1279948502779007,-0.010644313879311085,-0.019269390031695366,-0.07665669173002243,-0.030872242525219917,0.02692301571369171,0.07366594672203064,0.0031236805953085423,-0.04073566570878029,-0.006546888034790754,0.013087010011076927,-0.0006539325695484877,0.08187743276357651,-0.004644104745239019,0.006800767965614796,-0.031160205602645874,0.0017054971540346742,-0.026584019884467125,0.0006125188083387911,0.001900800270959735],[-0.003380256239324808,-0.09584038704633713,-0.02766544558107853,0.05313342809677124,0.20201140642166138,-0.00021283567184582353,-0.005416809115558863,-0.004874279722571373,-0.0017170438077300787,-0.013062398880720139,-0.0001338957081316039,0.05430465564131737,0.024049565196037292,0.014560566283762455,0.26702335476875305,-0.018329361453652382,0.026148570701479912,-0.03559798374772072,-0.023088259622454643,-0.029311740770936012,0.03448234125971794,-0.036625463515520096,-0.021770842373371124,0.012280743569135666,0.006972406059503555,-0.0019983553793281317,0.007716454565525055,0.07439247518777847,-0.002367510925978422,-0.012216290459036827,0.04376036673784256,0.01786503754556179,0.03230438008904457,-4.886157694272697e-05,-0.015596008859574795,0.0022216658107936382,0.019405612722039223,-0.009608658030629158,-0.008382480591535568,-0.003082943381741643,-0.027551429346203804,-0.0049604508094489574,0.004959183279424906,-0.013233243487775326,0.07829063385725021,0.005535818170756102,-0.009854353033006191,0.01903490722179413,0.0781283751130104,0.017044471576809883,-0.0026784376241266727,-0.007833919487893581,0.0008231133688241243,-0.004492197185754776,-0.02919813245534897,-0.012031170539557934,-0.038675401359796524,-0.00406522024422884,0.007983917370438576,0.013701402582228184,-0.006909344345331192,0.006315927486866713,0.03573119640350342,-0.04256713017821312],[-0.03846440836787224,0.05503939092159271,-0.007610925007611513,0.04226303473114967,-0.003542704973369837,0.07739277184009552,-0.03821789100766182,0.19483855366706848,0.08405905216932297,-0.026929214596748352,0.13730397820472717,-0.002836344763636589,-0.0024231462739408016,-0.06524313986301422,0.09647706896066666,-0.004153795540332794,0.03496702387928963,-0.0014769633999094367,0.0007161868270486593,-0.015922294929623604,-0.00859666895121336,0.186822772026062,0.01773834601044655,0.004994567483663559,-0.0056625609286129475,-0.004876898135989904,-0.005144287366420031,0.12575224041938782,-0.036264076828956604,-0.0012376487720757723,0.08352196216583252,-0.03464856371283531,0.16168303787708282,-0.006481883581727743,0.015120992437005043,-0.011759885586798191,0.4662923812866211,-0.0001256964314961806,0.05538472160696983,0.003395344829186797,-0.018749697133898735,0.013441191986203194,-0.0011844080872833729,-0.04351048916578293,-0.011930001899600029,-0.020333215594291687,0.0021447099279612303,0.010741347447037697,0.035986825823783875,0.01863458752632141,-0.013434931635856628,0.004832758102566004,-0.006559897214174271,0.06058422476053238,0.004469030071049929,-0.04413075000047684,0.002259110566228628,0.029072843492031097,-0.027805449441075325,-0.009250297211110592,-0.09631276875734329,0.002394384006038308,0.02843928337097168,0.0013212455669417977],[-0.00038139455136843026,-0.005320688243955374,-0.0008561631548218429,-0.0021416256204247475,0.008763321675360203,-0.0036705078091472387,-0.047679513692855835,0.011330514214932919,-0.008641764521598816,-0.0077081043273210526,-0.07201337814331055,-0.024211516603827477,0.07249527424573898,-0.009465648792684078,-0.008552877232432365,2.036022488027811e-05,-0.023946158587932587,0.06188356503844261,-0.013288441114127636,-0.007933609187602997,-0.0067152585834264755,-0.0034554039593786,0.014431487768888474,0.01636660471558571,-0.045327119529247284,0.00871239136904478,-0.009479147382080555,-0.0014034465420991182,0.13572482764720917,-0.0023995577357709408,0.07260772585868835,0.0454045794904232,0.021093666553497314,0.00023902632528916,0.0024472391232848167,0.008172246627509594,0.002755027497187257,0.022070016711950302,0.01828949898481369,0.013978918083012104,0.00029939666274003685,-0.023739326745271683,0.018198275938630104,-0.006178799085319042,-0.0040857489220798016,0.0006665545515716076,-0.008144197054207325,-0.005497039761394262,0.08197489380836487,0.01602174900472164,0.013483285903930664,-0.026553485542535782,-0.038671813905239105,0.36461877822875977,-0.02884887345135212,0.008880972862243652,0.007274139206856489,-0.15119875967502594,0.005923358257859945,-0.016512835398316383,0.055295322090387344,0.006336695980280638,0.08251775056123734,-0.016786737367510796],[-0.011971984058618546,-0.000948500819504261,-0.008206156082451344,0.003746926784515381,0.005254030227661133,-0.0036727702245116234,-0.019498148933053017,-0.011908279731869698,0.02448648400604725,-0.03408602252602577,0.001742583466693759,-0.008616166189312935,-0.0023475668858736753,-0.00716042285785079,0.059091366827487946,-0.0020026646088808775,-0.0028563763480633497,0.7151039838790894,-0.0006852278602309525,-0.00243889051489532,0.08357306569814682,0.08594661951065063,-0.012701064348220825,-0.0068289246410131454,0.0038386269006878138,0.010203057900071144,-0.04113083332777023,-0.004039045423269272,-0.007627981249243021,0.005857041571289301,-0.02986447513103485,0.08259967714548111,-0.024698661640286446,-0.0009670574218034744,0.0032953971531242132,-0.07398638129234314,0.14083242416381836,0.03286191448569298,-0.021708419546484947,0.04532970115542412,0.02075500786304474,0.18267779052257538,0.043853435665369034,0.004376429598778486,-0.0027334385085850954,0.007169910706579685,0.022340571507811546,0.004969383589923382,-0.005891677923500538,-0.06657474488019943,9.280235826736316e-05,0.005743340123444796,-0.04793081805109978,-0.023715930059552193,0.01767909526824951,0.0030600843019783497,0.032750148326158524,0.05318917706608772,-0.10728482156991959,0.2242056131362915,-0.07610709965229034,0.0009231063304468989,0.011235164478421211,0.01210837997496128],[-0.0010622316040098667,-0.05312838405370712,0.0037232860922813416,0.05737198516726494,-0.03457816317677498,0.012936770915985107,-0.005463580135256052,-0.009469049982726574,0.008881386369466782,0.019744638353586197,0.018708670511841774,-0.002232686150819063,0.1211957111954689,0.040669552981853485,0.025166762992739677,0.0017070710891857743,0.028708431869745255,0.006022741552442312,0.2614167034626007,0.0014208020875230432,-0.06447631120681763,0.016764473170042038,0.11732622236013412,0.004105744417756796,-0.004814587067812681,0.012246789410710335,0.10192490369081497,0.17693571746349335,-0.0007356274873018265,-0.03347818925976753,-0.01460955385118723,-0.0061266073025763035,0.0027084138710051775,-0.0054666814394295216,0.0300554521381855,-0.03432834893465042,0.007611540611833334,0.005371890030801296,-0.02243451587855816,0.004771157633513212,0.16913700103759766,0.02193443477153778,0.0390433631837368,0.07397397607564926,-0.005108758807182312,-0.005905346479266882,-0.024828793480992317,0.004662474617362022,-0.002770010381937027,-0.017945047467947006,0.043566860258579254,-0.00487237423658371,0.05656665563583374,0.024963503703475,-0.058777011930942535,0.018058782443404198,-0.037189044058322906,0.11925259977579117,0.016575541347265244,-0.02109733410179615,0.25930845737457275,0.009392132982611656,0.015815215185284615,0.04103565588593483],[0.019390499219298363,0.05333097651600838,0.029388073831796646,0.1564011573791504,-0.005791984032839537,0.433454692363739,-0.024507302790880203,-0.0013034753501415253,-0.0030447840690612793,0.10689831525087357,0.33250898122787476,0.6447740197181702,-0.005973809398710728,0.0079468609765172,-0.004644939675927162,-0.04483107849955559,-0.0028580771759152412,0.05176464468240738,-0.0006939696031622589,0.02337528020143509,0.12098231911659241,0.16007079184055328,-0.008880999870598316,0.08727112412452698,0.011360261589288712,-0.0034169543068856,-0.0052482970058918,0.2624962329864502,0.004252597223967314,-0.002640691353008151,0.16106033325195312,0.04277379438281059,-0.0038910796865820885,-0.07597172260284424,-0.01157904602587223,0.15368898212909698,0.00022672685736324638,0.10313466191291809,-0.009468426927924156,0.1962376981973648,-0.0016221634577959776,0.0002954721567220986,-0.025559306144714355,0.0021601510234177113,-0.010314279235899448,0.0024137983564287424,0.025079475715756416,-0.02590538188815117,-0.04780182987451553,-0.0519254170358181,0.005343396682292223,-0.015992367640137672,0.07725358754396439,-0.005795253906399012,-0.00723810400813818,0.010940434411168098,0.0028690712060779333,-0.008423377759754658,0.010094577446579933,0.005537400953471661,0.00791088305413723,0.004955637268722057,-0.006595000624656677,0.19218173623085022],[0.00789677631109953,0.024150919169187546,-0.008427183143794537,-0.09604676067829132,0.0780588909983635,0.25326481461524963,0.04742222651839256,0.17436707019805908,-0.03446580097079277,-0.015459700487554073,-0.018376491963863373,-0.02600482851266861,0.00284431385807693,-0.02230951562523842,0.004753673914819956,0.010539771988987923,-0.0014892617473378778,-0.01602712646126747,0.027816468849778175,-0.0076279896311461926,-0.008352648466825485,0.1096518412232399,-0.010711866430938244,-0.039188358932733536,0.10321192443370819,-0.02477787621319294,-0.014221061021089554,-0.00023779696493875235,-0.000562500674277544,-0.003789984155446291,0.002650890266522765,0.005614610854536295,0.002112150425091386,-0.0014538327232003212,-0.017902400344610214,-0.008921150118112564,-0.01060411799699068,-0.01430119201540947,0.06111973896622658,-0.012830793857574463,-0.04581665247678757,-0.03418072313070297,-0.003537859534844756,-0.003915900830179453,-0.02235945127904415,0.18568946421146393,-0.0028291677590459585,-0.016676053404808044,-0.06898068636655807,0.041533030569553375,-0.030074963346123695,0.20476014912128448,-0.012250873260200024,0.025306761264801025,0.07820350676774979,-0.0027490605134516954,-0.019432980567216873,0.21428820490837097,0.016151713207364082,0.02630760706961155,0.016709832474589348,-0.004726942162960768,-0.0039007579907774925,-0.007685123011469841],[0.018467744812369347,-0.0063987066969275475,0.03138565644621849,-0.051885586231946945,-0.03129017725586891,-0.00015451233775820583,-0.006551456172019243,0.047724369913339615,-0.005057531408965588,-0.015551531687378883,0.0183008573949337,-0.0018397823441773653,-0.0022385658230632544,-0.014439664781093597,0.021579544991254807,0.013950170017778873,0.008760461583733559,-0.01041736826300621,-0.012676212005317211,-0.033112626522779465,-0.04405989870429039,0.0002095125091727823,-0.006116317585110664,-0.034703001379966736,-0.02199949510395527,0.04073537513613701,0.025159144774079323,-0.029106806963682175,-0.058247994631528854,-0.034595660865306854,-0.04319586977362633,-0.00424548052251339,0.002218489767983556,-0.03242040053009987,0.017039654776453972,-0.048445191234350204,0.18472564220428467,0.05882515385746956,-0.06909164786338806,-0.010895276442170143,0.06825368106365204,0.010713526047766209,0.15993934869766235,-0.00032454918255098164,0.18790467083454132,-0.015733754262328148,-0.0038563215639442205,-0.07407152652740479,-0.01134100928902626,0.014287200756371021,-0.016506247222423553,-0.002446400932967663,0.004075178876519203,0.05573681369423866,-0.005277138203382492,-0.029919516295194626,0.06295528262853622,0.02961098961532116,-0.024952968582510948,0.0002470949839334935,-0.012903451919555664,0.006526879034936428,0.004548890981823206,0.022486120462417603],[0.0007031977293081582,-0.011098173446953297,0.0005036378279328346,0.0032105010468512774,0.06272909045219421,-0.06844544410705566,-0.01033997256308794,0.02556978538632393,0.3316364884376526,0.02378668636083603,0.16603899002075195,0.1012192890048027,-0.0017560970736667514,0.07259687036275864,-0.016242265701293945,-0.04860980436205864,-8.334604353876784e-05,-0.003397071035578847,-0.017157837748527527,-0.004535210318863392,0.034173384308815,-0.03125791624188423,-0.003416928928345442,0.11330373585224152,0.015504170209169388,0.0007054139277897775,0.002143880119547248,0.005326631013303995,0.004203251097351313,0.010523378849029541,0.10482998937368393,-0.0021694002207368612,0.26951536536216736,-0.017837485298514366,-0.0033166292123496532,0.005073225125670433,0.0040822867304086685,0.09451388567686081,0.034647081047296524,0.033915914595127106,-0.005228984169661999,-0.0048005892895162106,0.018097806721925735,-0.014803271740674973,-0.004989855922758579,-0.0017300022300332785,0.004007785581052303,0.018346888944506645,0.005145843606442213,-0.00258070370182395,-0.010825126431882381,0.012089180760085583,-0.0058935899287462234,0.007837159559130669,0.016619116067886353,-0.11683517694473267,-0.030878394842147827,0.03874924033880234,0.01964624598622322,-0.00232789758592844,0.1399078518152237,0.007210484705865383,-0.004307447466999292,0.2699168920516968],[-0.001386851305142045,-0.16956572234630585,-0.014497377909719944,0.14366766810417175,-0.0014249390223994851,-0.00795831996947527,-0.029906118288636208,-0.015408267267048359,0.16690252721309662,0.004093184135854244,0.011372233740985394,0.25740572810173035,-0.037239089608192444,-0.005313648842275143,0.11750657856464386,0.007029336411505938,0.018345076590776443,-0.04573101922869682,0.012454302981495857,0.07771646976470947,-0.009636851027607918,-0.012712768279016018,0.02075181156396866,-0.02213127911090851,0.010591201484203339,0.167741060256958,-0.002430352382361889,-0.0009518603910692036,-0.0028939705807715654,-0.008413197472691536,0.7021030783653259,-0.004593890160322189,-0.05697477236390114,0.03189952298998833,-0.005647123791277409,-0.012817027047276497,-0.01100547518581152,0.030290234833955765,-0.00799307506531477,-0.019384438171982765,-0.006633146665990353,-0.03597930818796158,0.019736655056476593,0.0033234376460313797,-0.05308498814702034,0.0004869652329944074,-0.006691085174679756,0.0040728445164859295,0.00017417187336832285,0.011532073840498924,0.12515859305858612,-0.0024855483788996935,0.00162292190361768,0.02707214467227459,-0.01545510534197092,-0.01008776668459177,-0.0009216934558935463,0.06798722594976425,-0.007839385420084,-3.060316885239445e-05,-0.009295620024204254,-0.0793241411447525,-0.0068739322014153,0.14318665862083435],[-0.000457126327091828,-0.03998026251792908,-0.0031201341189444065,0.11930659413337708,0.004745628219097853,-0.09319791197776794,-0.0013601392274722457,0.012938321568071842,-0.0164520051330328,-0.033740345388650894,0.000602422805968672,-0.0544000081717968,-0.0020822198130190372,-0.01591150462627411,-0.013667628169059753,0.009617476724088192,0.002743704244494438,0.0019029849208891392,-0.013422761112451553,0.005748941097408533,-0.037115808576345444,0.0012604250805452466,-0.016096362844109535,-0.1501796692609787,-0.07030007243156433,-0.04598483070731163,-0.054097045212984085,0.13845369219779968,-0.034750375896692276,-0.021337369456887245,0.006293851416558027,-0.0015634669689461589,0.0017558896215632558,0.002428871812298894,-0.020300526171922684,-0.007384138181805611,-0.004491092637181282,-0.016195230185985565,-0.0016314112581312656,-0.005505576264113188,-0.001161353662610054,-0.004724513739347458,0.005980781279504299,0.0312948040664196,-0.017268994823098183,-0.029777254909276962,0.018768658861517906,0.44961270689964294,0.008118866011500359,-0.006278596818447113,-0.02874174527823925,0.1418476402759552,-0.018276436254382133,-0.004730530083179474,0.022858452051877975,-0.03905598074197769,-0.003774165641516447,0.022160721942782402,-0.006822068244218826,-0.0222198236733675,-0.0031062159687280655,0.015547585673630238,0.0012053446844220161,0.24697662889957428],[0.01726004108786583,0.03361538425087929,-0.020579148083925247,0.0005952324136160314,0.059178225696086884,-0.0113602289929986,-0.0010688401525840163,-0.0073845782317221165,0.02034432627260685,0.018285218626260757,0.015984006226062775,0.0032236650586128235,-0.023425253108143806,0.032531652599573135,-0.019351154565811157,0.15788491070270538,-0.0015374587383121252,0.0438021644949913,0.03899456188082695,0.005289331544190645,0.04402501881122589,-0.010196664370596409,0.045799873769283295,-0.020681068301200867,-0.02181635983288288,-0.013764968141913414,0.018948892131447792,0.02005469612777233,-0.04877547547221184,-0.010378377512097359,-0.08346281945705414,-0.019546763971447945,-0.0061738514341413975,-0.005458686966449022,-0.0019041136838495731,-0.0038813783321529627,0.0281821321696043,-0.022431975230574608,0.001682924572378397,0.08426415920257568,-0.020807703956961632,0.0016358838183805346,0.03728383779525757,-0.029339265078306198,0.007681053131818771,0.11926102638244629,-0.0010841373587027192,-0.006671900395303965,-0.003899335628375411,0.12526938319206238,-0.009594770148396492,0.007146656513214111,0.2980741262435913,0.0034718168899416924,0.019651737064123154,-0.004924190696328878,-0.043529342859983444,-0.006110643036663532,-0.0034849392250180244,-0.00737681845203042,-0.0033208588138222694,-0.01167556457221508,0.00030056684045121074,0.20641785860061646],[0.08183722198009491,0.028174269944429398,-0.006698673125356436,0.0010332403471693397,-0.002291383920237422,-0.0033757551573216915,-0.00753322197124362,-0.0018931458471342921,0.019904419779777527,-0.013701768592000008,-0.015497997403144836,0.0176352821290493,0.06595146656036377,0.11633270978927612,-0.013472565449774265,0.24593667685985565,0.011428366415202618,0.07246765494346619,-0.013047810643911362,0.018081676214933395,-0.014121259562671185,0.0075004808604717255,-0.013510839082300663,-0.015663672238588333,0.010975268669426441,-0.013771751895546913,0.01579905115067959,0.009510263800621033,-0.1245226189494133,-0.11089810729026794,0.011421085335314274,-0.007148204371333122,-0.015153283253312111,0.010475683026015759,-0.009670669212937355,-0.02466120757162571,-0.0019146676640957594,-0.07029943913221359,0.006173625588417053,0.0012999781174585223,-0.06499486416578293,0.00581437349319458,-0.024107711389660835,0.06720402091741562,-0.0071667395532131195,0.027964098379015923,-0.004705394152551889,-0.0112041300162673,-0.011495262384414673,0.03670451045036316,-0.04268771782517433,0.021465154364705086,0.02688484638929367,-0.005603729281574488,0.00590489199385047,0.014251607470214367,-0.004824754316359758,-0.008417175151407719,-0.030222926288843155,0.055705223232507706,0.15783314406871796,-0.002907812362536788,-0.013279760256409645,0.006261605303734541],[-0.003430156037211418,-0.008986220695078373,-0.004338465165346861,-0.0027498058043420315,0.004587468691170216,-0.03217482194304466,0.01990473084151745,0.05330314859747887,0.11668094247579575,0.07740889489650726,-0.01696637272834778,0.0011429855367168784,-0.0030606871005147696,-0.03000987134873867,0.06922116875648499,-0.0028920506592839956,-0.005907099228352308,0.03855491429567337,-0.0026816027238965034,0.0007276231772266328,-0.012625506147742271,0.1419343203306198,-0.011388977989554405,0.0024175760336220264,0.0024989466182887554,-0.06170206889510155,-0.004142296500504017,0.005300722550600767,-0.01143167819827795,0.053042445331811905,0.03914249688386917,0.160530224442482,-0.02241348661482334,0.3769306540489197,0.1330377161502838,0.0036284641828387976,-0.0023240745067596436,-0.0035106840077787638,-0.0008417719509452581,0.052458256483078,0.06342276930809021,-0.05779692530632019,0.0009666014811955392,0.011660631746053696,-0.0016172985779121518,0.011291365139186382,-0.0076523288153111935,-0.007639871444553137,0.0039843302220106125,-0.0088134640827775,-0.01414224598556757,-0.006614453159272671,0.001986844465136528,0.0011204401962459087,-0.008894763886928558,0.01378717739135027,0.006797072011977434,0.00443745544180274,0.11156454682350159,0.07290377467870712,0.011270458810031414,-0.006055859383195639,-0.006146946921944618,-0.007420094683766365],[0.10880280286073685,-8.84074397617951e-05,0.16606496274471283,0.03330808877944946,-0.005711507052183151,0.015811162069439888,-0.07801683992147446,-0.006777368485927582,0.092556431889534,-0.01714608445763588,0.009059448726475239,0.019067853689193726,-0.007663468364626169,-0.043095387518405914,0.03398478403687477,0.029127486050128937,-0.008028143085539341,0.0073546189814805984,0.1828276813030243,0.019436893984675407,0.04073994979262352,0.001902354066260159,0.004665250889956951,-0.025351041927933693,-0.07044246047735214,0.018658651039004326,0.009803983382880688,-0.00977142434567213,0.0750952884554863,0.15327590703964233,0.01896848902106285,-0.00761126633733511,-0.010631305165588856,-0.0017967040184885263,-0.037685636430978775,0.2375953495502472,0.024706043303012848,-0.06615694612264633,-0.006485410965979099,-0.0017880332889035344,0.0015232511796057224,-0.024319974705576897,-0.02332351729273796,-0.005580633878707886,0.023989224806427956,0.0034704813733696938,-0.0003337182861287147,0.03359571844339371,-0.0007085782126523554,-0.04302370920777321,-0.007052919827401638,-0.001104839495383203,-0.0015286824200302362,0.0025068954564630985,-0.03358331322669983,-0.003511553630232811,0.06422897428274155,0.04000869393348694,-0.007797854486852884,-0.0023035570047795773,0.29567965865135193,-0.002570685464888811,-0.002939834725111723,0.0076227509416639805],[-0.006286390125751495,0.06972228735685349,0.009650676511228085,-0.09512551873922348,-0.08068141341209412,-0.005132943391799927,0.03617839142680168,-0.0039693391881883144,-0.0025103723164647818,-0.009762079454958439,-0.008541015908122063,-0.008257094770669937,0.030181679874658585,-0.0037664619740098715,0.10617286711931229,0.051624514162540436,0.0034024694468826056,-0.00259377621114254,0.3230321705341339,-0.06642479449510574,0.06410222500562668,-0.017422232776880264,0.0433245450258255,-0.002114349976181984,-0.010414163582026958,0.019602864980697632,0.018185583874583244,-0.05249035358428955,-0.03578391671180725,-0.0036094910465180874,-0.000678405980579555,-0.0076088570058345795,0.025984464213252068,0.03707066550850868,-0.018633155152201653,0.19237466156482697,-0.0037924458738416433,0.01789741963148117,0.013406962156295776,0.08204109966754913,-0.0022507484536617994,-0.019943153485655785,-0.009909553453326225,-0.0017817873740568757,-0.024083683267235756,-0.0111572640016675,-0.002352713607251644,0.010085896588861942,-0.0017198289278894663,-0.03498097136616707,-0.014404943212866783,-0.004392402712255716,0.049131959676742554,0.011584492400288582,-0.014011221937835217,-0.024410312995314598,-0.011385711841285229,-0.03652048110961914,0.03036557510495186,-0.005891698878258467,-0.0015782585833221674,-0.015826530754566193,-0.003998700529336929,-0.04266894981265068],[-0.008434169925749302,0.03635666146874428,0.006451057735830545,-0.018399618566036224,-0.009809603914618492,0.01833895593881607,-0.006078475620597601,0.22527770698070526,-0.01168537512421608,0.005056797526776791,-0.002161506563425064,0.09650868922472,0.0011392743326723576,-0.005252891220152378,0.06451069563627243,-0.03725253790616989,0.1676637977361679,-0.09150703251361847,0.008580648340284824,-0.001435623737052083,-0.011402866803109646,-0.003917403053492308,0.0075574712827801704,-0.002388652879744768,-0.08813897520303726,-0.01076489593833685,0.032735977321863174,0.009191588498651981,-0.00800092238932848,-0.0180086437612772,-0.11261468380689621,0.037919316440820694,0.0009748057345859706,-0.04047664254903793,0.005821756552904844,-0.0004936035256832838,0.25573912262916565,-0.007076680194586515,-0.007721832953393459,-0.008724418468773365,0.004357947036623955,0.006793621461838484,0.10502239316701889,0.0016076405299827456,-0.0061688353307545185,-0.009314843453466892,0.04424986615777016,0.0034328263718634844,0.0011769274715334177,-0.003238472854718566,0.3681802451610565,0.005782471038401127,-0.02593410573899746,0.008220376446843147,0.01277749240398407,0.004134156741201878,-0.00012138535385020077,0.024717874825000763,-0.010410076007246971,-0.0023796046152710915,-0.0011412969324737787,-0.008064273744821548,0.003630375489592552,0.004866226576268673],[-0.009563964791595936,-0.021202633157372475,0.0003320029645692557,-0.0002730156120378524,0.006500359624624252,-0.005530693102627993,-0.011651569046080112,0.008563892915844917,0.00023510196479037404,-0.00602139625698328,-0.008357232436537743,-0.004468056373298168,0.006194030400365591,0.03319437429308891,-0.0030667639803141356,0.002814425388351083,0.035355035215616226,-0.028481077402830124,0.05490719899535179,0.010853728279471397,0.11014627665281296,-0.029138820245862007,-0.014762120321393013,0.00031282109557650983,0.00087525270646438,0.13134299218654633,0.0033766028936952353,-0.0004918617196381092,-0.0029558404348790646,-0.022689932957291603,0.009330738335847855,-0.0054794177412986755,0.009236037731170654,0.007872565649449825,-0.024570567533373833,0.0014873010804876685,0.004937858320772648,0.03555239737033844,-0.02141241915524006,-0.007951817475259304,0.03462611511349678,0.010282238945364952,-0.03979173302650452,-0.005732805468142033,-0.01711372844874859,0.0012824798468500376,-0.007210528012365103,0.031061207875609398,-0.0019005981739610434,-0.039388373494148254,0.0140683613717556,-0.0033107756171375513,-0.0055655864998698235,0.015286808833479881,0.016343267634510994,0.1081511452794075,-0.0016034077852964401,0.46433600783348083,0.01766033284366131,-0.005684328731149435,-0.008740889839828014,-0.01706239953637123,-0.004077380523085594,0.00048207445070147514],[-0.006619768217206001,0.0007684135343879461,-0.06095748394727707,-0.010779956355690956,5.505003719008528e-05,-0.003819103818386793,-0.010616413317620754,0.02705393359065056,-0.04979003593325615,0.14397843182086945,0.0011796575272455812,0.02072046883404255,-0.011525535956025124,0.003121545072644949,0.0025810261722654104,-0.01766209304332733,0.1952013373374939,0.0024459809064865112,-0.012508227489888668,-0.01442317757755518,-0.008623972535133362,0.007272740360349417,0.02260281704366207,0.009376315400004387,-0.0358230359852314,-0.02093653567135334,-0.002304522320628166,-0.016963467001914978,-0.0049538929015398026,-0.007205733563750982,-0.031994376331567764,-0.0026386042591184378,0.0356132835149765,0.007091015111654997,0.10718517005443573,-0.035119980573654175,-0.010877256281673908,-0.023249130696058273,-0.07879941910505295,-0.0011116963578388095,-0.04503946378827095,0.17086076736450195,-0.002129456726834178,0.08004669845104218,0.00475337915122509,0.14789140224456787,0.12220489233732224,-0.020711509510874748,-0.01318239513784647,-0.0009795891819521785,-0.02741638757288456,0.023379411548376083,0.0010440037585794926,-0.0028736635576933622,0.0008303320500999689,0.004096638411283493,-0.008826647885143757,-0.019314268603920937,-0.04237856715917587,-0.012535655871033669,0.001890754560008645,0.11748742312192917,0.03559604659676552,-0.002285158960148692],[0.004185312893241644,0.022144082933664322,-0.0014040893875062466,-0.001897743670269847,0.04944509267807007,0.01776268146932125,0.011356507427990437,-0.04441734030842781,-0.009513605386018753,0.027786262333393097,-0.025412552058696747,0.022508664056658745,-0.015743231400847435,0.2729165256023407,-0.009756569750607014,-0.02571229264140129,0.02034592069685459,-0.008710525929927826,-0.004963724408298731,-0.00929989106953144,0.02016943320631981,-0.010220210999250412,0.03769482299685478,-0.00754699157550931,0.05218498781323433,0.0008872825419530272,0.08541427552700043,0.02456856705248356,0.08538840711116791,-0.05951105058193207,0.012458553537726402,-0.015515519306063652,0.010159734636545181,0.0689728856086731,-0.034479156136512756,0.16399624943733215,-0.049982063472270966,0.00020231390953995287,-0.004125971347093582,-0.06825835257768631,0.06558854132890701,0.013802263885736465,0.0008310135453939438,0.017802471294999123,0.09520474076271057,-0.04871523007750511,-0.021026020869612694,0.0061122397892177105,0.1222129613161087,0.0029381385538727045,0.04998905211687088,-0.003611804684624076,-0.0631658136844635,-0.0058439080603420734,-0.03773866221308708,0.0006563400384038687,0.10272485017776489,-0.010360436514019966,0.08872393518686295,0.0635119378566742,-0.001708125346340239,0.04725271090865135,0.022460073232650757,-0.0024894645903259516],[0.0048418547958135605,0.0062646409496665,0.0008174501708708704,0.013216438703238964,0.006000896450132132,-0.005013995338231325,-0.022229226306080818,-0.015498078428208828,-0.042715441435575485,0.36803004145622253,-0.07112967222929001,-0.041652947664260864,-0.00030510351643897593,-0.015243200585246086,-0.002942809369415045,-0.05135973542928696,-0.03044879250228405,0.022483015432953835,0.0911000594496727,0.012549537234008312,-0.011926837265491486,-0.002193296793848276,0.13494278490543365,-0.0012723043328151107,0.008968256413936615,0.005450306925922632,-0.004720342345535755,-0.02085121162235737,-0.01964847929775715,-0.005046359729021788,0.00980594102293253,-0.039496004581451416,-0.008213968947529793,-0.008124150335788727,-0.0027419542893767357,0.02412932924926281,0.014900320209562778,-0.03876253962516785,0.13825230300426483,0.008772013708949089,-0.002713114721700549,0.012623093090951443,0.0023085512220859528,0.012435686774551868,-0.018935177475214005,0.19905485212802887,-0.0047802492044866085,-0.004849446937441826,0.05828786641359329,0.008615112863481045,0.028957339003682137,-0.008389518596231937,-0.000234790044487454,0.03394897282123566,-0.00039802282117307186,0.009999164380133152,0.0005598191055469215,-0.001690863398835063,0.0031947586685419083,-0.003161469241604209,-0.0059798527508974075,-0.006496512331068516,0.0012028454802930355,-0.005960582289844751],[-0.005062402691692114,-0.0016604416305199265,0.008943780325353146,0.0061205592937767506,-0.01354395691305399,0.004063543397933245,0.0656934380531311,0.10855761170387268,0.002766466001048684,0.015515872277319431,0.0919347032904625,-0.0033125746995210648,-0.003478697035461664,0.0011752303689718246,0.003606051905080676,-0.0038120143581181765,0.031398482620716095,-0.004691349342465401,0.008881003595888615,0.023500362411141396,0.003138356376439333,0.02686181478202343,0.004147127270698547,0.00021757105423603207,-0.008492061868309975,-0.0010400093160569668,0.0011780103668570518,-0.07982251048088074,0.010167448781430721,5.554383824346587e-05,0.02143412083387375,0.004075644072145224,0.008399573154747486,0.050826650112867355,-0.05633855611085892,-0.03339773043990135,0.28793519735336304,-0.028594497591257095,0.12135067582130432,0.0013808244839310646,-0.008517961017787457,0.025457527488470078,-0.008553283289074898,-0.004316060338169336,-0.0020054320339113474,0.008603936992585659,0.06479892134666443,0.004998333752155304,-0.028956051915884018,-0.0077174329198896885,0.02420121245086193,0.0039058742113411427,-0.013592272996902466,-0.03428148478269577,-0.014637303538620472,0.14905105531215668,-0.00034011504612863064,-0.006364346016198397,-0.01728605479001999,0.018105005845427513,-0.009558763355016708,-0.01113666407763958,-0.010058940388262272,-0.0014264472993090749],[-0.013765932060778141,-0.0171009860932827,0.04905436560511589,-0.10371659696102142,-0.0073236762546002865,-0.08865631371736526,-0.00706460140645504,0.3285045623779297,0.006808524485677481,-0.003716197097674012,-0.004848439712077379,-0.00849424209445715,-0.032225146889686584,0.01975606381893158,-0.006351508665829897,0.1807904988527298,0.002604822628200054,0.031516749411821365,-0.008392172865569592,0.014482589438557625,-0.030743345618247986,-0.0029952791519463062,-0.012704668566584587,-0.00953291729092598,-0.006173840258270502,-0.05312345549464226,0.003179988358169794,0.014878222718834877,0.046956371515989304,-0.0005900162504985929,-0.0008827131823636591,0.012729627080261707,0.05626939982175827,0.010052453726530075,0.02024155668914318,-0.00042419866076670587,0.006481311749666929,0.02463172748684883,-0.07359142601490021,0.005615576636046171,-0.00599196320399642,-0.0036325587425380945,-0.004744841251522303,-0.00643210019916296,-0.03376389294862747,0.0007068978156894445,-0.048427484929561615,-0.020728519186377525,-0.004445121623575687,0.014776741154491901,0.05915725603699684,0.08184799551963806,0.04562787339091301,0.03124392405152321,-0.024494489654898643,-0.029142150655388832,0.06907393038272858,0.004327760543674231,0.15357568860054016,-0.00029522605473175645,-0.0004049324197694659,0.03668036311864853,0.017053475603461266,-0.003721818095073104],[0.25457844138145447,-0.0022196092177182436,-0.013193887658417225,-0.00974801741540432,0.11705756932497025,-0.0021530683152377605,0.003734542988240719,0.01837191730737686,-0.014920006506145,0.11165928095579147,0.087893545627594,0.08338312804698944,-0.010616310872137547,-0.0007391658728010952,0.1255163550376892,-0.002622986678034067,-0.010789536871016026,-0.005751191172748804,-0.0024054080713540316,0.016988372430205345,-0.035737115889787674,0.0035568717867136,0.007158106658607721,0.05468430742621422,-0.0006034895195625722,-0.000842469627968967,0.010537071153521538,-0.01229765359312296,0.009177710860967636,-0.00536999711766839,0.04751163348555565,0.0005898430827073753,0.004800737835466862,-0.002531446050852537,0.009670207276940346,0.030652372166514397,-0.061398062855005264,-0.0021500701550394297,-0.003778071841225028,-0.0014558351831510663,0.013892286457121372,0.0021874886006116867,0.053764842450618744,0.0595344640314579,0.017411671578884125,0.009198994375765324,0.0017600590363144875,-0.010746670886874199,0.04664795100688934,-0.001364925759844482,-0.1127227321267128,0.0007056238246150315,-0.0239674374461174,-0.0039194729179143906,0.022042449563741684,0.003003404475748539,-0.06318534165620804,0.0027487874031066895,0.1561419665813446,0.024798531085252762,0.05312056466937065,-0.018069377169013023,0.01921282336115837,-0.015287330374121666],[0.009897316806018353,-0.0044362847693264484,-0.10346078872680664,0.0006315418286249042,0.004240548238158226,0.0445525236427784,-0.002899657702073455,0.003096260828897357,0.007907029241323471,2.7386839065002277e-05,0.06029539927840233,0.004758127965033054,0.00568819185718894,0.006763231009244919,-0.01838696375489235,0.014819796197116375,0.0066917575895786285,-0.006849256809800863,0.0005701584741473198,-0.029365645721554756,-0.0010684097651392221,-0.005470482166856527,-0.10448210686445236,-0.0762324258685112,0.012111281976103783,-0.22258837521076202,0.12987020611763,-0.005190607625991106,0.05476167052984238,0.014025910757482052,0.008572500199079514,-0.06545866280794144,0.006106723099946976,-0.01822522096335888,-0.014307270757853985,0.0003083988558501005,-0.014754902571439743,-0.006976380944252014,-0.02323862351477146,-0.017937256023287773,0.03877364471554756,-0.005412340629845858,0.019320063292980194,-0.0034332440700381994,0.13801899552345276,0.0014400611398741603,-0.009429450146853924,-0.0033151486422866583,-0.02926529198884964,-0.0010916596511378884,-0.03375314176082611,0.05348825454711914,0.010852135717868805,-0.04562240093946457,-0.0188930444419384,-0.006555868778377771,-0.006273028906434774,0.011761968955397606,0.00818447582423687,-0.025232423096895218,0.13410355150699615,0.40544581413269043,0.0015166890807449818,-0.04204104095697403],[-0.013966957107186317,-0.015834558755159378,0.10679709911346436,0.042914874851703644,0.011779439635574818,-0.0014300155453383923,-0.04952358081936836,0.12945157289505005,0.13354723155498505,0.01982251927256584,-0.0003536157018970698,-0.007534627337008715,-0.0041167838498950005,0.09163407236337662,0.07744055986404419,0.004003276117146015,-0.020266707986593246,0.03342479467391968,-0.04354453086853027,-0.0015622678911313415,-0.021864978596568108,-0.030464377254247665,-0.036580998450517654,-0.010070298798382282,0.0022992005106061697,-0.0012453473173081875,-0.005830475129187107,0.0058205933310091496,0.025784194469451904,-0.004663365893065929,0.1373412013053894,0.0014365898678079247,0.0433829165995121,-0.09178519248962402,-0.022411728277802467,-0.007879635319113731,0.06809081137180328,-0.004058210179209709,0.11829428374767303,-0.0037158008199185133,-0.006518807262182236,0.009547492489218712,0.2818148136138916,-0.03575613722205162,0.14461606740951538,-0.0022815472912043333,0.00289138057269156,0.015687689185142517,0.20241865515708923,-0.0031396597623825073,-0.0008519265102222562,0.003254897892475128,-0.07853236794471741,-0.018154209479689598,0.015280451625585556,0.17916572093963623,-0.003714451566338539,-0.004161568358540535,-0.030891548842191696,0.005945430602878332,0.00713732372969389,-0.0005478303646668792,0.003536897012963891,-0.008505872450768948],[-0.006446393206715584,0.0002773639280349016,-0.04193270206451416,0.3338053226470947,0.03181032836437225,0.10544312000274658,0.23975154757499695,0.0005587908090092242,-0.02301384136080742,-0.010718466714024544,0.007370648439973593,0.09768371284008026,0.019710425287485123,0.0016882997006177902,-0.009175579994916916,-0.003696276107802987,0.04650665447115898,0.011317362077534199,-0.0023338852915912867,0.013348739594221115,0.05155555531382561,-0.030291246250271797,-0.008993218652904034,-0.021145178005099297,0.08556245267391205,-0.05768382176756859,5.252821938483976e-05,0.0019291759235784411,0.009595506824553013,-0.02401660569012165,0.004501008428633213,0.02150658331811428,0.024229926988482475,-0.021921832114458084,-0.005051030777394772,0.08100704103708267,-0.0029933506157249212,0.036992281675338745,0.0022449896205216646,0.1002068743109703,0.010631559416651726,0.020464176312088966,-0.006552437786012888,-0.01883787289261818,-0.03805805742740631,0.10634124279022217,-0.0074209533631801605,-0.004866227973252535,0.04474516212940216,-0.04774320498108864,0.06545193493366241,0.008351842872798443,0.017093604430556297,-0.0060453652404248714,-0.004144648555666208,0.001485321088694036,0.005009221378713846,0.00192946195602417,-0.21230275928974152,-0.004228701815009117,0.1862856149673462,-0.03997163102030754,-0.0037422061432152987,0.010015050880610943],[-0.0016807513311505318,0.021686241030693054,-0.003122221678495407,0.0012819248950108886,0.011147791519761086,-0.00714831380173564,-0.008835084736347198,0.0018975242273882031,0.008169448934495449,0.001971631310880184,-0.0051550595089793205,-0.00036220907350070775,-0.03765670582652092,-0.006588938646018505,0.020841248333454132,-0.009780178777873516,0.008780751377344131,0.02521262876689434,0.0169252697378397,-0.0030746422708034515,-0.01445965189486742,0.06636557728052139,0.014686920680105686,-0.02781290002167225,-0.005658993497490883,0.018415391445159912,-0.009795183315873146,0.0027202123310416937,-0.0032817053142935038,-0.02750137262046337,0.07384857535362244,0.2536703050136566,-0.012635293416678905,0.14308364689350128,-0.004755283240228891,-0.04626382142305374,-0.0005541902501136065,0.0006256647757254541,-0.003167911432683468,0.0018583649070933461,0.0072668432258069515,0.0007195991347543895,0.005628250539302826,0.0026532108895480633,-0.004811965394765139,-0.01557934284210205,-0.0024410078767687082,-0.1008034497499466,0.004706820473074913,-0.03128548711538315,-0.002760942094027996,0.00581957446411252,-0.06505484133958817,-0.01237938180565834,-0.018037596717476845,-0.002816735068336129,-0.04295036569237709,0.013854628428816795,-0.04767755791544914,0.26138344407081604,-0.008875303901731968,0.010986866429448128,-0.004627389833331108,0.004568960051983595],[-0.017383718863129616,-0.04610523581504822,-0.004826495889574289,0.1934332549571991,0.0007422718335874379,0.010442640632390976,-0.002851002151146531,0.01650136150419712,-0.0010042879730463028,-0.0018556338036432862,-0.009705770760774612,0.031213819980621338,0.001913527143187821,-0.002130413195118308,0.008327181451022625,-0.0036737408954650164,0.007053916342556477,-0.011295674368739128,0.30656278133392334,0.001087905839085579,0.08579953014850616,0.043320171535015106,0.007784849964082241,0.03600400686264038,0.24051909148693085,0.06903831660747528,0.054072700440883636,-0.0035297139547765255,0.09624241292476654,0.006554565392434597,-0.06552927196025848,-0.004928814712911844,-0.0812147930264473,-0.012662244029343128,-0.028308019042015076,0.02936592884361744,-0.03655901923775673,0.047396428883075714,0.016367997974157333,-0.009927383624017239,0.027291426435112953,-0.03237568214535713,-0.060187723487615585,0.0031988252885639668,-0.007139367517083883,0.010953938588500023,0.00010564559488557279,-0.00013482138456311077,0.02656184695661068,0.02055242285132408,0.0232087429612875,-0.01769379712641239,0.007691127248108387,0.047476161271333694,-0.007190796080976725,0.006552289705723524,-0.06908343732357025,0.01470065489411354,0.03726710006594658,0.16564355790615082,-0.02258165553212166,0.044827625155448914,-0.02068674936890602,-0.011316600255668163],[-0.006370794493705034,-0.016762182116508484,-0.019496796652674675,0.015307726338505745,0.02765672467648983,0.0035060103982686996,0.061095889657735825,-0.01706652343273163,-0.01998012140393257,0.012795539572834969,-0.012051145546138287,0.01335712056607008,0.008845968171954155,-0.03372344747185707,0.21133802831172943,-0.013723386451601982,0.17360679805278778,-0.015013995580375195,0.012557853013277054,-0.02442352846264839,0.003009383799508214,-0.004966295324265957,-0.009103823453187943,-0.0062670656479895115,-0.0014553555520251393,0.014199594035744667,-0.03332758694887161,-0.0035018092021346092,0.0670798048377037,-0.05746004357933998,-0.05579923093318939,0.008252207189798355,0.005237840581685305,-0.04761620983481407,0.003509764326736331,-0.04927784949541092,0.027307054027915,-0.004781183321028948,-0.09593003988265991,-0.0027698474004864693,0.00824057962745428,0.031100427731871605,0.005466194357722998,-0.017591286450624466,-0.05205025151371956,0.06866943091154099,-0.006722265854477882,-0.002029918832704425,0.1767091006040573,-7.772091521474067e-06,-0.000574007339309901,0.0002072049246635288,0.23863309621810913,0.009297879412770271,-0.006725148297846317,0.025133676826953888,-0.043715763837099075,0.004475896246731281,0.09412455558776855,-0.02059442549943924,-0.07767908275127411,-0.0009654538007453084,0.010739658959209919,0.0051940674893558025],[0.006434588227421045,-0.02490590140223503,0.07631773501634598,-0.0275731161236763,0.0022677003871649504,0.011715210042893887,-0.09409359097480774,0.08068477362394333,-0.0014431012095883489,0.02602120116353035,0.001353069907054305,0.03953405097126961,0.013417043723165989,-0.0008672505500726402,-0.006039141211658716,-0.008484303951263428,-0.020787252113223076,-0.00848315004259348,-0.004864308051764965,0.021094337105751038,-0.005285970866680145,0.001262808102183044,-0.011076305992901325,0.007044656202197075,-0.04987737536430359,0.003070257604122162,-0.005625477991998196,-0.02665749005973339,0.00039721131906844676,0.10205652564764023,-0.007883262820541859,-0.012041810899972916,-0.00800673570483923,-0.026232311502099037,0.022309746593236923,0.0006800732226110995,-0.04813557118177414,-0.02813149057328701,-0.005847478285431862,0.3122236132621765,-0.0019217211520299315,-0.019425438717007637,0.03049270249903202,-0.015554460696876049,0.032692935317754745,-0.03236410394310951,0.01152295246720314,0.001169516472145915,-0.006874178536236286,0.01480881217867136,-0.008516300469636917,-0.034259263426065445,0.010230878368020058,0.0039682211354374886,-0.01632762886583805,0.10799974203109741,0.0073707993142306805,-0.004085790365934372,0.024297188967466354,-0.005330395884811878,-0.004501835908740759,-0.010111144743859768,-0.057622186839580536,-0.013808263465762138]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"Difference: %{z:.4f}\\u003cbr\\u003eNeuron: %{customdata}\",\"customdata\":[[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63],[64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127],[128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191],[192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255],[256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319],[320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383],[384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447],[448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511],[512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575],[576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639],[640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703],[704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767],[768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800,801,802,803,804,805,806,807,808,809,810,811,812,813,814,815,816,817,818,819,820,821,822,823,824,825,826,827,828,829,830,831],[832,833,834,835,836,837,838,839,840,841,842,843,844,845,846,847,848,849,850,851,852,853,854,855,856,857,858,859,860,861,862,863,864,865,866,867,868,869,870,871,872,873,874,875,876,877,878,879,880,881,882,883,884,885,886,887,888,889,890,891,892,893,894,895],[896,897,898,899,900,901,902,903,904,905,906,907,908,909,910,911,912,913,914,915,916,917,918,919,920,921,922,923,924,925,926,927,928,929,930,931,932,933,934,935,936,937,938,939,940,941,942,943,944,945,946,947,948,949,950,951,952,953,954,955,956,957,958,959],[960,961,962,963,964,965,966,967,968,969,970,971,972,973,974,975,976,977,978,979,980,981,982,983,984,985,986,987,988,989,990,991,992,993,994,995,996,997,998,999,1000,1001,1002,1003,1004,1005,1006,1007,1008,1009,1010,1011,1012,1013,1014,1015,1016,1017,1018,1019,1020,1021,1022,1023],[1024,1025,1026,1027,1028,1029,1030,1031,1032,1033,1034,1035,1036,1037,1038,1039,1040,1041,1042,1043,1044,1045,1046,1047,1048,1049,1050,1051,1052,1053,1054,1055,1056,1057,1058,1059,1060,1061,1062,1063,1064,1065,1066,1067,1068,1069,1070,1071,1072,1073,1074,1075,1076,1077,1078,1079,1080,1081,1082,1083,1084,1085,1086,1087],[1088,1089,1090,1091,1092,1093,1094,1095,1096,1097,1098,1099,1100,1101,1102,1103,1104,1105,1106,1107,1108,1109,1110,1111,1112,1113,1114,1115,1116,1117,1118,1119,1120,1121,1122,1123,1124,1125,1126,1127,1128,1129,1130,1131,1132,1133,1134,1135,1136,1137,1138,1139,1140,1141,1142,1143,1144,1145,1146,1147,1148,1149,1150,1151],[1152,1153,1154,1155,1156,1157,1158,1159,1160,1161,1162,1163,1164,1165,1166,1167,1168,1169,1170,1171,1172,1173,1174,1175,1176,1177,1178,1179,1180,1181,1182,1183,1184,1185,1186,1187,1188,1189,1190,1191,1192,1193,1194,1195,1196,1197,1198,1199,1200,1201,1202,1203,1204,1205,1206,1207,1208,1209,1210,1211,1212,1213,1214,1215],[1216,1217,1218,1219,1220,1221,1222,1223,1224,1225,1226,1227,1228,1229,1230,1231,1232,1233,1234,1235,1236,1237,1238,1239,1240,1241,1242,1243,1244,1245,1246,1247,1248,1249,1250,1251,1252,1253,1254,1255,1256,1257,1258,1259,1260,1261,1262,1263,1264,1265,1266,1267,1268,1269,1270,1271,1272,1273,1274,1275,1276,1277,1278,1279],[1280,1281,1282,1283,1284,1285,1286,1287,1288,1289,1290,1291,1292,1293,1294,1295,1296,1297,1298,1299,1300,1301,1302,1303,1304,1305,1306,1307,1308,1309,1310,1311,1312,1313,1314,1315,1316,1317,1318,1319,1320,1321,1322,1323,1324,1325,1326,1327,1328,1329,1330,1331,1332,1333,1334,1335,1336,1337,1338,1339,1340,1341,1342,1343],[1344,1345,1346,1347,1348,1349,1350,1351,1352,1353,1354,1355,1356,1357,1358,1359,1360,1361,1362,1363,1364,1365,1366,1367,1368,1369,1370,1371,1372,1373,1374,1375,1376,1377,1378,1379,1380,1381,1382,1383,1384,1385,1386,1387,1388,1389,1390,1391,1392,1393,1394,1395,1396,1397,1398,1399,1400,1401,1402,1403,1404,1405,1406,1407],[1408,1409,1410,1411,1412,1413,1414,1415,1416,1417,1418,1419,1420,1421,1422,1423,1424,1425,1426,1427,1428,1429,1430,1431,1432,1433,1434,1435,1436,1437,1438,1439,1440,1441,1442,1443,1444,1445,1446,1447,1448,1449,1450,1451,1452,1453,1454,1455,1456,1457,1458,1459,1460,1461,1462,1463,1464,1465,1466,1467,1468,1469,1470,1471],[1472,1473,1474,1475,1476,1477,1478,1479,1480,1481,1482,1483,1484,1485,1486,1487,1488,1489,1490,1491,1492,1493,1494,1495,1496,1497,1498,1499,1500,1501,1502,1503,1504,1505,1506,1507,1508,1509,1510,1511,1512,1513,1514,1515,1516,1517,1518,1519,1520,1521,1522,1523,1524,1525,1526,1527,1528,1529,1530,1531,1532,1533,1534,1535],[1536,1537,1538,1539,1540,1541,1542,1543,1544,1545,1546,1547,1548,1549,1550,1551,1552,1553,1554,1555,1556,1557,1558,1559,1560,1561,1562,1563,1564,1565,1566,1567,1568,1569,1570,1571,1572,1573,1574,1575,1576,1577,1578,1579,1580,1581,1582,1583,1584,1585,1586,1587,1588,1589,1590,1591,1592,1593,1594,1595,1596,1597,1598,1599],[1600,1601,1602,1603,1604,1605,1606,1607,1608,1609,1610,1611,1612,1613,1614,1615,1616,1617,1618,1619,1620,1621,1622,1623,1624,1625,1626,1627,1628,1629,1630,1631,1632,1633,1634,1635,1636,1637,1638,1639,1640,1641,1642,1643,1644,1645,1646,1647,1648,1649,1650,1651,1652,1653,1654,1655,1656,1657,1658,1659,1660,1661,1662,1663],[1664,1665,1666,1667,1668,1669,1670,1671,1672,1673,1674,1675,1676,1677,1678,1679,1680,1681,1682,1683,1684,1685,1686,1687,1688,1689,1690,1691,1692,1693,1694,1695,1696,1697,1698,1699,1700,1701,1702,1703,1704,1705,1706,1707,1708,1709,1710,1711,1712,1713,1714,1715,1716,1717,1718,1719,1720,1721,1722,1723,1724,1725,1726,1727],[1728,1729,1730,1731,1732,1733,1734,1735,1736,1737,1738,1739,1740,1741,1742,1743,1744,1745,1746,1747,1748,1749,1750,1751,1752,1753,1754,1755,1756,1757,1758,1759,1760,1761,1762,1763,1764,1765,1766,1767,1768,1769,1770,1771,1772,1773,1774,1775,1776,1777,1778,1779,1780,1781,1782,1783,1784,1785,1786,1787,1788,1789,1790,1791],[1792,1793,1794,1795,1796,1797,1798,1799,1800,1801,1802,1803,1804,1805,1806,1807,1808,1809,1810,1811,1812,1813,1814,1815,1816,1817,1818,1819,1820,1821,1822,1823,1824,1825,1826,1827,1828,1829,1830,1831,1832,1833,1834,1835,1836,1837,1838,1839,1840,1841,1842,1843,1844,1845,1846,1847,1848,1849,1850,1851,1852,1853,1854,1855],[1856,1857,1858,1859,1860,1861,1862,1863,1864,1865,1866,1867,1868,1869,1870,1871,1872,1873,1874,1875,1876,1877,1878,1879,1880,1881,1882,1883,1884,1885,1886,1887,1888,1889,1890,1891,1892,1893,1894,1895,1896,1897,1898,1899,1900,1901,1902,1903,1904,1905,1906,1907,1908,1909,1910,1911,1912,1913,1914,1915,1916,1917,1918,1919],[1920,1921,1922,1923,1924,1925,1926,1927,1928,1929,1930,1931,1932,1933,1934,1935,1936,1937,1938,1939,1940,1941,1942,1943,1944,1945,1946,1947,1948,1949,1950,1951,1952,1953,1954,1955,1956,1957,1958,1959,1960,1961,1962,1963,1964,1965,1966,1967,1968,1969,1970,1971,1972,1973,1974,1975,1976,1977,1978,1979,1980,1981,1982,1983],[1984,1985,1986,1987,1988,1989,1990,1991,1992,1993,1994,1995,1996,1997,1998,1999,2000,2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,2020,2021,2022,2023,2024,2025,2026,2027,2028,2029,2030,2031,2032,2033,2034,2035,2036,2037,2038,2039,2040,2041,2042,2043,2044,2045,2046,2047]]}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"scaleanchor\":\"y\",\"constrain\":\"domain\",\"visible\":false},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\",\"constrain\":\"domain\",\"visible\":false},\"coloraxis\":{\"colorscale\":[[0.0,\"rgb(103,0,31)\"],[0.1,\"rgb(178,24,43)\"],[0.2,\"rgb(214,96,77)\"],[0.3,\"rgb(244,165,130)\"],[0.4,\"rgb(253,219,199)\"],[0.5,\"rgb(247,247,247)\"],[0.6,\"rgb(209,229,240)\"],[0.7,\"rgb(146,197,222)\"],[0.8,\"rgb(67,147,195)\"],[0.9,\"rgb(33,102,172)\"],[1.0,\"rgb(5,48,97)\"]],\"cmid\":0.0},\"title\":{\"text\":\"Difference in activations between original and ablated model at MLP layer 5 \\u003cbr\\u003e rearranged from a 1D vector into a grid\"},\"width\":800},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('f1b30628-3965-4db8-ad20-db70bfafbdaf');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def imshow(tensor, renderer=None, label_neurons=False, **kwargs):\n",
    "    preset_kwargs = {\n",
    "        \"color_continuous_midpoint\": 0.0,\n",
    "        \"color_continuous_scale\": \"RdBu\"\n",
    "    }\n",
    "\n",
    "    fig = px.imshow(utils.to_numpy(tensor), **{**preset_kwargs, **kwargs})\n",
    "    fig.update_xaxes(visible=False)\n",
    "    fig.update_yaxes(visible=False)\n",
    "    if label_neurons:\n",
    "        fig.update(data=[{'customdata': np.arange(len(tensor.flatten())).reshape(tensor.shape[0], -1), 'hovertemplate': \"Difference: %{z:.4f}<br>Neuron: %{customdata}\"}])\n",
    "    fig.show(renderer=renderer)\n",
    "\n",
    "imshow(difference.view(32, -1), label_neurons=True, title=\"\"\"Difference in activations between original and ablated model at MLP layer 5 <br> rearranged from a 1D vector into a grid\"\"\", width=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>                            <div id=\"3f276e01-5f6e-4f69-8f3d-83144a795ca3\" class=\"plotly-graph-div\" style=\"height:525px; width:1400px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"3f276e01-5f6e-4f69-8f3d-83144a795ca3\")) {                    Plotly.newPlot(                        \"3f276e01-5f6e-4f69-8f3d-83144a795ca3\",                        [{\"hovertemplate\":\"variable=0\\u003cbr\\u003eindex=%{x}\\u003cbr\\u003evalue=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"0\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"0\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99],\"xaxis\":\"x\",\"y\":[0.7151039838790894,0.7021030783653259,0.6447740197181702,0.475567102432251,0.4662923812866211,0.46433600783348083,0.44961270689964294,0.433454692363739,0.40544581413269043,0.3769306540489197,0.3681802451610565,0.36803004145622253,0.36461877822875977,0.3338053226470947,0.33250898122787476,0.3316364884376526,0.3285045623779297,0.3230321705341339,0.3122236132621765,0.30656278133392334,0.2980741262435913,0.29567965865135193,0.28793519735336304,0.2818148136138916,0.2729165256023407,0.2699168920516968,0.26951536536216736,0.26702335476875305,0.2624962329864502,0.2614167034626007,0.26138344407081604,0.25930845737457275,0.25740572810173035,0.25573912262916565,0.25457844138145447,0.2536703050136566,0.25326481461524963,0.24697662889957428,0.24593667685985565,0.24051909148693085,0.23975154757499695,0.23863309621810913,0.2375953495502472,0.23277893662452698,0.22527770698070526,0.2242056131362915,0.22258837521076202,0.21428820490837097,0.21230275928974152,0.21133802831172943,0.20641785860061646,0.20476014912128448,0.20241865515708923,0.20201140642166138,0.19905485212802887,0.1962376981973648,0.1952013373374939,0.19483855366706848,0.1934332549571991,0.19237466156482697,0.19218173623085022,0.18790467083454132,0.186822772026062,0.1862856149673462,0.18568946421146393,0.18472564220428467,0.1828276813030243,0.18267779052257538,0.1807904988527298,0.17916572093963623,0.17693571746349335,0.1767091006040573,0.17436707019805908,0.17360679805278778,0.17086076736450195,0.16956572234630585,0.16913700103759766,0.167741060256958,0.1676637977361679,0.16690252721309662,0.16606496274471283,0.16603899002075195,0.16564355790615082,0.16399624943733215,0.16168303787708282,0.16106033325195312,0.160530224442482,0.16007079184055328,0.15993934869766235,0.15788491070270538,0.15783314406871796,0.1564011573791504,0.1561419665813446,0.15368898212909698,0.15357568860054016,0.15327590703964233,0.15119875967502594,0.1501796692609787,0.14905105531215668,0.14789140224456787],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Neuron\"},\"tickmode\":\"array\",\"tickvals\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99],\"ticktext\":[273,670,395,8,164,1209,751,389,1661,929,1138,1353,245,1731,394,584,1479,1042,2023,1874,820,1020,1444,1706,1293,639,608,78,411,338,1851,380,651,1124,1536,1823,453,767,847,1880,1734,1972,995,4,1095,315,1625,505,1786,1934,831,499,1712,68,1389,423,1232,135,1859,1059,447,556,149,1788,493,548,978,297,1487,1719,347,1968,455,1936,1257,641,360,665,1104,648,962,586,1915,1315,160,414,927,405,554,783,892,387,1594,419,1530,989,249,727,1463,1261]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Absolute difference\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Top absolute neuron differences in layer 5\"},\"width\":1400},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('3f276e01-5f6e-4f69-8f3d-83144a795ca3');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def line(x, xlabel=\"\", ylabel=\"\", title=\"\", xticks=None, width=800, hover_data=None):\n",
    "    fig = px.line(x, title=title)\n",
    "    fig.update_layout(xaxis_title=xlabel, yaxis_title=ylabel, width=width)\n",
    "    if xticks != None:\n",
    "        fig.update_layout(\n",
    "            xaxis = dict(\n",
    "            tickmode = 'array',\n",
    "            tickvals = [i for i in range(len(xticks))],\n",
    "            ticktext = xticks\n",
    "            )\n",
    "        )\n",
    "    if hover_data != None:\n",
    "        fig.update(data=[{'customdata': hover_data, 'hovertemplate': \"Loss: %{y:.4f} (+%{customdata:.2f}%)\"}])\n",
    "    fig.show()\n",
    "\n",
    "# Plotting all differences seems to break Jupyter\n",
    "line(sorted_differences.cpu().numpy()[:100], xlabel=\"Neuron\", ylabel=\"Absolute difference\", xticks=sorted_neurons.cpu().tolist()[:100], title=f\"Top absolute neuron differences in layer {layer_to_cache}\", width=1400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss_patched_mlp_neurons(prompts: list[str], model: HookedTransformer, fwd_hooks: List[Tuple], patch_neurons, patch_layer=5, \n",
    "                                 crop_context_end: None | int=None):\n",
    "    original_losses = []\n",
    "    patched_losses = []\n",
    "    for prompt in tqdm(prompts):  \n",
    "        original_loss, _, _, ablated_cache = haystack_utils.get_caches_single_prompt(prompt, model, fwd_hooks, crop_context_end=crop_context_end)\n",
    "        \n",
    "        if crop_context_end is not None:\n",
    "            tokens = model.to_tokens(prompt)[:, :crop_context_end]\n",
    "        else:\n",
    "            tokens = model.to_tokens(prompt)\n",
    "        def patch_hook(value, hook):\n",
    "            # Batch, pos, d_mlp\n",
    "            value[:, :, patch_neurons] = ablated_cache[f'blocks.{patch_layer}.mlp.hook_post'][:, :, patch_neurons]\n",
    "        \n",
    "        with model.hooks(fwd_hooks=[(f'blocks.{patch_layer}.mlp.hook_post', patch_hook)]):\n",
    "            patched_loss = model(tokens, return_type=\"loss\")\n",
    "        \n",
    "        original_losses.append(original_loss)\n",
    "        patched_losses.append(patched_loss.item())\n",
    "\n",
    "    print(f\"Original loss: {np.mean(original_losses):.2f}, patched loss: {np.mean(patched_losses):.2f} (+{((np.mean(patched_losses) - np.mean(original_losses)) / np.mean(original_losses))*100:.2f}%)\")\n",
    "    return np.mean(original_losses), np.mean(patched_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patching neurons: [273, 670, 395, 8, 164]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "397aece3746a4ab9a8b8fc2a0487118b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1007 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original loss: 3.59, patched loss: 3.60 (+0.35%)\n"
     ]
    }
   ],
   "source": [
    "def ablate_neuron_hook(value, hook):\n",
    "    value[:, :, 609] = english_activations[609]\n",
    "    return value\n",
    "fwd_hooks = [(f'blocks.3.mlp.hook_post', ablate_neuron_hook)]\n",
    "\n",
    "patch_neurons = sorted_neurons.cpu().tolist()[:5]\n",
    "print(\"Patching neurons:\", patch_neurons)\n",
    "_, _ = get_loss_patched_mlp_neurons(kde_french, model, fwd_hooks, patch_neurons=patch_neurons, patch_layer=5, crop_context_end=500)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Patching neurons with high activation difference has a small effect on the loss\n",
    "- Activation doesn't necessarily correspond to changed log probs of the correct token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patching neurons: [273, 670, 395, 8, 164, 1209, 751, 389, 1661, 929, 1138, 1353, 245, 1731, 394, 584, 1479, 1042, 2023, 1874]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "090fa04cd9cd45c5981fc05d8f766961",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1007 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original loss: 3.59, patched loss: 3.62 (+0.99%)\n"
     ]
    }
   ],
   "source": [
    "def ablate_neuron_hook(value, hook):\n",
    "    value[:, :, 609] = english_activations[609]\n",
    "    return value\n",
    "fwd_hooks = [(f'blocks.3.mlp.hook_post', ablate_neuron_hook)]\n",
    "\n",
    "patch_neurons = sorted_neurons.cpu().tolist()[:20]\n",
    "print(\"Patching neurons:\", patch_neurons)\n",
    "_, _ = get_loss_patched_mlp_neurons(kde_french, model, fwd_hooks, patch_neurons=patch_neurons, patch_layer=5, crop_context_end=500)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logit attribution for all layers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Run model with and without ablating the French neuron, save both clean and ablated activations\n",
    "- Run model again without ablation\n",
    "- Simulate the effect of individual ablated components\n",
    "- To simulate ablating a component:\n",
    "    - Before the final layernorm, subtract the cached activation the component from the unablated run\n",
    "    - Then add the activation of the ablated run\n",
    "- This allows to compute the effect of running a component with corrupted activations without letting its output affecting later components\n",
    "- However, the cached ablated activations of later components will still be influenced by earlier components "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DLA(prompts: list[str], model: HookedTransformer, mean_neuron_activations, neurons = [609], layer_to_ablate=3, patched_component=8, crop_context: None | tuple[int, int]=None):\n",
    "    # TODO think about layer normalization\n",
    "    original_losses = []\n",
    "    patched_losses = []\n",
    "    for prompt in tqdm(prompts):\n",
    "\n",
    "        neurons = torch.LongTensor(neurons)\n",
    "        def ablate_neuron_hook(value, hook):\n",
    "            value[:, :, neurons] = mean_neuron_activations[neurons]\n",
    "            return value\n",
    "        \n",
    "        if crop_context is not None:\n",
    "            tokens = model.to_tokens(prompt)[:, crop_context[0]:crop_context[1]]\n",
    "        else:\n",
    "            tokens = model.to_tokens(prompt)\n",
    "        original_loss, original_cache = model.run_with_cache(tokens, return_type=\"loss\")\n",
    "\n",
    "        with model.hooks(fwd_hooks=[(f'blocks.{layer_to_ablate}.mlp.hook_post', ablate_neuron_hook)]):\n",
    "            ablated_loss, ablated_cache = model.run_with_cache(tokens, return_type=\"loss\")\n",
    "\n",
    "        # component, batch, pos, residual\n",
    "        # TODO figure out if we need layer norm here\n",
    "        original_per_layer_residual, original_labels = original_cache.decompose_resid(layer=-1, return_labels=True, apply_ln=False)\n",
    "        ablated_per_layer_residual, ablated_labels = ablated_cache.decompose_resid(layer=-1, return_labels=True, apply_ln=False)\n",
    "\n",
    "        # ['embed', '0_attn_out', '0_mlp_out', '1_attn_out', '1_mlp_out', '2_attn_out', '2_mlp_out', '3_attn_out', '3_mlp_out', '4_attn_out', '4_mlp_out', '5_attn_out', '5_mlp_out']\n",
    "        def swap_cache_hook(value, hook):\n",
    "            # Batch, pos, residual\n",
    "            value -= original_per_layer_residual[patched_component]\n",
    "            value += ablated_per_layer_residual[patched_component]\n",
    "        \n",
    "        with model.hooks(fwd_hooks=[(f'blocks.5.hook_resid_post', swap_cache_hook)]):\n",
    "            patched_loss = model(tokens, return_type=\"loss\")\n",
    "\n",
    "        original_losses.append(original_loss.item())\n",
    "        patched_losses.append(patched_loss.item())\n",
    "\n",
    "\n",
    "    print(f\"Original loss: {np.mean(original_losses):.2f}, patched loss: {np.mean(patched_losses):.2f} (+{((np.mean(patched_losses) - np.mean(original_losses)) / np.mean(original_losses))*100:.2f}%)\")\n",
    "    return np.mean(original_losses), np.mean(patched_losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component: 3_mlp_out\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92e7c2c9fe2d4187ab56d62537500d08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1007 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original loss: 3.59, patched loss: 3.65 (+1.72%)\n",
      "Component: 4_attn_out\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd622400e8574764abb025f595698437",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1007 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original loss: 3.59, patched loss: 3.60 (+0.41%)\n",
      "Component: 4_mlp_out\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3619ad63c857452bafa5a8d2b491b756",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1007 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original loss: 3.59, patched loss: 3.64 (+1.30%)\n",
      "Component: 5_attn_out\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8e1c17451d4434dac5a7d68e7706bde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1007 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original loss: 3.59, patched loss: 3.62 (+0.76%)\n",
      "Component: 5_mlp_out\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa7b0a42bc344ef49e34a51ae27184c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1007 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original loss: 3.59, patched loss: 3.73 (+3.99%)\n"
     ]
    }
   ],
   "source": [
    "# Layer 3 MLP logit attribution = direct effect of ablating the context neuron\n",
    "# Logit attribution of later components when ablating the context neuron\n",
    "# Not sure how clean this is - e.g. layer 5 MLP will get the accumulated effects of all previous layers from ablating the context neuron\n",
    "component_names = ['embed', '0_attn_out', '0_mlp_out', '1_attn_out', '1_mlp_out', '2_attn_out', '2_mlp_out', '3_attn_out', '3_mlp_out', '4_attn_out', '4_mlp_out', '5_attn_out', '5_mlp_out']\n",
    "\n",
    "components = []\n",
    "losses = []\n",
    "for later_component in range(8, 13):\n",
    "    print(f\"Component: {component_names[later_component]}\")\n",
    "    original_loss, patched_loss = DLA(kde_french, model, english_activations, patched_component=later_component, crop_context=(0, 500))\n",
    "    if len(losses) == 0:\n",
    "        components.append(\"Original loss\")\n",
    "        losses.append(original_loss)\n",
    "    components.append(component_names[later_component])\n",
    "    losses.append(patched_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>                            <div id=\"7b1eba46-1ae0-418d-84b8-14b6792ec08c\" class=\"plotly-graph-div\" style=\"height:525px; width:800px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"7b1eba46-1ae0-418d-84b8-14b6792ec08c\")) {                    Plotly.newPlot(                        \"7b1eba46-1ae0-418d-84b8-14b6792ec08c\",                        [{\"hovertemplate\":\"Loss: %{y:.4f} (+%{customdata:.2f}%)\",\"legendgroup\":\"0\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"0\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3,4,5],\"xaxis\":\"x\",\"y\":[3.588964023324915,3.6506699109977148,3.603763714861846,3.6356001068369044,3.616193000349293,3.732294611447854],\"yaxis\":\"y\",\"type\":\"scatter\",\"customdata\":[0.0,1.719323104711247,0.41236667296597734,1.299430231367554,0.7586862628718191,3.9936479494200547]}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Component\"},\"tickmode\":\"array\",\"tickvals\":[0,1,2,3,4,5],\"ticktext\":[\"Original loss\",\"3_mlp_out\",\"4_attn_out\",\"4_mlp_out\",\"5_attn_out\",\"5_mlp_out\"]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Loss\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Loss of individual patching individual components when ablating L3N609\"},\"width\":800},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('7b1eba46-1ae0-418d-84b8-14b6792ec08c');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "percent_increase = ((np.array(losses) - losses[0]) / losses[0]) * 100\n",
    "line(losses, xlabel=\"Component\", ylabel=\"Loss\", title=\"Loss of individual patching individual components when ablating L3N609\", xticks=components, width=800, hover_data=percent_increase.tolist())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Total effect of ablating L3N609: 5.97% increase in loss\n",
    "- Direct effect of ablating L3N609: 1.5% increase in loss\n",
    "- Added direct effects of all later components and ~8%\n",
    "- The French neuron must directly boost relevant words"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Does it make sense that the direct loss attribution of individual components sums to a higher total loss than the total loss of ablating the neuron\n",
    "- Yes?: \n",
    "    - Components make similar mistakes so that ablating all of them leads to fewer loss\n",
    "    - Later components receive the residual stream input of accumulated mistakes (not clean path patching)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check individual contributions of L5 neurons"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Motivation: The output of MLP layer 5 caused the biggest increase in loss in the previous analysis. We want to find which neurons specifically are responsible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check, compare output directions from the residual stream\n",
    "\n",
    "def get_answer_token_logit_difference(prompts: list[str], model: HookedTransformer, mean_neuron_activations, neurons = [609], layer_to_ablate=3, layer_to_compare=5, crop_context: None | tuple[int, int]=None):\n",
    "    # Computes output logit difference of the correct token between the outputs of a MLP layer with and without ablated neurons\n",
    "    # TODO think about layer normalization\n",
    "    differences = []\n",
    "    for prompt in tqdm(prompts):\n",
    "        model.reset_hooks()\n",
    "        if crop_context is not None:\n",
    "            tokens = model.to_tokens(prompt)[:, crop_context[0]:crop_context[1]]\n",
    "        else:\n",
    "            tokens = model.to_tokens(prompt)\n",
    "        original_loss, original_cache = model.run_with_cache(tokens, return_type=\"loss\")\n",
    "        answer_tokens = tokens[:, 1:]\n",
    "\n",
    "        # Shape batch pos residual\n",
    "        mlp_post = original_cache[f'blocks.{layer_to_compare}.hook_mlp_out']\n",
    "        # Shape batch pos-1 residual\n",
    "        normalized_mlp_post = original_cache.apply_ln_to_stack(mlp_post)[:,:-1]\n",
    "        correct_token_directions = model.W_U[:, answer_tokens].squeeze(1) # embed pos\n",
    "        # Shape position\n",
    "        original_unembedded = einops.einsum(normalized_mlp_post, correct_token_directions, 'batch pos residual, residual pos -> batch pos').squeeze(0)\n",
    "\n",
    "        def ablate_neuron_hook(value, hook):\n",
    "            value[:, :, neurons] = mean_neuron_activations[neurons]\n",
    "            return value\n",
    "    \n",
    "        with model.hooks(fwd_hooks=[(f'blocks.{layer_to_ablate}.mlp.hook_post', ablate_neuron_hook)]):\n",
    "            ablated_loss, ablated_cache = model.run_with_cache(tokens, return_type=\"loss\")\n",
    "        \n",
    "        mlp_post = ablated_cache[f'blocks.{layer_to_compare}.hook_mlp_out']\n",
    "        normalized_mlp_post = ablated_cache.apply_ln_to_stack(mlp_post)[:,:-1]\n",
    "        ablated_unembedded = einops.einsum(normalized_mlp_post, correct_token_directions, 'batch pos residual, residual pos -> batch pos').squeeze(0)\n",
    "\n",
    "        # Shape: pos\n",
    "        difference = (original_unembedded - ablated_unembedded).detach().cpu().mean().item()\n",
    "        differences.append(difference)\n",
    "    print(\"Mean difference:\", np.mean(differences))\n",
    "\n",
    "#get_answer_token_logit_difference(kde_french, model, english_activations, crop_context=(10, 500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neuron_logit_contribution(cache: ActivationCache, model: HookedTransformer, answer_tokens: Int[Tensor, \"batch pos\"], layer: int) -> Float[Tensor, \"neuron pos\"]:\n",
    "    # Expexts cache from a single example, won't work on batched examples\n",
    "    # Get per neuron output of MLP layer\n",
    "    neuron_directions = cache.get_neuron_results(layer, neuron_slice=utils.Slice(input_slice=None), pos_slice=utils.Slice(input_slice=None))\n",
    "    neuron_directions = einops.rearrange(neuron_directions, 'batch pos neuron residual -> neuron batch pos residual')\n",
    "    # Apply LN? LN is usually never applied to individual MLP output directions, it is applied to the sum of MLP output directions\n",
    "    # LN leads to finding top tokens with slightly higher loss attribution\n",
    "    #scaled_neuron_directions = neuron_directions[:, 0, :-1, :]\n",
    "    scaled_neuron_directions = cache.apply_ln_to_stack(neuron_directions)[:, 0, :-1, :] # neuron pos embed\n",
    "    # Unembed of correct answer tokens\n",
    "    correct_token_directions = model.W_U[:, answer_tokens].squeeze(1) # embed pos # d_model answer_tokens\n",
    "    # Neuron attribution to correct answer token by position\n",
    "    unembedded = einops.einsum(scaled_neuron_directions, correct_token_directions, 'neuron pos residual, residual pos -> neuron pos') # neuron pos\n",
    "    return unembedded\n",
    "\n",
    "# This doesn't work at all!\n",
    "def get_neuron_logit_contribution_wrong(cache: ActivationCache, model: HookedTransformer, answer_tokens: Int[Tensor, \"batch pos\"], layer: int) -> Float[Tensor, \"neuron pos\"]:\n",
    "    # Get per neuron output of MLP layer\n",
    "    neuron_directions = cache.get_neuron_results(layer, neuron_slice=utils.Slice(input_slice=None), pos_slice=utils.Slice(input_slice=None))\n",
    "    neuron_directions = einops.rearrange(neuron_directions, 'batch pos neuron residual -> neuron batch pos residual')\n",
    "    assert neuron_directions.shape[1] == 1, \"Expexts cache from a single example, won't work on batched examples\"\n",
    "    # Apply ln? LN is never applied to individual MLP output directions, not sure if it matters\n",
    "    #scaled_neuron_directions = neuron_directions[:, 0, :-1, :]\n",
    "    scaled_neuron_directions = cache.apply_ln_to_stack(neuron_directions)[:, 0, :-1, :]\n",
    "    unembedded = einops.einsum(scaled_neuron_directions, model.W_U, 'neuron pos residual, residual output_dim -> neuron output_dim')\n",
    "    unembedded = unembedded.softmax(-1)[:, answer_tokens[0]]\n",
    "    return unembedded # neuron answer_prob"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check if neurons are the same with and without LN\n",
    "- Repeat loss increase analysis for new top and bottom neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64d1fdd253b14d2fb5a08032aa366eac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1007 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1.44 GiB (GPU 0; 23.65 GiB total capacity; 6.03 GiB already allocated; 1.06 GiB free; 6.40 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 38\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[39mreturn\u001b[39;00m value\n\u001b[1;32m     37\u001b[0m fwd_hooks \u001b[39m=\u001b[39m [(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mblocks.3.mlp.hook_post\u001b[39m\u001b[39m'\u001b[39m, ablate_neuron_hook)]\n\u001b[0;32m---> 38\u001b[0m sorted_differences, sorted_neurons \u001b[39m=\u001b[39m MLP_attribution(kde_french, model, fwd_hooks, layer_to_compare\u001b[39m=\u001b[39;49mlayer_to_compare, crop_context\u001b[39m=\u001b[39;49m(\u001b[39m0\u001b[39;49m, \u001b[39m500\u001b[39;49m))\n",
      "Cell \u001b[0;32mIn[53], line 15\u001b[0m, in \u001b[0;36mMLP_attribution\u001b[0;34m(prompts, model, fwd_hooks, layer_to_compare, crop_context)\u001b[0m\n\u001b[1;32m     12\u001b[0m answer_tokens \u001b[39m=\u001b[39m tokens[:, \u001b[39m1\u001b[39m:]\n\u001b[1;32m     14\u001b[0m \u001b[39m# Shape neuron pos\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m original_unembedded \u001b[39m=\u001b[39m get_neuron_logit_contribution(original_cache, model, answer_tokens, layer\u001b[39m=\u001b[39;49mlayer_to_compare)\n\u001b[1;32m     17\u001b[0m \u001b[39mwith\u001b[39;00m model\u001b[39m.\u001b[39mhooks(fwd_hooks\u001b[39m=\u001b[39mfwd_hooks):\n\u001b[1;32m     18\u001b[0m     ablated_loss, ablated_cache \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mrun_with_cache(tokens, return_type\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[45], line 9\u001b[0m, in \u001b[0;36mget_neuron_logit_contribution\u001b[0;34m(cache, model, answer_tokens, layer)\u001b[0m\n\u001b[1;32m      5\u001b[0m neuron_directions \u001b[39m=\u001b[39m einops\u001b[39m.\u001b[39mrearrange(neuron_directions, \u001b[39m'\u001b[39m\u001b[39mbatch pos neuron residual -> neuron batch pos residual\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[39m# Apply LN? LN is usually never applied to individual MLP output directions, it is applied to the sum of MLP output directions\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39m# LN leads to finding top tokens with slightly higher loss attribution\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[39m#scaled_neuron_directions = neuron_directions[:, 0, :-1, :]\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m scaled_neuron_directions \u001b[39m=\u001b[39m cache\u001b[39m.\u001b[39;49mapply_ln_to_stack(neuron_directions)[:, \u001b[39m0\u001b[39m, :\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, :] \u001b[39m# neuron pos embed\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[39m# Unembed of correct answer tokens\u001b[39;00m\n\u001b[1;32m     11\u001b[0m correct_token_directions \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mW_U[:, answer_tokens]\u001b[39m.\u001b[39msqueeze(\u001b[39m1\u001b[39m) \u001b[39m# embed pos # d_model answer_tokens\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformer_lens/ActivationCache.py:631\u001b[0m, in \u001b[0;36mActivationCache.apply_ln_to_stack\u001b[0;34m(self, residual_stack, layer, mlp_input, pos_slice, batch_slice, has_batch_dim)\u001b[0m\n\u001b[1;32m    628\u001b[0m     residual_stack \u001b[39m=\u001b[39m batch_slice\u001b[39m.\u001b[39mapply(residual_stack, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    630\u001b[0m \u001b[39m# Center the stack\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m residual_stack \u001b[39m=\u001b[39m residual_stack \u001b[39m-\u001b[39;49m residual_stack\u001b[39m.\u001b[39;49mmean(dim\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, keepdim\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    633\u001b[0m \u001b[39mif\u001b[39;00m layer \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mcfg\u001b[39m.\u001b[39mn_layers \u001b[39mor\u001b[39;00m layer \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    634\u001b[0m     scale \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mln_final.hook_scale\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.44 GiB (GPU 0; 23.65 GiB total capacity; 6.03 GiB already allocated; 1.06 GiB free; 6.40 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# TODO think about layer normalization\n",
    "# This method lacks correct masking and so the means are wrong\n",
    "\n",
    "def MLP_attribution(prompts: list[str], model: HookedTransformer, fwd_hooks, layer_to_compare=5, crop_context_end: None | int=None):\n",
    "    \"\"\" \n",
    "    Gets the difference between neuron activations on the correct token between the original and ablated model.\n",
    "    Works on a single model layer. A positive difference here means the ablated neuron has lower mean activations \n",
    "    on the correct token\"\"\"\n",
    "    differences = torch.zeros(model.cfg.d_mlp)\n",
    "    for prompt in tqdm(prompts):\n",
    "        # Get answer tokens\n",
    "        if crop_context_end is not None:\n",
    "            tokens = model.to_tokens(prompt)[:, :crop_context_end]\n",
    "        else:\n",
    "            tokens = model.to_tokens(prompt)\n",
    "        answer_tokens = tokens[:, 1:]\n",
    "\n",
    "        # Get difference between ablated and unablated neurons' contribution to answer logit\n",
    "        _, _, original_cache, ablated_cache = haystack_utils.get_caches_single_prompt(\n",
    "            prompt, model, fwd_hooks, crop_context_end=crop_context_end)\n",
    "        \n",
    "        # [neuron pos]\n",
    "        original_unembedded = get_neuron_logit_contribution(original_cache, model, answer_tokens, layer=layer_to_compare)\n",
    "        ablated_unembedded = get_neuron_logit_contribution(ablated_cache, model, answer_tokens, layer=layer_to_compare)\n",
    "        # [neuron]\n",
    "        difference = (original_unembedded - ablated_unembedded).mean(1).detach().cpu()  \n",
    "        differences += difference\n",
    "    \n",
    "    mean_difference = differences / len(prompts)\n",
    "    print(\"Total activation difference on correct token:\", mean_difference.sum().item())\n",
    "    sorted_differences, sorted_neurons = torch.topk(mean_difference, len(mean_difference), largest=True)\n",
    "    return sorted_differences, sorted_neurons\n",
    "\n",
    "haystack_utils.clean_cache()\n",
    "layer_to_compare=5\n",
    "def ablate_neuron_hook(value, hook):\n",
    "    value[:, :, 609] = english_activations[609]\n",
    "    return value\n",
    "fwd_hooks = [(f'blocks.3.mlp.hook_post', ablate_neuron_hook)]\n",
    "sorted_differences, sorted_neurons = MLP_attribution(kde_french, model, fwd_hooks, layer_to_compare=layer_to_compare, crop_context_end=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>                            <div id=\"a58eadb8-faaa-4e60-812a-7d94b602593a\" class=\"plotly-graph-div\" style=\"height:525px; width:800px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"a58eadb8-faaa-4e60-812a-7d94b602593a\")) {                    Plotly.newPlot(                        \"a58eadb8-faaa-4e60-812a-7d94b602593a\",                        [{\"hovertemplate\":\"variable=0\\u003cbr\\u003eindex=%{x}\\u003cbr\\u003evalue=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"0\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"0\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29],\"xaxis\":\"x\",\"y\":[0.08461214601993561,0.04759485274553299,0.03019873984158039,0.024128390476107597,0.01896042563021183,0.013806466944515705,0.013721026480197906,0.013473210856318474,0.012234045192599297,0.01184495072811842,0.011024907231330872,0.010849898681044579,0.010374963283538818,0.009693855419754982,0.009565649554133415,0.00949173141270876,0.00936784129589796,0.009315874427556992,0.008360042236745358,0.007807486690580845,0.0076604862697422504,0.007384961936622858,0.007326149381697178,0.007324960082769394,0.007073892746120691,0.00699077732861042,0.006845083553344011,0.006686041597276926,0.006685232277959585,0.0064358278177678585],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Neuron\"},\"tickmode\":\"array\",\"tickvals\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29],\"ticktext\":[395,670,584,1622,1138,1487,1658,493,273,767,1283,1825,4,1020,1661,1479,1672,347,315,1844,1644,453,1874,586,164,759,472,1104,1884,1702]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Logit difference on correct token\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Top positive neuron logit differences on correct tokens on layer 5\"},\"width\":800},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('a58eadb8-faaa-4e60-812a-7d94b602593a');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>                            <div id=\"77f18c67-9e40-4f9f-824a-802a270f903e\" class=\"plotly-graph-div\" style=\"height:525px; width:800px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"77f18c67-9e40-4f9f-824a-802a270f903e\")) {                    Plotly.newPlot(                        \"77f18c67-9e40-4f9f-824a-802a270f903e\",                        [{\"hovertemplate\":\"variable=0\\u003cbr\\u003eindex=%{x}\\u003cbr\\u003evalue=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"0\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"0\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29],\"xaxis\":\"x\",\"y\":[-0.00509016215801239,-0.005194589961320162,-0.005227178800851107,-0.0052933464758098125,-0.0053576016798615456,-0.005443326663225889,-0.005465829744935036,-0.005701709073036909,-0.005766805727034807,-0.005866533610969782,-0.006229724735021591,-0.006250201724469662,-0.006486672442406416,-0.0067767915315926075,-0.0068545774556696415,-0.006912577897310257,-0.007049124222248793,-0.0073684207163751125,-0.007421499118208885,-0.007794040255248547,-0.007920109666883945,-0.008427614346146584,-0.008761937730014324,-0.010151831433176994,-0.011045901104807854,-0.012480740435421467,-0.012979354709386826,-0.014713485725224018,-0.044681720435619354,-0.0901414230465889],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Neuron\"},\"tickmode\":\"array\",\"tickvals\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29],\"ticktext\":[469,100,1027,636,869,1336,1934,929,265,291,1475,1716,1839,414,641,455,1232,1456,394,1708,1786,1972,8,1209,1353,1444,2023,651,1257,389]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Logit difference on correct token\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Top negative neuron logit differences on correct tokens on layer 5\"},\"width\":800},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('77f18c67-9e40-4f9f-824a-802a270f903e');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "line(sorted_differences.cpu().numpy()[:30], xlabel=\"Neuron\", ylabel=\"Logit difference on correct token\", xticks=sorted_neurons.cpu().tolist()[:30], title=f\"Top positive neuron logit differences on correct tokens on layer {layer_to_compare}\", width=800)\n",
    "line(sorted_differences.cpu().numpy()[-30:], xlabel=\"Neuron\", ylabel=\"Logit difference on correct token\", xticks=sorted_neurons.cpu().tolist()[-30:], title=f\"Top negative neuron logit differences on correct tokens on layer {layer_to_compare}\", width=800)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test effect of patching top logit difference neurons on loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sanity check: ablate whole layer - should lead to loss increase of 4%\n",
    "# def ablate_neuron_hook(value, hook):\n",
    "#     value[:, :, 609] = english_activations[609]\n",
    "#     return value\n",
    "# fwd_hooks = [(f'blocks.3.mlp.hook_post', ablate_neuron_hook)]\n",
    "# top_neurons = sorted_neurons.cpu().tolist()[:5]\n",
    "# _, _ = get_loss_patched_mlp_neurons(kde_french, model, fwd_hooks, patch_neurons=[i for i in range(model.cfg.d_mlp)], patch_layer=5, crop_context_end=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patched: [395, 670, 584, 1622, 1138]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36008791991141aa97dda85c1c98da17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1007 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original loss: 3.59, patched loss: 3.60 (+0.17%)\n"
     ]
    }
   ],
   "source": [
    "# Ablate top neurons\n",
    "def ablate_neuron_hook(value, hook):\n",
    "    value[:, :, 609] = english_activations[609]\n",
    "    return value\n",
    "fwd_hooks = [(f'blocks.3.mlp.hook_post', ablate_neuron_hook)]\n",
    "top_neurons = sorted_neurons.cpu().tolist()[:5]\n",
    "print(\"Patched:\", top_neurons)\n",
    "_, _ = get_loss_patched_mlp_neurons(kde_french, model, fwd_hooks, patch_neurons=top_neurons, patch_layer=5, crop_context_end=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patched: [1444, 2023, 651, 1257, 389]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7f1675a7a1848e184632634b6ad987b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1007 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original loss: 3.59, patched loss: 3.60 (+0.37%)\n"
     ]
    }
   ],
   "source": [
    "# Sanity check: ablate bottom neurons - should lead to a much lower increase in loss than top neurons\n",
    "def ablate_neuron_hook(value, hook):\n",
    "    value[:, :, 609] = english_activations[609]\n",
    "    return value\n",
    "fwd_hooks = [(f'blocks.3.mlp.hook_post', ablate_neuron_hook)]\n",
    "worst_neurons = sorted_neurons.cpu().tolist()[-5:]\n",
    "print(\"Patched:\", worst_neurons)\n",
    "_, _ = get_loss_patched_mlp_neurons(kde_french, model, fwd_hooks, patch_neurons=worst_neurons, patch_layer=5, crop_context_end=500)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Patching all neurons leads to the expected increase in loss of 4% (in line with our layer ablation results)\n",
    "- Patching the top 5 neurons from our analysis should result in a high-ish loss increase but we get 0.18%\n",
    "- Patching the bottom 5 neurons should result in a very low increase in loss (technically it should be negative looking at our attribution curve) but we get 0.37%"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
