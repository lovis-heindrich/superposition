{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from transformer_lens import HookedTransformer\n",
    "from jaxtyping import Float, Int, Bool\n",
    "from torch import Tensor\n",
    "from tqdm.auto import tqdm\n",
    "import plotly.io as pio\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px \n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from IPython.display import display, HTML\n",
    "from datasets import load_dataset\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "pio.renderers.default = \"notebook_connected+notebook\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.autograd.set_grad_enabled(False)\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "from haystack_utils import get_mlp_activations\n",
    "from hook_utils import save_activation\n",
    "import haystack_utils\n",
    "import hook_utils\n",
    "import plotting_utils\n",
    "import pythia_160m_utils\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model EleutherAI/pythia-70m into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "model = HookedTransformer.from_pretrained(\"EleutherAI/pythia-70m\",\n",
    "    center_unembed=True,\n",
    "    center_writing_weights=True,\n",
    "    fold_ln=True,\n",
    "    device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/freelaw.txt\", \"r\") as f:\n",
    "    freelaw = f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'     The summaries of the Colorado Court of Appeals published opinions\\n  constitute no part of the opinion of the division but have been prepared by\\n  the division for the convenience of the reader. The summaries may not be\\n    cited or relied upon as they are not the official language of the division.\\n  Any discrepancy between the language in the summary and in the opinion\\n           should be resolved in favor of the language in the opinion.\\n\\n\\n                                                                  SUMMARY\\n                                                            February 8, 2018\\n\\n                                2018COA12\\n\\nNo. 14CA0144, People v. Trujillo — Criminal Law — Sentencing\\n— Probation — Indeterminate Sentence\\n\\n     A division of the court of appeals considers whether a\\n\\nColorado statute authorizes imposition of a sentence to an\\n\\nindeterminate term of probation and whether the defendant was\\n\\nentitled to the benefit of amendments to the statute criminalizing\\n\\nthef'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freelaw[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2115"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freelaw_data = freelaw.split(\"\\n\\n\\n\")\n",
    "len(freelaw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35b7beb119054ac1af92618656810710",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2115 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from nltk.util import ngrams\n",
    "\n",
    "all_ngrams = {n:[] for n in range(10, 3, -1)}\n",
    "\n",
    "for sentence in tqdm(freelaw_data):\n",
    "    tokens = model.to_str_tokens(sentence)\n",
    "    for n in range(10, 3, -1):\n",
    "        x_grams = ngrams(tokens, n)\n",
    "        all_ngrams[n].extend(x_grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((' U', '.', 'S', '.'), 907)\n",
      "((' F', '.', '3', 'd'), 395)\n",
      "((' F', '.', '2', 'd'), 388)\n",
      "(('S', '.', 'C', '.'), 341)\n",
      "(('.', 'S', '.', 'C'), 339)\n",
      "((' S', '.', 'Ct', '.'), 274)\n",
      "(('.', 'C', '.', ' §'), 210)\n",
      "((' L', '.', 'Ed', '.'), 210)\n",
      "(('.', 'Ed', '.', '2'), 182)\n",
      "(('Ed', '.', '2', 'd'), 182)\n",
      "((' S', '.', 'W', '.'), 175)\n",
      "((' United', ' States', ' v', '.'), 146)\n",
      "(('.', 'W', '.', '2'), 128)\n",
      "((' (', '5', 'th', ' Cir'), 127)\n",
      "(('.', '3', 'd', ' at'), 126)\n",
      "(('W', '.', '2', 'd'), 126)\n",
      "(('.', 'S', '.', ' at'), 123)\n",
      "(('5', 'th', ' Cir', '.'), 121)\n",
      "(('.', '2', 'd', ' at'), 107)\n",
      "((' v', '.', ' United', ' States'), 100)\n"
     ]
    }
   ],
   "source": [
    "common_phrases = Counter(all_ngrams[4]).most_common(20)\n",
    "for phrase in common_phrases:\n",
    "    print(phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<|endoftext|>', ' 28', ' U', '.', 'S', '.', 'C', '.']\n"
     ]
    }
   ],
   "source": [
    "prompt = ' 28 U.S.C.'\n",
    "print(model.to_str_tokens(model.to_tokens(prompt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.2944e+01, 4.1906e+00, 2.8218e-03, 2.1607e-01, 3.9450e-04, 1.6760e+00,\n",
       "         1.8215e-03]], device='cuda:0')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(prompt, return_type=\"loss\", loss_per_token=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
